[{"title":"DDD架构中数据传递的过程","url":"/2023/05/11/the-process-of-data-transfer-in-DDD-architecture/","content":"\nDDD架构中如何domain层和infrastructure如何传递数据，以及作用\n\n<!--more-->\n\n### 传统的三层架构\n\n传统的三层架构包括表示层、业务逻辑层和数据访问层，它的设计目标是将系统划分为独立的、高内聚、低耦合的模块，使得每个模块的职责清晰、易于维护和升级。在这种架构中，业务逻辑层是系统的核心，它处理所有的业务逻辑，而表示层和数据访问层则分别负责与用户交互和访问数据。\n\n![1895018-20230314115040094-875486601](the-process-of-data-transfer-in-DDD-architecture/1895018-20230314115040094-875486601-16843216712372.png)\n\nMVC模式中业务逻辑层直接与数据访问层交互，导致与数据层面有较强的依赖关系，以致于不便后续数据层面的更新，并且也会导致自身的庞大和臃肿，不便后续的维护。\n\n### 领域驱动设计的四层架构\n\n![2-02-16826858766012](the-process-of-data-transfer-in-DDD-architecture/2-02-16826858766012.png)\n\n领域驱动设计的四层架构则更加强调领域模型的设计和实现，它包括表示层、应用层、领域层和基础设施层。在这种架构中，领域层是系统的核心，它包含了系统的领域模型和业务逻辑，而应用层负责协调各个领域层的操作，提供应用程序的服务接口，表示层负责与用户交互，基础设施层负责提供与外部系统的交互和数据存储等服务。\n\n领域层只关注业务逻辑的实现，提供领域数据的接口，而不关注具体数据如何操作，基础层实现领域层提供的接口，配合DAO和po完成具体的方法。\n\n#### 领域层包结构\n\n![image-20230517192910187](the-process-of-data-transfer-in-DDD-architecture/image-20230517192910187.png)\n\nactivity, award,strategy是三个领域，领域下在repository包中定义具体的数据接口。\n\n#### 基础层包结构\n\ndao包含数据访问逻辑，po是持久化对象，repository是对领域层提供的接口的实现\n\n![image-20230517193502810](the-process-of-data-transfer-in-DDD-architecture/image-20230517193502810.png)\n\n在infrastructure层下实现这些接口，DAO做数据层面的交互，处理数据访问逻辑，可以实现解耦合。\n\n并且，仓储层可以在领域模型的操作之上实施领域规则。这意味着在执行数据访问操作之前或之后，可以在仓储中添加额外的逻辑来保持领域模型的一致性和完整性。\n\n![image-20230517200449992](the-process-of-data-transfer-in-DDD-architecture/image-20230517200449992.png)\n\n仓储层可以负责将基础设施层的数据映射为领域模型所需的数据结构，以及将领域模型的数据转换为基础设施层所需的格式。这种转换和映射逻辑可以在仓储中集中处理，减少领域模型与基础设施层之间的耦合。如转换成聚合根。\n\n![image-20230517200645985](the-process-of-data-transfer-in-DDD-architecture/image-20230517200645985.png)\n\n过在仓储层中定义接口，可以实现技术的灵活性，使得可以更换底层数据访问技术或使用不同的数据存储策略，而无需修改领域模型。同时，仓储接口也有助于编写针对领域模型的单元测试，因为可以使用模拟或存根实现来模拟数据访问。\n","tags":["设计模式"],"categories":["设计模式"]},{"title":"理清@Autowired和@Resource的区别和联系","url":"/2023/04/17/difference-between-resource-and-autowired/","content":"\n使用方法以及区别联系\n\n<!--more-->\n\n### 联系\n\n@Autowired和@Resource注解都是作为bean对象注入的时候使用的\n两者都可以声明在字段和setter方法上\n注意：如果声明在字段上，那么就不需要再写setter方法。但是本质上，该对象还是作为set方法的实参，通过执行set方法注入，只是省略了setter方法罢了\n\n### 区别\n\n@Autowired注解是Spring提供的，而@Resource注解是J2EE本身提供的，JDK1.6之后才能使用\n@Autowird注解默认通过byType方式注入，而@Resource注解默认通过byName方式注入\n@Autowired注解注入的对象需要在IOC容器中存在，否则需要加上属性required=false，表示忽略当前要注入的bean，如果有直接注入，没有跳过，不会报错\n\n#### 什么是byType，什么是byName\n\n```\n<bean id=\"userService\" class=\"com.test.UserServiceImpl\">\n</bean> \n```\n\n```\n@Autowired\nprivate UserService userService;\n```\n\n此处byName就是拿变量名userService去匹配IOC容器的iduserService，匹配成功；而byType就是拿变量类型UserService去匹配IOC容器的idcom.test.UserService.UserServiceImpl，因为UserServiceImpl是UserService实现，所以也匹配成功\n\n### @Autowird注解的使用\n\n@Autowird默认的注入方式为byType，也就是根据类型匹配，当有多个实现时，则通过byName注入，也可以通过配合@Qualifier注解来显式指定name值，指明要使用哪个具体的实现类\n\n举例：\n\n首先有一个接口UserService和两个实现类UserServiceImpl1和UserServiceImpl2，并且这两个实现类已经加入到Spring的IOC容器中了\n\n```\n@Service\npublic class UserServiceImpl1 implements UserService\n\n@Service\npublic class UserServiceImpl2 implements UserService\n```\n\n通过@Autowired注入使用\n\n```\n@Autowired\nprivate UserService userService;\n```\n\n根据上面的步骤，可以很容易判断出，直接这么使用是会报错的\n原因：首先通过byType注入，判断UserService类型有两个实现，无法确定具体是哪一个，于是通过byName方式，这里的变量名userService也无法匹配IOC容器中id（此处指的userServiceImpl1和userServiceImpl2），于是报错。\n\n注意：通过注解注入到IOC容器的id值默认是其类名首字母小写\n\n解决方案\n\n方式一：\n\n// 方式一：改变变量名\n\n```\n@Autowired\nprivate UserService userServiceImpl1;\n```\n\n方式二：\n\n// 方式二：配合@Qualifier注解来显式指定name值\n\n```\n@Autowired\n@Qualifier(value = \"userServiceImpl1\")\nprivate UserService userService;\n```\n\n### @Resource注解的使用\n\n步骤：@Resource默认通过byName注入，如果没有匹配则通过byType注入\n\n举例：\n\n```\n@Service\npublic class UserServiceImpl1 implements UserService\n\n@Service\npublic class UserServiceImpl2 implements UserService\n\n@Resource\nprivate UserService userService;\n```\n\n首先通过byName匹配，变量名userService无法匹配IOC容器中任何一个id（这里指的userServiceImpl1和userServiceImpl2），于是通过byType匹配，发现类型UserService的实现类有两个，仍然无法确定，于是BeanCreationException异常。\n\n同时@Resource还有两个重要的属性：name和type，用来显式指定byName和byType方式注入\n\n#### @Resource装配顺序\n\n```\n/ 1. 默认方式：byName\n@Resource  \nprivate UserService userDao; \n\n// 2. 指定byName\n@Resource(name=\"userService\")  \nprivate UserService userService; \n\n// 3. 指定byType\n@Resource(type=UserService.class)  \nprivate UserService userService; \n\n// 4. 指定byName和byType\n@Resource(name=\"userService\",type=UserService.class)  \nprivate UserService userService; \n```\n\n既没指定name属性，也没指定type属性：默认通过byName方式注入，如果byName匹配失败，则使用byType方式注入（也就是上面的那个例子）\n指定name属性：通过byName方式注入，把变量名和IOC容器中的id去匹配，匹配失败则报错\n指定type属性：通过byType方式注入，在IOC容器中匹配对应的类型，如果匹配不到或者匹配到多个则报错\n同时指定name属性和type属性：在IOC容器中匹配，名字和类型同时匹配则成功，否则失败\n","tags":["java","springboot"],"categories":["java","springboot"]},{"title":"git使用过程中遇到的问题以及解决方法","url":"/2023/04/09/the-usage-of-git/","content":"\n记录了git使用过程中遇到的问题以及解决方法\n\n<!--more-->\n\n### git stash暂存文件\n\n当前分支还未完成所有的工作，然而又需要切换分支或者不能继续工作，可以采用`git stash`命令，切换回来以后再采用`git stash pop`命令切回\n\n在idea 2020版中使用`git stash`命令有几率丢失文件\n\n所以也可以commit 之后再切换分支然后再reset\n\n### git pull拉取分支\n\n在团队开发时，可能出现增加了其他文件和修改统一文件的情况，此时需要`git pull`先合并再push，若不想合并则先fetch\n\n### git pull和git fetch的区别\n\n#### 目的不同\n\n**git fetch**：从远程获取最新版本到本地，但不会自动 merge，用于从远程跟踪分支下载和查看其他人完成的最新提交，但不将这些提交合并到本地存储库中。它从远程存储库中获取更改并将其存储在本地存储库中。\n\n**git pull**：从远程获取最新版本并 merge 到本地，它会自动将提交合并到您的本地存储库中，而无需查看提交。\n\n#### 用途不同\n\n**git fetch**：Fetch 只是通过将提交从远程存储库传输到本地存储库来使远程存储库的本地副本保持最新。将提交导入到本地分支将允许您跟上其他人所做的更改。\n\n**git pull**：Pull 将更改引入本地代码存储库，以使用远程存储库更新本地存储库。\n\n#### 用法不同\n\n**git fetch**：当您想要查看其他人正在处理的内容时，Fetch 命令非常有用，这使您可以在将更改与本地存储库集成之前轻松查看其他开发人员推送的提交。您可以通过使用命令“git fetch ”来做到这一点，该命令从远程存储库中获取所有分支。\n\n**git pull**：您可以使用命令“git pull ”来执行拉取，该命令检索分支的远程副本并将其与本地副本合并。这与使用命令“git fetch ”后跟“git merge ”完全相同。\n\n#### 远端跟踪分支不同\n\n**git fetch**：Git fetch能够直接更改远端跟踪分支。\n\n**git pull**：git pull无法直接对远程跟踪分支操作，我们必须先切回本地分支然后创建一个新的commit提交。\n\n### 使用 git revert 回滚某次的提交\n\n想象这么一个场景，你的项目最近有2个版本要上线，这两个版本还伴随着之前遗留的 bug 的修复，一开始的时候，你将 bug 修复在了第一个版本的 release 分支上，突然在发版前一天，测试那边反馈，需要把第一个版本修复 bug 的内容改在第二个版本上，这个时候，第一个版本的集成分支的提交应该包括了第一个版本的功能内容，遗留 bug 修复的提交和其他同事提交的内容，想要通过 reset 的方式粗暴摘除之前的关于 bug 修复的 commit 肯定是不行的，同时，这种做法比较危险，此时，我们既不想破坏之前的提交记录，又想撤回我们遗留 bug 的 commit 记录应该怎么做呢？git revert 就派上了用场。\n\n `git revert <commit-id>` 针对普通 commit\n\n`git revert <commit-id> -m` 针对 merge 的 commit\n\n下面就用一个案例来理解一下这个命令，如下图所示，假设被红框框起来的地方是会引起 bug 的一次提交，在他的提交之后，又进行了2次提交，其中包含了其它同事的提交。\n\n![image-20210519142702752.png](the-usage-of-git/f36331158e084072a033802bf4fa0478tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp)\n\n此时想把引起提交的 bug 的干掉，执行 `git revert 1121932`，执行操作后，再打开查看日志，如下图所示，可以看到是新增了一条 commit 记录，这个 commit 的产生的 msg 是自动生成的，Revert 开头，后面跟撤回的 commit-msg 信息 之前的 commit 记录并没有消失，此时也达到了代码回退的效果\n\n![image-20210519142824836.png](the-usage-of-git/9729e537218e4609b54df3e899fd332ftplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp)\n\n此外 git revert 也可以回滚多次的提交\n\n语法：`git revert [commit-id1] [commit-id2] ...`  注意这是一个前开后闭区间，即不包括 commit1 ，但包括 commit2 。\n\n回滚我们的提交有二种方式，一种是上文提到的`git revert`命令外，还可以使用 `git reset` 命令，那么它们两者有什么区别呢？\n\n`git revert` 会新建一条 commit 信息，来撤回之前的修改。\n\n`git reset` 会直接将提交记录退回到指定的 commit 上。\n\n对于个人的 feature 分支而言，可以使用 `git reset` 来回退历史记录，之后使用 `git push --force` 进行推送到远程，但是如果是在多人协作的集成分支上，不推荐直接使用 `git reset` 命令，而是使用更加安全的 `git revert` 命令进行撤回提交。这样，提交的历史记录不会被抹去，可以安全的进行撤回。\n","tags":["git"],"categories":["git"]},{"title":"使用go实现一个简单的高性能RPC","url":"/2023/04/02/implment-a-high-performance-rpc-with-go/","content":"\nRPC是远程过程调用（**Remote Procedure Call**）的缩写形式。RPC调用的原理其实很简单，它类似于三层构架的C/S系统，第三方的客户程序通过接口调用RPC内部的标准或自定义函数，获得函数返回的数据进行处理后显示或打印。\n\n<!--more-->\n\n[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc) 是基于Go语言标准库 **net/rpc** 扩展的远程过程调用框架，它具有以下特性：\n\n- 基于TCP传输层协议\n- 支持多种**压缩格式**：gzip、snappy、zlib；\n- 基于二进制的 **Protocol Buffer** 序列化协议：具有协议编码小及高扩展性和跨平台性；\n- 支持生成工具：TinyRPC提供的 **protoc-gen-tinyrpc** 插件可以帮助开发者快速定义自己的服务；\n- 支持自定义序列化器\n\n[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc) 的源代码仅有一千行左右，通过学习 **TinyRPC** ，开发者可以得到以下收获：\n\n- 代码简洁规范\n- 涵盖大多数 Go 语言基础用法和高级特性\n- 单元测试编写技巧\n- TCP流中处理数据包的技巧\n- RPC框架的设计理念\n\n## 基于TCP的TinyRPC协议\n\n在TinyRPC中，请求消息由TinyRPC客户端的应用程序发出，在TCP的字节流中，请求消息分为三部分：\n\n- 由可变长量编码的 **uint 类型**用来标识请求头的长度；\n- 基于自定义协议编码的请求头部信息\n- 基于 **Protocol Buffer** 协议编码的请求体，见图所示：\n\n![img](implment-a-high-performance-rpc-with-go/v2-62b7995089963eb1477a66476c18f3f3_b.jpg)\n\n在TinyRPC中，响应消息由TinyRPC服务端的应用程序响应，在TCP的字节流中，响应消息分为三部分：\n\n- 由可变长量编码的 **uint 类型**用来标识响应头的长度；\n- 基于自定义协议编码的响应头部信息\n- 基于 **Protocol Buffer** 协议编码的响应体，见图所示：\n\n![img](implment-a-high-performance-rpc-with-go/v2-512d68763da8ca61ebbaa6735485a768_b.jpg)\n\n其中ID为RPC调用的序号，以便在并发调用时，客户端根据响应的ID序号来判断RPC的调用结果；\n\nError message为调用时发生错误的消息，若该内容为空则表示未出现RPC调用错误；\n\n在请求I/O流中，请求体（Request Body）表示RPC的参数内容；而在响应I/O流中，响应体（Response Body）则表示RPC调用的结果，这些Body在TinyRPC中均采用 **Protocol Buffer** 协议编码。\n\n## 请求头部消息编码\n\n由于[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc)的请求头部是自定义协议编码的，我们可以查看文件[header/header.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/header/header.go)了解它的细节：\n\n```go\n// CompressType type of compressions supported by rpc\ntype CompressType uint16\n\n// RequestHeader request header structure looks like:\n// +--------------+----------------+----------+------------+----------+\n// | CompressType |      Method    |    ID    | RequestLen | Checksum |\n// +--------------+----------------+----------+------------+----------+\n// |    uint16    | uvarint+string |  uvarint |   uvarint  |  uint32  |\n// +--------------+----------------+----------+------------+----------+\ntype RequestHeader struct {\n        sync.RWMutex\n\tCompressType CompressType  // 它表示RPC的协议内容的压缩类型，TinyRPC支持四种压缩类型，Raw、Gzip、Snappy、Zlib\n\tMethod       string  // 方法名\n\tID           uint64  // 请求ID\n\tRequestLen   uint32  // 请求体长度\n\tChecksum     uint32  // 请求体校验 使用CRC32摘要算法\n}\n```\n\n其中 RequestHeader 的编解码过程如下所示：\n\n```go\n\n// Marshal will encode request header into a byte slice\nfunc (r *RequestHeader) Marshal() []byte {\n        r.RLock()\n\tdefer r.RUnlock()\n\tidx := 0\n\theader := make([]byte, MaxHeaderSize+len(r.Method))\n        // 写入uint16类型的压缩类型\n\tbinary.LittleEndian.PutUint16(header[idx:], uint16(r.CompressType))\n\tidx += Uint16Size\n        \n\tidx += writeString(header[idx:], r.Method)\n\tidx += binary.PutUvarint(header[idx:], r.ID)  // 写入uvarint类型的请求ID号\n\tidx += binary.PutUvarint(header[idx:], uint64(r.RequestLen)) // 写入uvarint类型的请求体长度\n\n\tbinary.LittleEndian.PutUint32(header[idx:], r.Checksum)  // 写入uvarint类型的校验码\n\tidx += Uint32Size\n\treturn header[:idx]\n}\n\n// Unmarshal will decode request header into a byte slice\nfunc (r *RequestHeader) Unmarshal(data []byte) (err error) {\n\tr.Lock()\n\tdefer r.Unlock()\n        if len(data) == 0 {\n\t\treturn UnmarshalError\n\t}\n\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = UnmarshalError\n\t\t}\n\t}()\n\tidx, size := 0, 0\n\tr.CompressType = CompressType(binary.LittleEndian.Uint16(data[idx:]))\n\tidx += Uint16Size // 读取uint16类型的压缩类型\n\n\tr.Method, size = readString(data[idx:])\n\tidx += size\n\n\tr.ID, size = binary.Uvarint(data[idx:]) // 读取uvarint类型的请求ID号\n\tidx += size\n\n\tlength, size := binary.Uvarint(data[idx:])   // 读取uvarint类型的请求体长度\n\tr.RequestLen = uint32(length)\n\tidx += size\n\n\tr.Checksum = binary.LittleEndian.Uint32(data[idx:]) // 读取uvarint类型的校验码\n\treturn\n}\n\nfunc readString(data []byte) (string, int) {\n\tidx := 0\n\tlength, size := binary.Uvarint(data)  // 读取一个uvarint类型表示字符的长度\n\tidx += size\n\tstr := string(data[idx : idx+int(length)])\n\tidx += len(str)\n\treturn str, idx\n}\n\nfunc writeString(data []byte, str string) int {\n\tidx := 0\n\tidx += binary.PutUvarint(data, uint64(len(str)))  // 写入一个uvarint类型表示字符长度\n\tcopy(data[idx:], str)\n\tidx += len(str)\n\treturn idx\n}\n```\n\n## 响应头部消息编码\n\n由于[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc)的响应头部是自定义协议编码的，我们可以查看文件[header/header.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/header/header.go)了解它的细节：\n\n```go\n// ResponseHeader request header structure looks like:\n// +--------------+---------+----------------+-------------+----------+\n// | CompressType |    ID   |      Error     | ResponseLen | Checksum |\n// +--------------+---------+----------------+-------------+----------+\n// |    uint16    | uvarint | uvarint+string |    uvarint  |  uint32  |\n// +--------------+---------+----------------+-------------+----------+\ntype ResponseHeader struct {\n        sync.RWMutex\n\tCompressType CompressType  // 压缩类型\n\tID           uint64  // 响应ID号\n\tError        string  // 错误信息\n\tResponseLen  uint32  // 响应体长度\n\tChecksum     uint32  // 响应体校验码\n}\n```\n\n其中 ResponseHeader 的编解码过程如下所示，与RequestHeader 的编解码过程类似：\n\n```go\n\n// Marshal will encode response header into a byte slice\nfunc (r *ResponseHeader) Marshal() []byte {\n        r.RLock()\n\tdefer r.RUnlock()\n\tidx := 0\n\theader := make([]byte, MaxHeaderSize+len(r.Error))\n\n\tbinary.LittleEndian.PutUint16(header[idx:], uint16(r.CompressType))\n\tidx += Uint16Size\n\n\tidx += binary.PutUvarint(header[idx:], r.ID)\n\tidx += writeString(header[idx:], r.Error)\n\tidx += binary.PutUvarint(header[idx:], uint64(r.ResponseLen))\n\n\tbinary.LittleEndian.PutUint32(header[idx:], r.Checksum)\n\tidx += Uint32Size\n\treturn header[:idx]\n}\n\n// Unmarshal will decode response header into a byte slice\nfunc (r *ResponseHeader) Unmarshal(data []byte) (err error) {\n        r.Lock()\n\tdefer r.Unlock()\n\tif len(data) == 0 {\n\t\treturn UnmarshalError\n\t}\n\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = UnmarshalError\n\t\t}\n\t}()\n\tidx, size := 0, 0\n\tr.CompressType = CompressType(binary.LittleEndian.Uint16(data[idx:]))\n\tidx += Uint16Size\n\n\tr.ID, size = binary.Uvarint(data[idx:])\n\tidx += size\n\n\tr.Error, size = readString(data[idx:])\n\tidx += size\n\n\tlength, size := binary.Uvarint(data[idx:])\n\tr.ResponseLen = uint32(length)\n\tidx += size\n\n\tr.Checksum = binary.LittleEndian.Uint32(data[idx:])\n\treturn\n}\n```\n\n## 头部消息对象池\n\n为了减少创建请求头部对象 **RequestHeader** 和响应头部对象 **ResponseHeader** 的次数**，**我们通过为这两个结构体建立对象池，以便可以进行复用。\n\n同时我们为 *RequestHeader* 和 *ResponseHeader* 都实现了ResetHeader方法，当每次使用完这些对象时，我们调用ResetHeader让结构体内容初始化，随后再把它们丢回对象池里。\n\n代码 [header/pool.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/header/pool.go) 如下：\n\n```go\n\npackage header\n\nimport \"sync\"\n\nvar (\n\tRequestPool  sync.Pool\n\tResponsePool sync.Pool\n)\n\nfunc init() {\n\tRequestPool = sync.Pool{New: func() any {\n\t\treturn &RequestHeader{}\n\t}}\n\tResponsePool = sync.Pool{New: func() any {\n\t\treturn &ResponseHeader{}\n\t}}\n}\n\n// ResetHeader reset request header\nfunc (h *RequestHeader) ResetHeader() {\n\th.Id = 0\n\th.Checksum = 0\n\th.Method = \"\"\n\th.CompressType = 0\n\th.RequestLen = 0\n}\n\n// ResetHeader reset response header\nfunc (h *ResponseHeader) ResetHeader() {\n\th.Error = \"\"\n\th.Id = 0\n\th.CompressType = 0\n\th.Checksum = 0\n\th.ResponseLen = 0\n}\n```\n\n## IO操作\n\nTinyRPC的IO操作函数在[codec/io.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/codec/io.go)中，其中 *sendFrame* 函数会向IO中写入**uvarint**类型的 *size* ，表示要发送数据的长度，随后将该字节slice类型的数据 *data* 写入IO流中。\n\n- 若写入数据的长度为 0 ，此时*sendFrame* 函数会向IO流写入uvarint类型的 0 值；\n- 若写入数据的长度大于 0 ，此时*sendFrame* 函数会向IO流写入uvarint类型的 *len(data)* 值，随后将该字节串的数据 data 写入IO流中。\n\n代码如下所示：\n\n```go\nfunc sendFrame(w io.Writer, data []byte) (err error) {\n\tvar size [binary.MaxVarintLen64]byte\n\n\tif data == nil || len(data) == 0 {\n\t\tn := binary.PutUvarint(size[:], uint64(0))\n\t\tif err = write(w, size[:n]); err != nil {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\n\tn := binary.PutUvarint(size[:], uint64(len(data)))\n\tif err = write(w, size[:n]); err != nil {\n\t\treturn\n\t}\n\tif err = write(w, data); err != nil {\n\t\treturn\n\t}\n\treturn\n}\n\nfunc write(w io.Writer, data []byte) error {\n\tfor index := 0; index < len(data); {\n\t\tn, err := w.Write(data[index:])\n\t\tif _, ok := err.(net.Error); !ok {\n\t\t\treturn err\n\t\t}\n\t\tindex += n\n\t}\n\treturn nil\n}\n```\n\n*recvFrame* 函数与*sendFrame* 函数类似，首先会向IO中读入**uvarint**类型的 *size* ，表示要接收数据的长度，随后将该从IO流中读取该 *size* 长度字节串。\n\n> 注意，由于 codec 层会传入一个**bufio**类型的结构体，**bufio**类型实现了有缓冲的IO操作，以便减少IO在用户态与内核态拷贝的次数。\n\n- 若 *recvFrame* 函数从IO流读取**uvarint**类型的 *size* 值大于0，随后 *recvFrame* 将该从IO流中读取该 *size* 长度字节串。\n\n```go\nfunc recvFrame(r io.Reader) (data []byte, err error) {\n\tsize, err := binary.ReadUvarint(r.(io.ByteReader))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif size != 0 {\n\t\tdata = make([]byte, size)\n\t\tif err = read(r, data); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn data, nil\n}\n\nfunc read(r io.Reader, data []byte) error {\n\tfor index := 0; index < len(data); {\n\t\tn, err := r.Read(data[index:])\n\t\tif err != nil {\n\t\t\tif _, ok := err.(net.Error); !ok {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tindex += n\n\t}\n\treturn nil\n}\n```\n\n## TinyRPC的压缩器\n\nTinyRPC的压缩器代码部分很短，RawCompressor、GzipCompressor、SnappyCompressor、ZlibCompressor压缩器均实现了Compressor 接口，代码[compressor/compressor.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/compressor/compressor.go)：\n\n```go\ntype CompressType int32\n\nconst (\n\tRaw CompressType = iota\n\tGzip\n\tSnappy\n\tZlib\n)\n// Compressors 四种压缩器的实现\nvar Compressors = map[CompressType]Compressor{\n\tRaw:    RawCompressor{},\n\tGzip:   GzipCompressor{},\n\tSnappy: SnappyCompressor{},\n\tZlib:   ZlibCompressor{},\n}\n// Compressor 压缩器接口\ntype Compressor interface {\n\tZip([]byte) ([]byte, error)\n\tUnzip([]byte) ([]byte, error)\n}\n\n```\n\n## TinyRPC的序列化器\n\nTinyRPC的序列化器的代码部分也很短，ProtoSerializer实现了Serializer接口，它是基于Protocol Buffer的序列化协议，代码[serializer/serializer.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/serializer/serializer.go)：\n\n```go\ntype SerializeType int32\n\ntype Serializer interface {\n\tMarshal(message any) ([]byte, error)\n\tUnmarshal(data []byte, message any) error\n}\n```\n\n## 实现ClientCodec接口\n\n由于TinyRPC是**基于标准库net/rpc**扩展的，所以TinyRPC在codec层需要实现**net/rpc**的**ClientCodec**接口，我们先看看**ClientCodec**的代码：\n\n```go\n// 文件 src/net/rpc/server.go\n\ntype ClientCodec interface {\n\tWriteRequest(*Request, any) error\n\tReadResponseHeader(*Response) error\n\tReadResponseBody(any) error\n\n\tClose() error\n}\n// Request 标准库里的请求体结构\ntype Request struct {\n\tServiceMethod string \n\tSeq           uint64 \n\tnext          *Request \n}\n// Response 标准库里的响应结构\ntype Response struct {\n\tServiceMethod string \n\tSeq           uint64 \n\tError         string \n\tnext          *Response \n}\n```\n\n其中ClientCodec接口包括**写请求**、**读响应头部**和**读响应体**，我们建立一个clientCode的结构体用来实现ClientCodec接口：\n\n代码 [codec/client.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/codec/client.go) 如下：\n\n```go\ntype clientCodec struct {\n\tr io.Reader\n\tw io.Writer\n\tc io.Closer\n\n\tcompressor compressor.CompressType // rpc compress type(raw,gzip,snappy,zlib)\n\tserializer serializer.Serializer\n\tresponse   header.ResponseHeader // rpc response header\n\tmutex      sync.Mutex            // protect pending map\n\tpending    map[uint64]string\n}\n```\n\n其中 *compressor* 表示压缩类型，*serializer* 表示使用的序列化器，*response* 是响应的头部，*mutex* 是用于保护 *pending* 的互斥锁；\n\n```go\n// NewClientCodec Create a new client codec\nfunc NewClientCodec(conn io.ReadWriteCloser,\n\tcompressType compressor.CompressType, serializer serializer.Serializer) rpc.ClientCodec {\n\n\treturn &clientCodec{\n\t\tr:          bufio.NewReader(conn),\n\t\tw:          bufio.NewWriter(conn),\n\t\tc:          conn,\n\t\tcompressor: compressType,\n\t\tserializer: serializer,\n\t\tpending:    make(map[uint64]string),\n\t}\n}\n```\n\n这里的读写IO分别使用 *bufio.NewReader* 和 *bufio.NewWriter* 构造，通过缓冲IO来提高RPC的读写性能；\n\n首先 *clientCode* 结构体实现了 ***ClientCodec*** 接口的***WriteRequest*** 方法：\n\n```go\nfunc (c *clientCodec) WriteRequest(r *rpc.Request, param any) error {\nc.mutex.Lock()\n\tc.pending[r.Seq] = r.ServiceMethod\n\tc.mutex.Unlock()\n          // 判断压缩器是否存在\n\tif _, ok := compressor.Compressors[c.compressor]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n\treqBody, err := c.serializer.Marshal(param) // 用序列化器进行编码\n\tif err != nil {\n\t\treturn err\n\t}\n        // 压缩\n\tcompressedReqBody, err := compressor.Compressors[c.compressor].Zip(reqBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 从请求头部对象池取出请求头\n\th := header.RequestPool.Get().(*header.RequestHeader)\n\tdefer func() {\n\t\th.ResetHeader()\n\t\theader.RequestPool.Put(h)\n\t}()\n\th.ID = r.Seq\n\th.Method = r.ServiceMethod\n\th.RequestLen = uint32(len(compressedReqBody))\n\th.CompressType = header.CompressType(c.compressor)\n\th.Checksum = crc32.ChecksumIEEE(compressedReqBody)\n        // 发送请求头\n\tif err := sendFrame(c.w, h.Marshal()); err != nil {\n\t\treturn err\n\t}\n        // 发送请求体\n\tif err := write(c.w, compressedReqBody); err != nil {\n\t\treturn err\n\t}\n\n\tc.w.(*bufio.Writer).Flush()\n\treturn nil\t\n}\n```\n\n实现 ***ClientCodec\\*** 接口的 ***ReadResponseHeader\\*** 方法：\n\n```go\nfunc (c *clientCodec) ReadResponseHeader(r *rpc.Response) error {\n        c.response.ResetHeader() // 重置clientCodec的响应头部\n\tdata, err := recvFrame(c.r) // 读取请求头字节串  \n\tif err != nil {\n\t\treturn err\n\t}\n\terr = c.response.Unmarshal(data) // 用序列化器继续解码\n\tif err != nil {\n\t\treturn err\n\t}\n\tc.mutex.Lock()\n\tr.Seq = c.response.ID // 填充 r.Seq  \n\tr.Error = c.response.Error // 填充 r.Error\n\tr.ServiceMethod = c.pending[r.Seq]  // 根据序号填充 r.ServiceMethod\n\tdelete(c.pending, r.Seq) // 删除pending里的序号  \n\tc.mutex.Unlock()\n\treturn nil\t\n}\n```\n\n实现 ***ClientCodec\\*** 接口的 ***ReadResponseBody\\*** 方法：\n\n```go\n\nfunc (c *clientCodec) ReadResponseBody(param any) error {\n        if param == nil {\n\t\tif c.response.ResponseLen != 0 {   // 废弃多余部分\n\t\t\tif err := read(c.r, make([]byte, c.response.ResponseLen)); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n        // 根据响应体长度，读取该长度的字节串\n\trespBody := make([]byte, c.response.ResponseLen)\n\terr := read(c.r, respBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 校验\n\tif c.response.Checksum != 0 {\n\t\tif crc32.ChecksumIEEE(respBody) != c.response.Checksum {\n\t\t\treturn UnexpectedChecksumError\n\t\t}\n\t}\n        // 判断压缩器是否存在\n\tif _, ok := compressor.Compressors[c.response.GetCompressType()]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n        // 解压\n\tresp, err := compressor.Compressors[c.response.GetCompressType()].Unzip(respBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 反序列化\n\treturn c.serializer.Unmarshal(resp, param)\n}\n```\n\n## 实现ServerCodec接口\n\nTinyRPC在codec层还需要实现**net/rpc**的**ServerCodec**接口\n\n*ServerCodec* 的接口和 *ClientCodec* 接口十分类似：\n\n```go\ntype ServerCodec interface {\n\tReadRequestHeader(*Request) error\n\tReadRequestBody(any) error\n\tWriteResponse(*Response, any) error\n\tClose() error\n}\n```\n\n其中 *ServerCodec* 接口包括**写响应**、**读请求头部**和**读请求体**，我们建立一个 *serverCodec* 的结构体用来实现 *ServerCodec* 接口，代码[codec/server.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/codec/server.go)：\n\n```go\ntype serverCodec struct {\n\tr io.Reader\n\tw io.Writer\n\tc io.Closer\n\n\trequest    header.RequestHeader\n\tserializer serializer.Serializer\n\tmutex      sync.Mutex // protects seq, pending\n\tseq        uint64\n\tpending    map[uint64]uint64\n}\n\n// NewServerCodec Create a new server codec\nfunc NewServerCodec(conn io.ReadWriteCloser, serializer serializer.Serializer) rpc.ServerCodec {\n\treturn &serverCodec{\n\t\tr:          bufio.NewReader(conn),\n\t\tw:          bufio.NewWriter(conn),\n\t\tc:          conn,\n\t\tserializer: serializer,\n\t\tpending:    make(map[uint64]uint64),\n\t}\n}\n```\n\n是不是和刚才的 *clientCode* 结构体**神似**？\n\n首先， *serverCodec* 结构体实现了 *ServerCodec* 接口的 *ReadRequestHeader*方法：\n\n```go\nfunc (s *serverCodec) ReadRequestHeader(r *rpc.Request) error {\n\ts.request.ResetHeader()  // 重置serverCodec结构体的请求头部\n\tdata, err := recvFrame(s.r) // 读取请求头部字节串\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = s.request.Unmarshal(data)   //将字节串反序列化\n\tif err != nil {\n\t\treturn err\n\t}\n\ts.mutex.Lock()\n\ts.seq++  // 序号自增\n\ts.pending[s.seq] = s.request.ID // 自增序号与请求头部的ID进行绑定\n\tr.ServiceMethod = s.request.Method  // 填充 r.ServiceMethod \n\tr.Seq = s.seq// 填充 r.Seq  \n\ts.mutex.Unlock()\n\treturn nil\t\n}\n```\n\n实现 *ServerCodec* 接口的 *ReadRequestBody* 方法：\n\n```go\nfunc (s *serverCodec) ReadRequestBody(x any) error {\n       if param == nil { \n\t\tif s.request.RequestLen != 0 {  // 废弃多余部分\n\t\t\tif err := read(s.r, make([]byte, s.request.RequestLen)); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\treqBody := make([]byte, s.request.RequestLen)\n        // 根据请求体的大小，读取该大小的字节串\n\terr := read(s.r, reqBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 校验\n\tif s.request.Checksum != 0 {\n\t\tif crc32.ChecksumIEEE(reqBody) != s.request.Checksum {\n\t\t\treturn UnexpectedChecksumError\n\t\t}\n\t}\n         // 判断压缩器是否存在\n\tif _, ok := compressor.\n\t\tCompressors[s.request.GetCompressType()]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n        // 解压\n\treq, err := compressor.\n\t\tCompressors[s.request.GetCompressType()].Unzip(reqBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 把字节串反序列化\n\treturn s.serializer.Unmarshal(req, param)\n}\n```\n\n实现 *ServerCodec* 接口的 *WriteResponse* 方法：\n\n```go\nfunc (s *serverCodec) WriteResponse(r *rpc.Response, param any) error {\n\ts.mutex.Lock()\n\tid, ok := s.pending[r.Seq]\n\tif !ok {\n\t\ts.mutex.Unlock()\n\t\treturn InvalidSequenceError\n\t}\n\tdelete(s.pending, r.Seq)\n\ts.mutex.Unlock()\n\n\tif r.Error != \"\" {   // 如果RPC调用结果有误，把param置为nil\n\t\tparam = nil\n\t}\n         // 判断压缩器是否存在\n\tif _, ok := compressor.\n\t\tCompressors[s.request.GetCompressType()]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n        \n\tvar respBody []byte\n\tvar err error\n\tif param != nil {\n\t\trespBody, err = s.serializer.Marshal(param) // 反序列化\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n        // 压缩\n\tcompressedRespBody, err := compressor.\n\t\tCompressors[s.request.GetCompressType()].Zip(respBody)\n\tif err != nil {\n\t\treturn err\n\t}\n\th := header.ResponsePool.Get().(*header.ResponseHeader)\n\tdefer func() {\n\t\th.ResetHeader()\n\t\theader.ResponsePool.Put(h)\n\t}()\n\th.ID = id\n\th.Error = r.Error\n\th.ResponseLen = uint32(len(compressedRespBody))\n\th.Checksum = crc32.ChecksumIEEE(compressedRespBody)\n\th.CompressType = s.request.CompressType\n        // 发送响应头\n\tif err = sendFrame(s.w, h.Marshal()); err != nil {\n\t\treturn err\n\t}\n        // 发送响应体\n\tif err = write(s.w, compressedRespBody); err != nil {\n\t\treturn err\n\t}\n\ts.w.(*bufio.Writer).Flush()\n\treturn nil\n}\n```\n\n## TinyRPC的Server\n\nTinyRPC的服务端非常简单，把标准库 **net/rpc** 的 **Server** 结构包装了一层，其中 *ServeCodec* 使用的是TinyRPC的编解码器，代码[server.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/server.go)：\n\n```go\ntype Server struct {\n\t*rpc.Server\n\tserializer.Serializer\n}\n\n...\n\nfunc (s *Server) Serve(lis net.Listener) {\n\tfor {\n\t\tconn, err := lis.Accept()\n\t\tif err != nil {\n\t\t\tlog.Print(\"tinyrpc.Serve: accept:\", err.Error())\n\t\t\treturn\n\t\t}\n\t\tgo s.Server.ServeCodec(codec.NewServerCodec(conn, s.Serializer)))  // 使用TinyRPC的解码器\n\t}\n}\n```\n\n## TinyRPC的Client\n\nTinyRPC的客户端也很简单，把标准库 **net/rpc** 的 **Client** 结构包装了一层，其中 *ClientCodec* 使用的是TinyRPC的编解码器，代码[client.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/client.go)：\n\n> 注意：TinyRPC Client使用一种Go语言常用的设计模式：功能选项模式\n\n```go\n// Client rpc client based on net/rpc implementation\ntype Client struct {\n\t*rpc.Client\n}\n\n//Option provides options for rpc\ntype Option func(o *options)\n\ntype options struct {\n\tcompressType compressor.CompressType\n\tserializer   serializer.Serializer\n}\n\n// WithCompress set client compression format\nfunc WithCompress(c compressor.CompressType) Option {\n\treturn func(o *options) {\n\t\to.compressType = c\n\t}\n}\n\n// WithSerializer set client serializer\nfunc WithSerializer(serializer serializer.Serializer) Option {\n\treturn func(o *options) {\n\t\to.serializer = serializer\n\t}\n}\n\n// NewClient Create a new rpc client\nfunc NewClient(conn io.ReadWriteCloser, opts ...Option) *Client {\n\toptions := options{\n\t\tcompressType: compressor.Raw,\n\t\tserializer:   serializer.Proto,\n\t}\n\tfor _, option := range opts {\n\t\toption(&options)\n\t}\n\treturn &Client{rpc.NewClientWithCodec(\n\t\tcodec.NewClientCodec(conn, options.compressType, options.serializer))}\n}\n\n// Call synchronously calls the rpc function\nfunc (c *Client) Call(serviceMethod string, args interface{}, reply interface{}) error {\n\treturn c.Client.Call(serviceMethod, args, reply)\n}\n\n// AsyncCall asynchronously calls the rpc function and returns a channel of *rpc.Call\nfunc (c *Client) AsyncCall(serviceMethod string, args interface{}, reply interface{}) chan *rpc.Call {\n\treturn c.Go(serviceMethod, args, reply, nil).Done\n}\n```\n\n作者：马丸子\n链接：https://zhuanlan.zhihu.com/p/499098284\n来源：知乎\n","tags":["go"],"categories":["go"]},{"title":"how to fix Incorrect credentials. Request response. 401 Unauthorized","url":"/2023/03/23/how-to-fix-Incorrect-credentials-Request-response-401-Unauthorized/","content":"\n使用GitHub生成的token登录idea时，无法登录，报了如标题错误\n\n<!--more-->\n\n这是因为生成token时未勾选相应的权限\n\n请务必勾选以下权限\n\n```\nrepo - select everything\ngist - select everything\norg - select only read:org\n```\n\n勾选以后即可使用GitHub登录idea了\n","tags":["debug","git"],"categories":["debug"]},{"title":"redis实战:短信登录","url":"/2023/03/21/redis-in-action-SMS-login/","content":"\n本文介绍了如何使用session进行登录及其缺点，以及如何用redis对缺点进行改进\n\n<!--more-->\n\n## 基于session实现登录流程\n\n### **发送验证码：**\n\n用户在提交手机号后，会校验手机号是否合法，如果不合法，则要求用户重新输入手机号\n\n如果手机号合法，后台此时生成对应的验证码，同时将验证码进行保存，然后再通过短信的方式将验证码发送给用户\n\n### **短信验证码登录、注册：**\n\n用户将验证码和手机号进行输入，后台从 session 中拿到当前验证码，然后和用户输入的验证码进行校验，如果不一致，则无法通过校验，如果一致，则后台根据手机号查询用户，如果用户不存在，则为用户创建账号信息，保存到数据库，无论是否存在，都会将用户信息保存到 session 中，方便后续获得当前登录信息\n\n### **校验登录状态:**\n\n用户在请求时候，会从 cookie 中携带sessionId 到后台，后台通过 sessionId 从 session 中拿到用户信息，如果没有 session 信息，则进行拦截，如果有 session 信息，则将用户信息保存到 threadLocal 中，并且放行\n\n![登录流程](redis-in-action-SMS-login/登录流程.png)\n\n## 实现发送短信验证码功能\n\n![短信验证码](redis-in-action-SMS-login/短信验证码.png)\n\n代码如下：\n\n```\n    @Override\n    public Result sendCode(String phone, HttpSession session) {\n        // 1.校验手机号\n        if (RegexUtils.isPhoneInvalid(phone)) {\n            // 2.如果不符合，返回错误信息\n            return Result.fail(\"手机号格式错误！\");\n        }\n        // 3.符合，生成验证码\n        String code = RandomUtil.randomNumbers(6);\n \n        // 4.保存验证码到 session\n        session.setAttribute(\"code\",code);\n        // 5.发送验证码\n        log.debug(\"发送短信验证码成功，验证码：{}\", code);\n        // 返回ok\n        return Result.ok();\n    }\n```\n\n登录：\n\n```\n    @Override\n    public Result login(LoginFormDTO loginForm, HttpSession session) {\n        // 1.校验手机号\n        String phone = loginForm.getPhone();\n        if (RegexUtils.isPhoneInvalid(phone)) {\n            // 2.如果不符合，返回错误信息\n            return Result.fail(\"手机号格式错误！\");\n        }\n        // 3.校验验证码\n        Object cacheCode = session.getAttribute(\"code\");\n        String code = loginForm.getCode();\n        if(cacheCode == null || !cacheCode.toString().equals(code)){\n             //3.不一致，报错\n            return Result.fail(\"验证码错误\");\n        }\n        //一致，根据手机号查询用户\n        User user = query().eq(\"phone\", phone).one();\n \n        //5.判断用户是否存在\n        if(user == null){\n            //不存在，则创建\n            user =  createUserWithPhone(phone);\n        }\n        //7.保存用户信息到session中\n        session.setAttribute(\"user\",user);\n \n        return Result.ok();\n    }\n```\n\n## 实现登录拦截功能\n\n![登录拦截](redis-in-action-SMS-login/登录拦截.png)\n\n当用户发起请求时，会访问我们像 tomcat 注册的端口，任何程序想要运行，都需要有一个线程对当前端口号进行监听，tomcat 也不例外，当监听线程知道用户想要和 tomcat 连接连接时，那会由监听线程创建 socket 连接，socket 都是成对出现的，用户通过 socket 像互相传递数据，当 tomcat 端的 socket 接受到数据后，此时监听线程会从 tomcat 的线程池中取出一个线程执行用户请求，在我们的服务部署到 tomcat 后，线程会找到用户想要访问的工程，然后用这个线程转发到工程中的 controller，service，dao 中，并且访问对应的 DB，在用户执行完请求后，再统一返回，再找到 tomcat 端的 socket，再将数据写回到用户端的 socket，完成请求和响应\n\n通过以上讲解，我们可以得知 每个用户其实对应都是去找 tomcat 线程池中的一个线程来完成工作的， 使用完成后再进行回收，既然每个请求都是独立的，所以在每个用户去访问我们的工程时，我们可以使用 threadlocal 来做到线程隔离，每个线程操作自己的一份数据\n\n**温馨小贴士：关于 threadlocal**\n\n如果小伙伴们看过 threadLocal 的源码，你会发现在 threadLocal 中，无论是他的 put 方法和他的 get 方法， 都是先从获得当前用户的线程，然后从线程中取出线程的成员变量 map，只要线程不一样，map 就不一样，所以可以通过这种方式来做到线程隔离\n\n![拦截器处理](redis-in-action-SMS-login/拦截器处理.png)\n\n拦截器代码：\n\n```\npublic class LoginInterceptor implements HandlerInterceptor {\n \n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n       //1.获取session\n        HttpSession session = request.getSession();\n        //2.获取session中的用户\n        Object user = session.getAttribute(\"user\");\n        //3.判断用户是否存在\n        if(user == null){\n              //4.不存在，拦截，返回401状态码\n              response.setStatus(401);\n              return false;\n        }\n        //5.存在，保存用户信息到Threadlocal\n        UserHolder.saveUser((User)user);\n        //6.放行\n        return true;\n    }\n}\n```\n\n使拦截器生效：\n\n```\n@Configuration\npublic class MvcConfig implements WebMvcConfigurer {\n \n    @Resource\n    private StringRedisTemplate stringRedisTemplate;\n \n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        // 登录拦截器\n        registry.addInterceptor(new LoginInterceptor())\n                .excludePathPatterns(\n                        \"/shop/**\",\n                        \"/voucher/**\",\n                        \"/shop-type/**\",\n                        \"/upload/**\",\n                        \"/blog/hot\",\n                        \"/user/code\",\n                        \"/user/login\"\n                ).order(1);\n        // token刷新的拦截器\n        registry.addInterceptor(new RefreshTokenInterceptor(stringRedisTemplate)).order(0);\n    }\n}\n```\n\n## 隐藏用户敏感信息\n\n我们通过浏览器观察到此时用户的全部信息都在，这样极为不靠谱，所以我们应当在返回用户信息之前，将用户的敏感信息进行隐藏，采用的核心思路就是书写一个 UserDto 对象，这个 UserDto 对象就没有敏感信息了，我们在返回前，将有用户敏感信息的 User 对象转化成没有敏感信息的 UserDto 对象，那么就能够避免这个尴尬的问题了\n\n```\n//7.保存用户信息到session中\nsession.setAttribute(\"user\", BeanUtils.copyProperties(user,UserDTO.class));\n```\n\n**在拦截器处：**\n\n```\n//5.存在，保存用户信息到Threadlocal\nUserHolder.saveUser((UserDTO) user);\n```\n\n**在 UserHolder 处：将 user 对象换成 UserDTO**\n\n```\n\tpublic class UserHolder {\n    private static final ThreadLocal<UserDTO> tl = new ThreadLocal<>();\n \n    public static void saveUser(UserDTO user){\n        tl.set(user);\n    }\n \n    public static UserDTO getUser(){\n        return tl.get();\n    }\n \n    public static void removeUser(){\n        tl.remove();\n    }\n}\n```\n\n## session 共享问题\n\n**核心思路分析：**\n\n每个 tomcat 中都有一份属于自己的 session, 假设用户第一次访问第一台 tomcat，并且把自己的信息存放到第一台服务器的 session 中，但是第二次这个用户访问到了第二台 tomcat，那么在第二台服务器上，肯定没有第一台服务器存放的 session，所以此时 整个登录拦截功能就会出现问题，我们能如何解决这个问题呢？早期的方案是 session 拷贝，就是说虽然每个 tomcat 上都有不同的 session，但是每当任意一台服务器的 session 修改时，都会同步给其他的 Tomcat 服务器的 session，这样的话，就可以实现 session 的共享了\n\n但是这种方案具有两个大问题\n\n1、每台服务器中都有完整的一份 session 数据，服务器压力过大。\n\n2、session 拷贝数据时，可能会出现延迟\n\n所以咱们后来采用的方案都是基于 redis 来完成，我们把 session 换成 redis，redis 数据本身就是共享的，就可以避免 session 共享的问题了\n\n![session共享](redis-in-action-SMS-login/session共享.png)\n\n## Redis 代替 session 的业务流程\n\n### 设计 key 的结构\n\n首先我们要思考一下利用 redis 来存储数据，那么到底使用哪种结构呢？由于存入的数据比较简单，我们可以考虑使用 String，或者是使用哈希，如下图，如果使用 String，同学们注意他的 value，用多占用一点空间，如果使用哈希，则他的 value 中只会存储他数据本身，如果不是特别在意内存，其实使用 String 就可以啦。\n\n![redis设计key](redis-in-action-SMS-login/redis设计key.png)\n\n### 设计 key 的具体细节\n\n所以我们可以使用 String 结构，就是一个简单的 key，value 键值对的方式，但是关于 key 的处理，session 他是每个用户都有自己的 session，但是 redis 的 key 是共享的，咱们就不能使用 code 了\n\n在设计这个 key 的时候，我们之前讲过需要满足两点\n\n1、key 要具有唯一性\n\n2、key 要方便携带\n\n如果我们采用 phone：手机号这个的数据来存储当然是可以的，但是如果把这样的敏感数据存储到 redis 中并且从页面中带过来毕竟不太合适，所以我们在后台生成一个随机串 token，然后让前端带来这个 token 就能完成我们的整体逻辑了\n\n### 整体访问流程\n\n当注册完成后，用户去登录会去校验用户提交的手机号和验证码，是否一致，如果一致，则根据手机号查询用户信息，不存在则新建，最后将用户数据保存到 redis，并且生成 token 作为 redis 的 key，当我们校验用户是否登录时，会去携带着 token 进行访问，从 redis 中取出 token 对应的 value，判断是否存在这个数据，如果没有则拦截，如果存在则将其保存到 threadLocal 中，并且放行。\n\n![共享session登录](redis-in-action-SMS-login/共享session登录.png)\n\n## 基于 Redis 实现短信登录\n\n### 设计 key 的结构\n\n首先我们要思考一下利用 redis 来存储数据，那么到底使用哪种结构呢？由于存入的数据比较简单，我们可以考虑使用 String，或者是使用哈希，如下图，如果使用 String，同学们注意他的 value，用多占用一点空间，如果使用哈希，则他的 value 中只会存储他数据本身，如果不是特别在意内存，其实使用 String 就可以啦。\n\n![使用string结构保存json字符串](redis-in-action-SMS-login/使用string结构保存json字符串.png)\n\n### 设计 key 的具体细节\n\n所以我们可以使用 String 结构，就是一个简单的 key，value 键值对的方式，但是关于 key 的处理，session 他是每个用户都有自己的 session，但是 redis 的 key 是共享的，咱们就不能使用 code 了\n\n在设计这个 key 的时候，我们之前讲过需要满足两点\n\n1、key 要具有唯一性\n\n2、key 要方便携带\n\n如果我们采用 phone：手机号这个的数据来存储当然是可以的，但是如果把这样的敏感数据存储到 redis 中并且从页面中带过来毕竟不太合适，所以我们在后台生成一个随机串 token，然后让前端带来这个 token 就能完成我们的整体逻辑了\n\n### 整体访问流程\n\n当注册完成后，用户去登录会去校验用户提交的手机号和验证码，是否一致，如果一致，则根据手机号查询用户信息，不存在则新建，最后将用户数据保存到 redis，并且生成 token 作为 redis 的 key，当我们校验用户是否登录时，会去携带着 token 进行访问，从 redis 中取出 token 对应的 value，判断是否存在这个数据，如果没有则拦截，如果存在则将其保存到 threadLocal 中，并且放行。\n\n![1653319474181](redis-in-action-SMS-login/1653319474181.png)\n\n## 基于 Redis 实现短信登录\n\n这里具体逻辑就不分析了，之前咱们已经重点分析过这个逻辑啦。\n\n```java\n@Override\npublic Result login(LoginFormDTO loginForm, HttpSession session) {\n    // 1.校验手机号\n    String phone = loginForm.getPhone();\n    if (RegexUtils.isPhoneInvalid(phone)) {\n        // 2.如果不符合，返回错误信息\n        return Result.fail(\"手机号格式错误！\");\n    }\n    // 3.从redis获取验证码并校验\n    String cacheCode = stringRedisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone);\n    String code = loginForm.getCode();\n    if (cacheCode == null || !cacheCode.equals(code)) {\n        // 不一致，报错\n        return Result.fail(\"验证码错误\");\n    }\n \n    // 4.一致，根据手机号查询用户 select * from tb_user where phone = ?\n    User user = query().eq(\"phone\", phone).one();\n \n    // 5.判断用户是否存在\n    if (user == null) {\n        // 6.不存在，创建新用户并保存\n        user = createUserWithPhone(phone);\n    }\n \n    // 7.保存用户信息到 redis中\n    // 7.1.随机生成token，作为登录令牌\n    String token = UUID.randomUUID().toString(true);\n    // 7.2.将User对象转为HashMap存储\n    UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class);\n    Map<String, Object> userMap = BeanUtil.beanToMap(userDTO, new HashMap<>(),\n            CopyOptions.create()\n                    .setIgnoreNullValue(true)\n                    .setFieldValueEditor((fieldName, fieldValue) -> fieldValue.toString()));\n    // 7.3.存储\n    String tokenKey = LOGIN_USER_KEY + token;\n    stringRedisTemplate.opsForHash().putAll(tokenKey, userMap);\n    // 7.4.设置token有效期\n    stringRedisTemplate.expire(tokenKey, LOGIN_USER_TTL, TimeUnit.MINUTES);\n \n    // 8.返回token\n    return Result.ok(token);\n}\n```\n\n","tags":["redis"],"categories":["redis"]},{"title":"爬虫初级使用记录","url":"/2023/03/20/introduction-to-spider/","content":"\n本文记录了爬虫最基础的使用方法，如果只想最快获得网页源码从2.2浏览即可\n\n<!--more-->\n\n## 1、爬虫核心库1：requests库\n\n学习爬虫其实并不太需要了解太多的网页结构知识，作为初学者只需要知道1点：所有想要获取的内容（例如新闻标题/网址/日期/来源等）都在网页源代码里，所谓网页源代码，就是网页背后的编程代码，这一小节我们首先来讲解下如何查看网页源代码，以及通过两个案例快速体验下如何通过requests库获取网页源代码。\n\n### 1.1 如何查看网页源代码\n\n在进入正式爬虫实战前，我们首先来了解下如何查看网页源代码。\n\n网络爬虫首先得有一个浏览器，这里强烈推荐谷歌浏览器（百度搜索谷歌浏览器，然后在官网[https://www.google.cn/chrome/](https://www.google.cn/chrome/)下载，谷歌浏览器默认是谷歌搜索，直接在网址输入框里输入内容可能搜索不到内容，可以在网址栏上输入baidu.com进行访问，或者可以点击浏览器右侧的设置按钮->选择界面左侧的搜索引擎->选择百度搜索引擎）。当然用别的浏览器，比如火狐浏览器等都是可以的，只要它按F12(有的电脑要同时按住左下角的Fn键)能弹出网页源代码即可。\n\n以谷歌浏览器为例来演示下F12的强大作用，百度搜索“阿里巴巴”，然后**按一下F12（有的电脑还得同时按住Fn）**，弹出如下页面，其中点击右侧设置按钮可以切换布局样式。\n\n![image-20230320154143682](introduction-to-spider/image-20230320154143682.png)\n\n这个按住F12弹出来的东西叫做开发者工具，是进行数据挖掘的利器，对于爬虫来说，大多数情况下只需要会用下图的这两个按钮即可。\n\n![img](introduction-to-spider/v2-e64893143d82ba0f5e79621345dea1cf_r.jpg)\n\n第一个按钮箭头形状按钮为**选择**按钮，第二个Elements按钮为**元素**按钮。\n\n**(1)** **选择按钮**\n\n点击一下它，发现它会变成蓝色，然后把鼠标在页面上移动移动，会发现页面上的颜色机会发生改变。如下图所示，当**移动鼠标**的时候，会发现界面上的颜色会发生变化，并且Elements里的内容就会随之发生变化。\n\n![image-20230320154833691](introduction-to-spider/image-20230320154833691.png)\n\n下面当选择按钮处于蓝色状态的时，点击一下第一个链接的标题，这时候选择按钮再次变成灰色，而Elements里的内容也将不再变动，此时便可以观察具体的网页源代码内容了，如下图所示，我们一般只关心里面的所需要的中文内容，如果没有看到中文文本，店家下图所示的三角箭头，即可展开内容，看到中文文本。\n\n![image-20230320155030944](introduction-to-spider/image-20230320155030944.png)\n\n**(2) Elements元素按钮**：\n\nElements元素按钮里面的内容可以理解为**就是网站的源码**，最后爬虫爬到的内容大致就是长这个样子的。下面就要接着完成一些“神奇”的操作。\n\n在下图“**1688”**那个地方鼠标双击俩下，这两个字变成可编辑的格式。\n\n![image-20230320155132398](introduction-to-spider/image-20230320155132398.png)\n\n将其改成“测试”，可以看到第一个的标题发生了改变，如下图所示：\n\n![image-20230320155245952](introduction-to-spider/image-20230320155245952.png)\n\n还可以用同样的操作，修改页面上的其他信息，如股价等。\n\n通过F12启动开发者工具，我们可以对网页结构有一个初步的认识，并可以利用选择按钮和“Elements”元素按钮观察我们想获取的内容在源码中的文本格式以及所在位置。\n\n**补充知识点1：查看网页源码的另一个方式**\n\n除了F12，另一个获取网页源码的方式是在网页上右击选择“**查看网页源代码**”，就可以获取这个网址的源代码，这个基本就是Python爬取到的最终信息。用鼠标上下滚动，就能看到很多内容，同样初学者不需要关心那些英文或者网页框架，只需要知道想获取的中文在哪里即可。\n\n这个方法比F12观察源码的方式更加真实，因为F12观察到的源码可能是被网页修饰过的，通过Python获取到内容可能和F12看到的不一致。通过该方法查看到的源码就是通过Python程序能够获取到的网页源代码。实战中常将两种方法联合使用：通过F12进行初步了解，然后右击查看网页源代码，看看所需内容到底在网页源代码的什么位置，其中可以通过Ctrl + F快捷键搜索所需要的内容。\n\n此外，如果F12看到的内容和通过右击查看网页源代码看到的内容很不一样，这是因为网站做了动态渲染的处理（这是一种反爬处理），这时候就需要用到2.2节selenium库的相关知识点来获取真正的网页源代码。\n\n**补充知识点2：http与https协议**\n\n有的时候我们理解的网址是：[http://www.baidu.com]([http://www.baidu.com)，但其实在编程里或者它真实的名字其实是：[https://www.baidu.com](https://www.baidu.com)，它前面有个“https://”这个叫做https协议，是网址的固定构成形式，某种程度表明这个网址是安全的，有的网址前面则为http://。如果在Python里输入[www.baidu.com](https://link.zhihu.com/?target=http%3A//www.baidu.com/)它是不认识的，得把“https://”加上才行，如下面所示。\n\n```text\nurl = 'https://www.baidu.com/'\n```\n\n其实最简单的办法，**就是直接浏览器访问该网址，然后把链接复制下来就行**。\n\n### 1.2 爬虫初尝试 - requests库获取网页源代码\n\n了解了如何查看网页源代码后，这一小节我们讲解下如何通过requests库爬取网页源代码。这里以一个学校的招聘网站为例。\n\n**（1） 获取网页源代码**\n\n通过第一章最后介绍的requests库来尝试获取下新闻的网页源代码，代码如下：\n\n```python\nimport requests\nurl = 'https://www.163.com/dy/article/I09JUB0P051984TV.html'\nres = requests.get(url).text\nprint(res)\n```\n\n运行后报错：\n\n`requests.exceptions.SSLError: HTTPSConnectionPool`\n\n![image-20230320160811293](introduction-to-spider/image-20230320160811293.png)\n\n这是由于ssl认证失败造成的，我们并不需要知道原因，只要像以下一样禁用ssl认证就可以了。\n\n```python\nimport requests\n\ns = requests.session()\ns.trust_env = False\ns.keep_alive = False\nrequests.DEFAULT_RETRIES = 50\n\nurl = 'https://www.gdpt.edu.cn/al_8/189'\nres = s.get(url).text\nprint(res)\n```\n\n这段代码使requests的连接禁用了ssl认证，不使用keep-alive，并将重连次数增加到了50，如果出现了类似的错误只需要将以上代码复制粘贴即可。运行后得到以下结果。\n\n![image-20230320161701948](introduction-to-spider/image-20230320161701948.png)\n\n这里虽然得到了结果，但是有的网站只认可浏览器发送过去的访问，而不认可直接通过Python发送过去的访问请求，那么该如何解决该问题呢？这时就需要设置下requests.get()中的headers参数，用来模拟浏览器进行访问。\n\n```python\nimport requests\n\ns = requests.session()\ns.trust_env = False\ns.keep_alive = False\nrequests.DEFAULT_RETRIES = 50\n\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 \\\n                    (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1'}\nurl = 'https://www.gdpt.edu.cn/al_8/189'\nres = s.get(url, headers=headers).text\nprint(res)\n```\n\n## 2 爬虫核心库2：selenium库\n\n对比了我想要查询的内容，发现requests爬取的信息不是完整的，这是因为Requests只能获取到HTML文本，而无法获取到JavaScript动态生成的内容。如果div盒子里的内容是通过JavaScript生成的，那么requests就无法获取到。此时就需要使用selenium库了。\n\nSelenium库这一知识点相对比较重要，如果说requests库能够爬取50%的网站的话，那么通过selenium库的话可以爬取95%的网站，大部分较为困难的网址都可以通过其来获取网页源代码。下面我们首先来分析下requests库在一些复杂爬虫中遇到的难点，然后讲解下如何安装selenium库以及如何通过selenium库获取到网页源代码。\n\n### 2.1 requests库遇到的难点\n\n在使用requests库进行爬虫实战时，有时会遇到一大难题：获取不了网页真正的源代码。例如，上海证券交易所的公开信息、新浪财经的股票行情实时数据等，用常规爬虫手段会发现获取到的网页源代码内容很少且没有用。因为这些网页上展示的信息是动态渲染出来的，而通过常规爬虫手段获取的则是未经渲染的信息，所以其中没有我们想要的信息。\n\n以新浪财经的上证综合指数（上证综合指数反映在上海证券交易所全部上市股票价格综合情况）网页（[http://finance.sina.com.cn/realstock/]([http://finance.sina.com.cn/realstock)）为例，在浏览器中按F12 键，可以在网页源代码中看到指数数值。然后用常规爬虫手段，以requests.get(url).text 的方式获取这个网页的源代码，然后按快捷键Ctrl+F，在源代码中搜索刚才看到的指数数值，会发现搜索不到，如下图所示。而且就算加上headers 参数也没有改观。\n\n面对这种动态渲染的网页，在数据挖掘时就需要使用Selenium 库，通过模拟打开一个浏览器访问网址，然后获取渲染后的网页源代码，从而完成requests库难以完成的任务。\n\n| 优点       | 缺点                |                  |\n| ---------- | ------------------- | ---------------- |\n| requests库 | 爬取速度快          | 有些网站爬取不到 |\n| selenium库 | 能爬取95%以上的网站 | 爬取速度较慢     |\n\n### 2.2  Selenium库介绍与安装\n\n正式介绍selenium库之前，得首先先安装一个网页模拟器：ChromeDriver，它的作用是给Pyhton提供一个模拟浏览器，让Python能够运行一个模拟的浏览器进行网页访问，并用selenium进行鼠标及键盘等操作获取到网页真正的源代码。\n\n**(1) 安装Chrome谷歌浏览器**\n\n安装ChromeDriver之前，得先装一下Chrome谷歌浏览器，直接百度搜索谷歌浏览器，然后在官网[https://www.google.cn/chrome/](https://www.google.cn/chrome)下载即可。\n\n**(2) 查看Chrome浏览器版本**\n\n地址栏输入`chrome://version`回车即可\n\n![image-20230320163352932](introduction-to-spider/image-20230320163352932.png)\n\n![image-20230320163501421](introduction-to-spider/image-20230320163501421.png)\n\n**(3) ChromeDriver下载**\n\nChromeDriver官方下载地址：[http://chromedriver.storage.googleapis.com/index.html](http://chromedriver.storage.googleapis.com/index.html)。进入官网后，选择对应自己谷歌浏览器版本的ChromeDriver下载即可。不过由于官网再国内经常访问不了，因此可以在百度上搜索“ChromeDriver下载”，可以找到如下一个镜像下载网站：[http://npm.taobao.org/mirrors/chromedriver/](https://registry.npmmirror.com/binary.html?path=chromedriver/)。\n\n**(4) ChromeDriver环境变量配置**\n\n解压压缩包，找到chromedriver.exe复制到chrome的安装目录（其实也可以随便放一个文件夹,关键是要加入环境变量）。复制chromedriver.exe文件的路径并加入到电脑的环境变量中去。具体的：\n\n![img](introduction-to-spider/1365470-20190316154653549-1071713064.png)进入环境变量编辑界面，添加到用户变量即可，双击PATH，将你的文件位置（C:\\Program Files (x86)\\Google\\Chrome\\Application\\)添加到后面。\n\n![img](introduction-to-spider/1365470-20190316155217109-176711956.png)\n\n完成后在按住win+R键进入cmd，输入chromedriver验证是否安装成功：\n\n![image-20230320165251568](introduction-to-spider/image-20230320165251568.png)\n\n未配置环境也可以，例如：\n\n```python\nfrom selenium import webdriver\nimport time\n\ndef main():\n    chrome_driver = 'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe'  #chromedriver的文件位置\n    b = webdriver.Chrome(executable_path = chrome_driver)\n    b.get('https://www.google.com')\n    time.sleep(5)\n    b.quit()\n\nif __name__ == '__main__':\n    main()\n```\n\n已配置环境变量时，就不需要指定位置了\n\n```python\nfrom selenium import webdriver\nimport time\n\ndef main():\n    b = webdriver.Chrome()\n    b.get('https://www.baidu.com')\n    time.sleep(5)\n    b.quit()\n\nif __name__ == '__main__':\n    main()\n```\n\n如果运行时提示\n\n![img](introduction-to-spider/1365470-20190316162023053-275348276.png)\n\n很可能是chromedriver的版本不对（不要问我怎么知道的）。\n\n### **2.3 Selenium库获取网页源代码** \n\nSelenium库的功能很强大，使用技巧却并不复杂，只要掌握了下面的几个知识点，就能较游刃有余的使用selenium库了。\n\n**(1) 访问及关闭页面 + 网页最大化**\n\n通过以下这三行代码，就可以访问网站了，它相当于模拟人打开了一个浏览器，然后输入了一串网址：\n\n```text\nfrom selenium import webdriver\nbrowser = webdriver.Chrome()\nbrowser.get(\"https://www.baidu.com/\")\n```\n\n第一行引入selenium库里的webdriver功能，第二行browser = webdriver.Chrome()声明我们用的模拟器是谷歌浏览器，第三行通过brower.get()的这个方法访问网址。\n\n关闭模拟浏览器的代码如下，在代码最后加上这么一行，能关闭模拟浏览器。\n\n```text\nbrowser.quit()\n```\n\n**(2) 获取网页真正的源代码**\n\n利用selenium的一个主要目的就是为了获取原来难以获得的网页源码，代码如下：\n\n```text\ndata = browser.page_source\n```\n\n拿这个方法来试试之前提到过的比较难以获取的动态加载的内容：\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver import ChromeOptions\n\nurl = \"https://www.gdpt.edu.cn/al_8/189\"\n\noptions = ChromeOptions()\nbrowser = webdriver.Chrome(options=options)\nbrowser.get(url)\n\nsource = browser.page_source\n\nwith open('example.html', 'w', encoding=\"utf8\") as f:\n    f.write(source)\nbrowser.quit()\n```\n\n这样就得到了所有的内容并以一个html文件的形式写出\n\n### 2.4 selenium库加载登录信息\n\n如果一个网站要求登录才能看到信息，如何使用selenium登录呢。很简单，加载浏览器登陆过的信息即可。浏览器会将用户登录过的所有数据保存在`C:\\Users\\电脑用户名\\AppData\\Local\\Google\\Chrome\\User Data`，selenium只需要加载这个文件夹就可以了，代码如下：\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver import ChromeOptions\n\nurl = \"https://www.gdpt.edu.cn/al_8/189\"\n\n# 加载cookies中已经保存的账号和密码\noptions = ChromeOptions()\noptions.add_argument(r'user-data-dir=C:\\Users\\电脑用户名\\AppData\\Local\\Google\\Chrome\\User Data')\nbrowser = webdriver.Chrome(options=options)\nbrowser.get(url)\n\nsource = browser.page_source\n\nwith open('example.html', 'w', encoding=\"utf8\") as f:\n    f.write(source)\nbrowser.quit()\n```\n\n","tags":["python","spider"],"categories":["python","spider"]},{"title":"how-to-fix-This-application-has-no-explicit-mapping-error","url":"/2023/03/17/how-to-fix-This-application-has-no-explicit-mapping-error/","content":"\n报错完整信息:This application has no explicit mapping for /error, so you are seeing this as a fallback\n\n<!--more-->\n\n翻阅了网上众多资料，主要有一下几种解决的方向：\n\n## 方向1:包的位置可能错误\n\nApplication启动类的位置不对.要将Application类放在最外侧,即包含所有子包\n\n原因:spring-boot会自动加载启动类所在包下及其子包下的所有组件.\n\n## 方向2: springboot配置文件有误\n\n在springboot的配置文件:application.yml或application.properties中关于视图解析器的配置问题:\n\n当pom文件下的spring-boot-starter-paren版本高时使用:\n\nspring.mvc.view.prefix/spring.mvc.view.suffix\n\n当pom文件下的spring-boot-starter-paren版本低时使用:\n\nspring.view.prefix/spring.view.suffix\n\n## 方向3: 映射路径有误\n\n控制器的URL路径书写问题\n\n@RequestMapping(“xxxxxxxxxxxxxx”)\n\n实际访问的路径与”xxx”不符合.\n\n然而作为刚接触SpringBoot的我一开始犯错的时候是在第四层\n\n## 方向4: 扫包出现错误\n\n你把你Controller类的@Controller给补上\n\n## 方向5: nginx是否打开并检查端口\n\n当使用nginx代理静态资源时，需要检查是否运行nginx，并注意端口不能冲突\n\n","tags":["springboot","debug"],"categories":["debug","springboot"]},{"title":"LeetCode题解：括号匹配算法","url":"/2023/01/21/LeetCode题解：括号匹配算法/","content":"\n## 括号匹配算法\n\n左*括号*必须用相同类型的右*括号*闭合。 左*括号*必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。\n\n<!--more-->\n\n### 1.实现目标\n\n在开发中，会出现需要判断字符串是否匹配的问题，如文本编辑器中括号不匹配会出现格式错误（如以下字符串），这就需要括号匹配算法\n\n```\ndsa(dsadsa{dhk)s})}\n```\n\n### 2.实现思路\n\n![$R5G0SIK](LeetCode题解：括号匹配算法/$R5G0SIK.jpg)\n\n由于括号是与最近的同类型括号匹配，可以利用栈的后进先出特性将右括号与最近的左括号匹配，如果不匹配，直接返回false\n\n### 3.具体实现\n\n当括号数量为奇数时直接返回false，为0直接返回true。\n\n核心逻辑：循环遍历字符串每一个字符，判断是左括号则入栈，num++，若是右括号则num--，让该括号与栈顶括号匹配，若相同则弹出栈，不同则什么都不做，这样就可以跳过普通字符而判断括号是否匹配\n\n为什么要设置num：设置变量num统计左括号的数目，当有右括号时num--，这是为了判断左右括号的数目要相同，但是还要判断是否为同类括号\n\n改进方法：判断isMatch（）时在后面加else，就不用判断num了，但是使用原方法leetcode速度更快，内存也更小\n\n代码\n\n```javascript\n<script>\t\n    let isValid = funtion(str){\n        const len = str.length\n        if(len%2===1)\n            return false\n        if(len===0)\n            return true\n        \n        str = str.split('')\n        let stack = []\n        const leftBracket = '{[('\n        cosnt rightBracket = '}])'\n        let a = str[0]\n        if(rightBracket.includes(a))\n            return false\n        \n        for(let i = 0;i<len;i++)\n            if(leftBracket.includes(str[i]))\n                stack.push(str[i])\n        \t\tnum++\n        \telse if(rightBracket.includes(str[i]))//\n                num--\n                let top = stack[stack.length-1]\n                if(isMatch(top,str[i]))\n                    stack.pop()\n        \t\t/*\n        \t\telse\n        \t\t\treturn false\t\t此时就不用num了\n        \t\t*/\n        if(num===0&&stack.length===0)\n            return true\n        else \n            return false\n        \n        \n    }\n\n\n\tfuntion isMatch(left,right){\n        if(left==='{'&&right==='}'){\n            return true\n        }else if(left==='['&&right===']'){\n            return true\n        }else if(left==='('&&right===')'){\n            return true\n        }else\n            return false\n    \n</script>\n```\n\n","tags":["leetcode"],"categories":["leetcode"]}]