[{"title":"索引type说明","url":"/2023/11/22/index-type-description/","content":"\n在使用sql的过程中经常需要建立索引，而每种索引是怎么触发的又是怎么起到作用的，首先必须知道索引和索引的类型。\n\n<!--more-->\n\n ![img](index-type-description/782972-20190425143541932-674488725.png)\n\n \n\n我们可以清楚的看到type那一栏有index ALL eq_ref，他们都代表什么意思呢？\n\n首先类型有许多，这里我只给大家介绍用的最多的几种类型：\n\n**system>const>eq_ref>ref>range>index>ALL**\n\n越往左边，性能越高，**比如system就比ALL类型性能要高出许多**，其中system、const只是理想类型，基本达不到；\n\n我们自己实际能优化到ref>range这两个类型，就是你自己写SQL，如果你没优化基本上就是ALL，如果你优化了，那就尽量达到**ref>range**这两个级别；\n\n**左边基本达不到！**\n\n所以，要对type优化的前提是，**你需要有索引，如果你连索引都没有创建，那你就不用优化了，肯定是ALL.....**；\n\n## **Type级别详解**\n\n### **一.system级别**\n\n索引类型能是system的只有两种情况：\n\n**1.只有一条数据的系统表**\n\n只有一条数据的系统表，就是系统里自带一张表，并且这个表就一条数据，这个基本上就达不到，这个是系统自带的表，而且就一条数据，所以基本达不到；\n\n**2.或衍生表只能有一条数据的主查询**\n\n这个是可以实现的，但是在实际开发当中，你不可能去写一个这么个玩意儿，不可能公司的业务去让你把SQL索引类型写实system...\n\nSQL语句:select * From (select * From test01) t where tid = 1;//前面需要加explain\n\n执行结果：\n\n ![img](index-type-description/782972-20190425143549230-45717682.png)\n\n \n\n就是把它凑出来即可；\n\n我之所以能达到system，是因为我满足了它的第二个条件；\n\n### **二.const级别**\n\nconst条件稍微低一点，**但是基本上也达不到；**\n\n**1.仅仅能查出一条的SQL语句并且用于Primary key 或 unique索引；**\n\n这个我就不说了把，都知道，所以在企业里根本不可能实现，能查出来一条SQL语句，你的索引还必须是Primary key或unique；\n\nSQL语句：select * tid From test01 where tid = 1;//前面需要加explain\n\n执行结果：\n\n ![img](index-type-description/782972-20190425143554134-686833777.png)\n\n \n\n**根据tid找，因为tid是我设置的主键，主键就是Primary key，并且只能有一条数据，我表里面本来就一条，所以我满足了；**\n\n### **三.eq_ref级别**\n\n**唯一性索引：对于每个索引键的查询，返回** **匹配唯一行数据（有且只有1个，不能多，不能0）;**\n\n解说：比如你select ...from 一张表 where 比方说有一个字段 name = 一个东西，也就是我们以name作为索引，假设我之前给name加了一个索引值，我现在根据name去查，查完后有20条数据，我就必须保证这二十条数据每行都是唯一的，不能重复不能为空！\n\n**只要满足以上条件，你就能达到eq_ref，当然前提是你要给name建索引，如果name连索引都没，那你肯定达不到eq_ref;**\n\n此种情况常见于唯一索引和主键索引；\n\n比如我根据name去查，但是一个公司里面或一个学校里面叫name的可能不止一个，一般你想用这个的时候，就要确保你这个字段是唯一的，id就可以，你可以重复两个张三，但是你身份证肯定不会重复；\n\n**添加唯一键语法：alter table 表名 add constraint 索引名 unique index(列名)**\n\n检查字段是否唯一键：show index form 表名；被展示出来的皆是有唯一约束的；\n\n#### **以上级别，均是可遇不可求！！！！**\n\n### **四 .ref级别**\n\n到ref还是问题不大的，**只要你上点心，就可以达到**；\n\n**非唯一性索引：对于每个索引键的查询，返回匹配的所有行（可以是0，或多个）**\n\n假设我现在要根据name查询，首先name可能有多个，因为一个公司或学校叫小明的不止一个人，但是你要用name去查，你必须name是索引，我们先给它加个索引，因为要达到ref级别，所以这里我给它加一个**单值索引**，\n\n**单值索引语法：alter table 表名 索引类型 索引名（字段）**\n\n现在我们根据索引来查数据，这里我假设我写的单值索引；\n\nalter table student add index index_name (name);\n\n这个时候我们再去编写sql语句：\n\nalter table student add index index_name (name);\n\n**因为name是索引列，这里假设有两个叫张三的，ref级别规则就是能查出多个或0个，很显然能查出来多个，那这条SQL语句，必然是ref级别！**\n\n执行结果：\n\n ![img](index-type-description/782972-20190425143613568-1424280825.png)\n\n \n\n数据：\n\n ![img](index-type-description/782972-20190425143622009-1263643692.png)\n\n \n\n### **五.range级别**\n\n检索指定范围的行，查找一个范围内的数据，where后面是一个范围查询 （between,in,> < >=);\n\n注：in 有时会失效，导致为ALL；\n\n现在我们写一个查询语句，前提是，tid一定是一个索引列，如果是id的话，就用主键索引，也就是唯一索引，值不可以重复，这个时候我们范围查询的时候要用它来做条件：\n\n EXPLAIN SELECT t.* FROM student t WHERE t.tid BETWEEN 1 AND 2; ;//查询tid是1到2；\n\n查看执行结果：\n\n ![img](index-type-description/782972-20190425143635585-1298799422.png)\n\n \n\n### **六.index级别**\n\n查询全部索引中的数据\n\n讲解：假设我有一张表，里面有id name age，这个时候name是一个单值索引，一旦name被设定成索引，**它就会成为B树一样，经过各种算法将name里面的值像树一样进行分类，这个时候我where name = \\**，就相当于把这颗B树查了一个遍，**\n\n**也就是说，你把name这一列给查了一遍；**\n\nSQL语句：select id From student;//我只查被索引声明的列，必然就是index了；\n\n执行结果：\n\n ![img](index-type-description/782972-20190425143641792-1375317565.png)\n\n \n\n### **七.ALL级别**\n\n查询全部表数据，就是select name From student;\n\n其中 name 不是索引；\n\n如果你查的这一列不是索引，就会导致全表扫描，**所以要避免全表扫描**；\n\n执行结果：\n\n \n\n ![img](index-type-description/782972-20190425143647380-1518567754.png)\n\n \n","tags":["数据库"],"categories":["数据库"]},{"title":"B树和B+树性质对比","url":"/2023/11/21/Comparison-of-properties-between-B-tree-and-B-tree/","content":"\nB树和B+树性质对比\n<!--more-->\n\n\n![image-20231121183856474](Comparison-of-properties-between-B-tree-and-B-tree/image-20231121183856474.png)\n\n### **通用概念：**\n\n **阶：**所有结点的孩子个数的最大值称为阶。通常用m表示\n\n **终端结点：**最后一排具有关键字的结点。\n\n **叶子结点：**也叫失败结点，没有任何信息的一排结点。\n\n------\n\n### B树（B-树）\n\n概念：\n\n 也叫作多路平衡查找树、B-树。\n\n 注：2-3树、2-3-4树是B树的一种特定情况。而B+树则是B树的变形。\n\n性质（条件）//注意分清子树和结点\n\nB树是一种平衡的多分树，通常我们说m阶的B树，它必须满足如下条件：\n\n- 每个结点最多有m棵子树。\n- 具有*k*个子树的非叶结点包含*k* -1个键。\n- 每个非叶子结点（除了根）具有至少**⌈ m/2⌉子树**，即最少有**⌈ m/2⌉-1个关键字**。\n- 如果**根不是终端结点，则根结点至少有一个关键字**，即至少有2棵子树。【根的关键字取值范围是[1，m-1]，子树的取值范围是[2,m]】\n- 所有叶子结点都出现在同一水平，没有任何信息（高度一致）。【带有关键字那个叫做终端结点】\n\n> **关键字：**最少⌈ m/2⌉-1，最多m-1\n> **子树**：最少⌈ m/2⌉，最多m\n\n\n\n![image-20231121183925738](Comparison-of-properties-between-B-tree-and-B-tree/image-20231121183925738.png)\n\n其他性质：\n\n![image-20231121183810713](Comparison-of-properties-between-B-tree-and-B-tree/image-20231121183810713.png)\n\n![image-20231121183942382](Comparison-of-properties-between-B-tree-and-B-tree/image-20231121183942382.png)\n\n------\n\n### B+树\n\n概念：\n\n B+树是应数据库所需要而出现的一种**B树的变形树。**\n\n性质（条件）//注意分清子树和结点\n\n一棵m阶B+树，它必须满足如下条件：\n\n- 每个结点最多有m棵子树。\n- 如果**根不是终端结点，则根结点至少有一个关键字**，即至少有2棵子树。【根的关键字取值范围是[1，m-1]】\n- **每个关键字对应一棵子树**（与B树的不同），具有*k*个子树的非叶结点包含*k* 个键。\n- 每个非叶子结点（除了根）具有至少**⌈ m/2⌉子树**，即最少有**⌈m/2⌉个关键字**。\n- 终端结点包含全部关键字及相应记录的指针，叶结点中将关键字按大小顺序排序，并且相邻叶结点按大小顺序相互链接起来。\n- 所有分支结点（可以视为索引的索引）中金包含他的各个子节点（即下一级的索引块）中关键字最大值，及指向其子结点的指针。\n\n\n\n![img](Comparison-of-properties-between-B-tree-and-B-tree/v2-b4dcfc3464962feda83fb1087147eff9_1440w.webp)\n\n\n\n------\n\n### m阶B树和B+树的主要对比：\n\n|             | B树                                             | B+树                                            |\n| ----------- | ----------------------------------------------- | ----------------------------------------------- |\n| 关键字      | 最少：⌈m/2⌉-1 最多：m-1                         | 最少：⌈m/2⌉ 最多：m                             |\n| 子树        | 非叶根：至少2棵，最多m棵 其他：至少⌈m/2⌉，最多m | 非叶根：至少2棵，最多m棵 其他：至少⌈m/2⌉，最多m |\n| key-subtree | k个key有k+1棵tree                               | k个key有k棵tree                                 |\n|             |                                                 |                                                 |\n| 非终端节点  | 包含有用信息                                    | 只是索引                                        |\n| 终端节点    | 不会出现非终端节点的key                         | 会出现非终端节点的key                           |\n\n- 在B+树中，叶结点包含信息，所有非叶结点仅起索引作用，非叶子结点中的每个索引项只是包含了对应子树最大关键字和指向该孩子树的指针，不含有该关键字对应记录的存储地址。\n- 在B+树中，终端结点包含全部关键字及相应记录的指针，即非终端结点出现过的关键字也会在这重复出现一次。而B树是不重复的。\n","tags":["数据结构"],"categories":["数据结构"]},{"title":"如何解决Linux中buff-cache占用过高","url":"/2023/09/08/how-to-solve-the-problem-of-excessive-buffer-cache-usage-in-Linux/","content":"\nLinux中buff-cache占用过高解决手段\n\n<!--more-->\n\n### 简介\n\n    使用free -h命令可以查看当前系统的内存使用情况\n\n```\n      total        used        free      shared  buff/cache   available \nMem:  1.8G        1.4G         66M        952K        313M        211M\nSwap:  0B          0B          0B\n```\n\n> available表示应用程序还可以申请到的内存\n\n首先了解下两个概念buff和cache\n\n> - buff（Buffer Cache）是一种I/O缓存，用于内存和硬盘的缓冲，是io设备的读写缓冲区。根据磁盘的读写设计的，把分散的写操作集中进行，减少磁盘碎片和硬盘的反复寻道，从而提高系统性能。\n\n> - cache（Page Cache）是一种高速缓存，用于CPU和内存之间的缓冲 ,是文件系统的cache。\n>     把读取过的数据保存起来，重新读取时若命中（找到需要的数据）就不要去读硬盘了，若没有命中就读硬盘。其中的数据会根据读取频率进行组织，把最频繁读取的内容放在最容易找到的位置，把不再读的内容不断往后排，直至从中删除。\n\n    它们都是占用内存。两者都是RAM中的数据。简单来说，buff是即将要被写入磁盘的，而cache是被从磁盘中读出来的。\n\n    目前进程正在实际被使用的内存的计算方式为used-buff/cache，通过释放buff/cache内存后，我们还可以使用的内存量free+buff/cache。通常我们在频繁存取文件后，会导致buff/cache的占用量增高。\n\n### 处理方式\n\n#### 手动清除\n\n    执行以下命令即可\n\n```\n[root@izbp17wg1wphb6f95b76obz ~]# sync\n[root@izbp17wg1wphb6f95b76obz ~]# echo 1 > /proc/sys/vm/drop_caches\n[root@izbp17wg1wphb6f95b76obz ~]# echo 2 > /proc/sys/vm/drop_caches\n[root@izbp17wg1wphb6f95b76obz ~]# echo 3 > /proc/sys/vm/drop_caches\n```\n\n- sync：将所有未写的系统缓冲区写到磁盘中，包含已修改的i-node、已延迟的块I/O和读写映射文件\n- echo 1 > /proc/sys/vm/drop_caches：清除page cache\n- echo 2 > /proc/sys/vm/drop_caches：清除回收slab分配器中的对象（包括目录项缓存和inode缓存）。slab分配器是内核中管理内存的一种机制，其中很多缓存数据实现都是用的pagecache。\n- echo 3 > /proc/sys/vm/drop_caches：清除pagecache和slab分配器中的缓存对象。\n    /proc/sys/vm/drop_caches的值,默认为0\n\n#### 定时清除\n\n1、创建脚本cleanCache.sh\n\n```\n#!/bin/bash#每两小时清除一次缓存\necho \"开始清除缓存\"\nsync;sync;sync #写入硬盘，防止数据丢失\nsleep 10#延迟10秒\necho 1 > /proc/sys/vm/drop_caches\necho 2 > /proc/sys/vm/drop_caches\necho 3 > /proc/sys/vm/drop_caches\n```\n\n2、创建定时任务\n\n```\ncrontab -e #弹出配置文件\n```\n\n3、添加定时任务执行频率\n\n```\n#分　 时　 日　 月　 周　 命令\n0 */2 * * * ./cleanCache.sh\n```\n\n4、设置crond启动以及开机自启\n\n```\nsystemctl start crond.service\nsystemctl enable crond.service\n```\n\n5、查看定时任务是否被执行\n\n```\ncat /var/log/cron | grep cleanCache\n```\n\n### 参考资料\n\n- [linux top命令中的cache & buffers](https://blog.csdn.net/Cooling88/article/details/50969013)\n- [buff/cache的问题](https://blog.csdn.net/dyh4201/article/details/85266235)\n- [Linux 内存缓存占用过大，Centos7设置定时清除buff/cache的脚本](http://www.sapv.cn/article/83)\n","tags":["Linux"],"categories":["Linux"]},{"title":"使用TCP和KCP传输一张图片","url":"/2023/08/12/Transfer-a-picture-with-TCP-and-KCP/","content":"\n基于Go分别在两台虚拟机上使用TCP和KCP传输一张图片的demo\n\n<!--more-->\n\n## TCP传输\n\n### TCP服务端\n\n使用服务端接收图片，此虚拟机的ip是192.168.10.107\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"time\"\n)\n\nfunc main() {\n\tlis, err := net.Listen(\"tcp\", \"192.168.10.107:10000\")\n\tif err != nil {\n\t\tfmt.Printf(\"Error connecting to server: %s\\n\", err)\n\t\treturn\n\t}\n\tdefer lis.Close()\n\n\t// 创建本地文件用于保存接收的图片数据\n\tfile, err := os.Create(\"received_image.png\")\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %s\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\t// 创建一个缓冲区，用于接收数据\n\tbuffer := make([]byte, 1024*256)\n\tendSignal := []byte(\"TRANSFER_COMPLETED\")\n\n\tstartTime := time.Now()\n\n\tconn, err := lis.Accept()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer conn.Close()\n\n\tfmt.Println(time.Now())\n\n\tfor {\n\t\tn, err := conn.Read(buffer)\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak // 读取结束\n\t\t\t}\n\t\t\tfmt.Printf(\"Error reading data: %s\\n\", err)\n\t\t\treturn\n\t\t}\n\n\t\t // 检查是否收到结束标志\n\t\t if bytes.Equal(buffer[:n], endSignal) {\n\t\t\tbreak\n\t\t}\n\n\t\t// 将数据写入本地文件\n\t\t_, err = file.Write(buffer[:n])\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error writing to file: %s\\n\", err)\n\t\t\treturn\n\t\t}\n\n\t}\n\n\tendTime := time.Now()\n\telapsedTime := endTime.Sub(startTime)\n\tprint(elapsedTime.Milliseconds())\n\n\t// 获取文件大小\n\tfileInfo, err := file.Stat()\n\tif err != nil {\n\t\tfmt.Printf(\"Error getting file info: %s\\n\", err)\n\t\treturn\n\t}\n\tfileSize := fileInfo.Size()\n\tfmt.Println(fileSize)\n\n\t// 计算传输速度\n\ttransferSpeed := float64(fileSize) / float64((elapsedTime.Milliseconds() * (1024 * 1024))/1000) // MB/s\n\n\tfmt.Printf(\"File transfer complete. Transfer speed: %.2f MB/s\\n\", transferSpeed)\n\n}\n```\n\n首先监听本地ip和相应端口，获取一个listener，通过listener的Accept方法后就可以获取一个连接，通过连接便可传送数据。先创建一个空文件和缓冲区，进入循环，循环中将连接的数据写入到缓冲区中，获取得到的字节数n，并将数据写入到本地文件，直到遇到传输结束信号\"TRANSFER_COMPLETED\"\n\n### TCP客户端\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n\t\"time\"\n)\n\n\nfunc main() {\n\t// kcp\n\t// conn, err := kcp.DialWithOptions(serverAddr, nil, 10, 3)\n\t// tcp\n\tconn, err := net.Dial(\"tcp\", \"192.168.10.107:10000\")\n\tif err!= nil {\n\t\tfmt.Println(err)\n\t}\n\tdefer conn.Close()\n\tif err != nil {\n\t\tlog.Fatal(\"Listen failed:\", err)\n\t}\n\n\tfmt.Println(\"Server started, waiting for connections...\")\n\n\thandleClientWithTCP(conn)\n}\n\nfunc handleClientWithTCP(conn net.Conn) {\n\n\tfile, err := os.Open(\"mountain.png\")\n\tif err != nil {\n\t\tlog.Fatal(\"Create file failed:\", err)\n\t}\n\tdefer file.Close()\n\n\tbuf := make([]byte, 1024*256)\n\n\tfor {\n\t\tn, err := file.Read(buf)\n\t\tif err != nil {\n\t\t\tif err != io.EOF {\n\t\t\t\tlog.Println(\"Read from file failed:\", err)\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\t_, err = conn.Write(buf[:n])\n\t\tif err != nil {\n\t\t\tlog.Println(\"Write to client failed:\", err)\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// 图片传输完成后发送结束标志\n\t_, err = conn.Write([]byte(\"TRANSFER_COMPLETED\"))\n\tif err != nil {\n\t    fmt.Printf(\"Error sending completion signal: %s\\n\", err)\n\t    return\n\t}\n\t\n\tfmt.Println(time.Now())\n\tfmt.Println(\"Image transfer completed.\")\n}\n```\n\n获取到连接conn后，循环将文件数据file写入到缓冲区中，然后将缓冲区的数据发送到连接中，直到遇到io.EOF跳出循环，发送了结束标志\n\n## KCP传输\n\n### KCP服务端\n\n```go\npackage main\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"github.com/xtaci/kcp-go\"\n\t\"io\"\n\t\"net\"\n\t\"os\"\n\t\"time\"\n)\n\nconst (\n\tserverAddr = \"192.168.10.107:10000\"\n\t\n)\n\nfunc kcpRecv() {\n    // 这里的10， 3是设置了前向纠错\n    // 也可以使用kcp.Listen，与tcp接口兼容 但是默认没有使用前向纠错\n\tlis, err := kcp.ListenWithOptions(serverAddr, nil, 10, 3)\n\tif err != nil {\n\t\tfmt.Printf(\"Error connecting to server: %s\\n\", err)\n\t\treturn\n\t}\n\tdefer lis.Close()\n\n\t// 创建本地文件用于保存接收的图片数据\n\tfile, err := os.Create(\"received_image.png\")\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating file: %s\\n\", err)\n\t\treturn\n\t}\n\tdefer file.Close()\n\n\t// 创建一个缓冲区，用于接收数据\n\tbuffer := make([]byte, 1024*256)\n\tendSignal := []byte(\"TRANSFER_COMPLETED\")\n\n\tstartTime := time.Now()\n\n\tconn, err := lis.AcceptKCP()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\tdefer conn.Close()\n\n\tfmt.Println(time.Now())\n\n\tfor {\n\t\tn, err := conn.Read(buffer)\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak // 读取结束\n\t\t\t}\n\t\t\tfmt.Printf(\"Error reading data: %s\\n\", err)\n\t\t\treturn\n\t\t}\n\n\t\t // 检查是否收到结束标志\n\t\t if bytes.Equal(buffer[:n], endSignal) {\n\t\t\tbreak\n\t\t}\n\n\t\t// 将数据写入本地文件\n\t\t_, err = file.Write(buffer[:n])\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"Error writing to file: %s\\n\", err)\n\t\t\treturn\n\t\t}\n\n\t}\n\n\tendTime := time.Now()\n\telapsedTime := endTime.Sub(startTime)\n\n\t// 获取文件大小\n\tfileInfo, err := file.Stat()\n\tif err != nil {\n\t\tfmt.Printf(\"Error getting file info: %s\\n\", err)\n\t\treturn\n\t}\n\tfileSize := fileInfo.Size()\n\n\t// 计算传输速度\n\ttransferSpeed := float64(fileSize) / elapsedTime.Seconds() / (1024 * 1024) // MB/s\n\n\tfmt.Printf(\"File transfer complete. Transfer speed: %.2f MB/s\\n\", transferSpeed)\n\n}\n```\n\nkcp-go与tcp的接口做了兼容处理，可以无障碍替换使用tcp，也增加了一些可选项，如前向纠错，如kcp.ListenWithOptions(serverAddr, nil, 10, 3)的10和3就代表着每发送10个包就发送3个冗余包\n\n### KCP客户端\n\n```go\npackage main\n\nimport (\n\t\"time\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"io\"\n\t\"github.com/xtaci/kcp-go\"\n)\n\nconst (\n\tserverAddr = \"192.168.10.107:10000\"\n)\n\nfunc kcpSend() {\n\tconn, err := kcp.DialWithOptions(serverAddr, nil, 10, 3)\n\tif err!= nil {\n\t\tfmt.Println(err)\n\t}\n\tdefer conn.Close()\n\tif err != nil {\n\t\tlog.Fatal(\"Listen failed:\", err)\n\t}\n\n\tfmt.Println(\"Server started, waiting for connections...\")\n\n\thandleClient(conn)\n}\n\nfunc handleClient(conn *kcp.UDPSession) {\n\n\tfile, err := os.Open(\"mountain.png\")\n\tif err != nil {\n\t\tlog.Fatal(\"Create file failed:\", err)\n\t}\n\tdefer file.Close()\n\n\tbuf := make([]byte, 1024*256)\n\n\tfor {\n\t\tn, err := file.Read(buf)\n\t\tif err != nil {\n\t\t\tif err != io.EOF {\n\t\t\t\tlog.Println(\"Read from file failed:\", err)\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\t_, err = conn.Write(buf[:n])\n\t\tif err != nil {\n\t\t\tlog.Println(\"Write to client failed:\", err)\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// 图片传输完成后发送结束标志\n\t_, err = conn.Write([]byte(\"TRANSFER_COMPLETED\"))\n\tif err != nil {\n\t    fmt.Printf(\"Error sending completion signal: %s\\n\", err)\n\t    return\n\t}\n\n\tfmt.Println(time.Now())\n\tfmt.Println(\"Image transfer completed.\")\n}\n```\n\n","tags":["计算机网络","KCP"],"categories":["计算机网络","KCP"]},{"title":"TCP系列01-概述及协议头格式","url":"/2023/08/11/TCP-series-01-Overview-and-protocol-header-format/","content":"\n对TCP的概述以及对协议头格式的解释\n\n<!--more-->\n\n## 一、TCP简单介绍\n\n​    我们经常听人说TCP是一个面向连接的(connection-oriented)、可靠的(reliable)、字节流式(byte stream)传输协议，  TCP的这三个特性该怎么理解呢？\n\n- 面向连接：在应用TCP协议进行通信之前双方通常需要通过三次握手来建立TCP连接，连接建立后才能进行正常的数据传输，因此广播和多播不会承载在TCP协议上。(谷歌提交了一个RFC文档，建议在TCP三次握手的过程允许SYN数据包中带数据，即 TFO(TCP Fast Open)，ubuntu14.04已经支持该TFO功能)。但是同时面向连接的特性给TCP带来了复杂的连接管理以及用于检测连接状态的存活检测机制。\n- 可靠性：由于TCP处于多跳通信的IP层之上，而IP层并不提供可靠的传输，因此在TCP层看来就有四种常见传输错误问题，分别是比特错误(packet bit errors)、包乱序(packet reordering)、包重复(packet duplication)、丢包(packet erasure或称为packet drops)，TCP要提供可靠的传输，就需要有额外的机制处理这几种错误。因此个人理解可靠性体现在三个方面，首先TCP通过超时重传和快速重传两个常见手段来保证数据包的正确传输，也就是说接收端在没有收到数据包或者收到错误的数据包的时候会触发发送端的数据包重传(处理比特错误和丢包)。其次TCP接收端会缓存接收到的乱序到达数据，重排序后在向应用层提供有序的数据(处理包乱序)。最后TCP发送端会维持一个发送\"窗口\"动态的调整发送速率以适用接收端缓存限制和网络拥塞情况，避免了网络拥塞或者接收端缓存满而大量丢包的问题(降低丢包率)。因此可靠性需要TCP协议具有超时与重传管理、窗口管理、流量控制、拥塞控制等功能。另外TFO下TCP有可能向应用层提供重复的数据，也就是不可靠传输，但是只会发生在连接建立阶段，我们后续会进行介绍。\n- 字节流式：应用层发送的数据会在TCP的发送端缓存起来，统一分片(例如一个应用层的数据包分成两个TCP包)或者打包(例如两个或者多个应用层的数据包打包成一个TCP数据包)发送，到接收端的时候接收端也是直接按照字节流将数据传递给应用层。作为对比，同样是传输层的协议，UDP并不会对应用层的数据包进行打包和分片的操作，一般一个应用层的数据包就对应一个UDP包。这个也是伴随TCP窗口管理、拥塞控制等。\n\n​    在接下来的TCP系列中，我们将会依次介绍TCP协议的连接管理、超时与重传、流量控制、窗口管理、拥塞控制、存活检测等机制。在深入介绍这些内容之前我们先来看一下TCP的封装和协议头的格式(TCP/IP的网络分层等基础网络概念本处不在介绍)\n\n## 二、TCP的封装和协议头的格式\n\n  TCP封装在IP报文中的时候，如下图所示，TCP头紧接着IP头(IPV6有扩展头的时候，则TCP头在扩展头后面)，不携带选项(option)的TCP头长为20bytes，携带选项的TCP头最长可到60bytes。\n\n \n\n![img](TCP-series-01-Overview-and-protocol-header-format/740952-20161107132806686-1082325930.png)\n\n  其中不携带选项的TCP头如下图所示(其中阴影部分的四个字段表示了相反方向的数据流信息)，其中header length字段由4比特构成，最大为15，单位是32比特(32-bit word)，即头长的最大值为15*32 bits = 60bytes，因此上面说携带选项的TCP头长最长为60bytes。\n\n[![img](TCP-series-01-Overview-and-protocol-header-format/740952-20161107132809311-2059896218.png)](http://images2015.cnblogs.com/blog/740952/201611/740952-20161107132809311-2059896218.png)\n\nTCP头中的相关字段顺序解释如下：\n\n  **TCP源端口(Source Port)**：16位的源端口其中包含发送方应用程序对应的端口。源端口和源IP地址标示报文发送端的地址。\n\n  **TCP目的端口(Destination port)**：16位的目的端口域定义传输的目的。这个端口指明报文接收计算机上的应用程序地址接口。\n\nTCP的源端口、目的端口、以及IP层的源IP地址、目的IP地址四元组唯一的标识了一个TCP连接，一个IP地址和一个端口号的组合叫做一个endpoint或者socket。也即一对endpoint或者一对socket唯一的标识了一个TCP连接。接收端的TCP层就是根据不同的端口号来将数据包传送给应用层的不同程序，这个过程叫做解复用(demultiplex)。相应的发送端会把应用层不同程序的数据映射到不同的端口号，这个过程叫做复用(multiplex)。\n\n  **TCP序列号（序列码SN,Sequence　Number）**：32位的序列号标识了TCP报文中第一个byte在对应方向的传输中对应的字节序号。当SYN出现，序列码实际上是初始序列码（ISN），而第一个数据字节是ISN+1，单位是byte。比如发送端发送的一个TCP包净荷(不包含TCP头)为12byte，SN为5，则发送端接着发送的下一个数据包的时候，SN应该设置为5+12=17。通过系列号，TCP接收端可以识别出重复接收到的TCP包，从而丢弃重复包，同时对于乱序数据包也可以依靠系列号进行重排序，进而对高层提供有序的数据流。另外SYN标志和FIN标志在逻辑上也占用一个byte，当SYN标志位有效的时候，该字段也称为ISN(initial sequence number)，详细请参考后续的TCP连接管理。\n\n  **TCP应答号(Acknowledgment  Number简称ACK Number或简称为ACK Field)**：32位的ACK Number标识了报文发送端期望接收的字节序列。如果设置了ACK控制位，这个值表示一个准备接收的包的序列码，注意是准备接收的包，比如当前接收端接收到一个净荷为12byte的数据包，SN为5，则发送端可能会回复一个确认收到的数据包，如果这个数据包之前的数据也都已经收到了，这个数据包中的ACK Number则设置为12+5=17，表示17byte之前的数据都已经收到了。在举一个例子，如果在这个数据包之前有个SN为3，净荷为2byte的数据包丢失，则在接受端接收到这个SN为5的乱序数据包的时候，协议要求接收端必须要回复一个ACK确认包，这个确认包中的Ack Number只能设置为3。\n\n  **头长(Header Length)**：4位包括TCP头大小，指示TCP头的长度，即数据从何处开始。最大为15，单位是32比特(32-bit word)。\n\n  **保留(Reserved)**：4位值域，这些位必须是0。为了将来定义新的用途所保留，其中RFC3540将Reserved字段中的最后一位定义为Nonce标志。后续拥塞控制部分的讲解我们会简单介绍Nonce标志位。\n\n  **标志(Code Bits)**：8位标志位，下面介绍。\n\n  **窗口大小(Window Size)**：16位，该值指示了从Ack Number开始还愿意接收多少byte的数据量，也即用来表示当前接收端的接收窗还有多少剩余空间。用于TCP的流量控制。\n\n  **校验位(Checksum)**：16位TCP头。发送端基于数据内容计算一个数值，接收端要与发送端数值结果完全一样，才能证明数据的有效性。接收端checksum校验失败的时候会直接丢掉这个数据包。CheckSum是根据伪头+TCP头+TCP数据三部分进行计算的。另外对于大的数据包，checksum并不能可靠的反应比特错误，应用层应该再添加自己的校验方式。\n\n  **优先指针（紧急,Urgent Pointer）**：16位，指向后面是优先数据的字节，在URG标志设置了时才有效。如果URG标志没有被设置，紧急域作为填充。加快处理标示为紧急的数据段。\n\n  **选项(Option)**：长度不定，但长度必须以是32bits的整数倍。常见的选项包括MSS、SACK、Timestamp等等，后续的内容会分别介绍相关选项。\n\n \n\n在**标志(Code Bits)**中的八位标志位分别介绍如下\n\n**CWR(Congestion Window Reduce****)**：拥塞窗口减少标志被发送主机设置，用来表明它接收到了设置ECE标志的TCP包，发送端通过降低发送窗口的大小来降低发送速率\n\n**ECE(ECN Echo)**：ECN响应标志被用来在TCP3次握手时表明一个TCP端是具备ECN功能的，并且表明接收到的TCP包的IP头部的ECN被设置为11。更多信息请参考RFC793。\n\n**URG(Urgent)**：该标志位置位表示紧急(The urgent pointer) 标志有效。该标志位目前已经很少使用参考后面流量控制和窗口管理部分的介绍。\n\n**ACK(Acknowledgment)**：取值1代表Acknowledgment Number字段有效，这是一个确认的TCP包，取值0则不是确认包。后续文章介绍中当ACK标志位有效的时候我们称呼这个包为ACK包，使用大写的ACK称呼。\n\n**PSH(Push)**：该标志置位时，一般是表示发送端缓存中已经没有待发送的数据，接收端不将该数据进行队列处理，而是尽可能快将数据转由应用处理。在处理 telnet 或 rlogin 等交互模式的连接时，该标志总是置位的。\n\n**RST(Reset)**：用于复位相应的TCP连接。通常在发生异常或者错误的时候会触发复位TCP连接。\n\n**SYN(Synchronize****)**：同步序列编号(Synchronize Sequence Numbers)有效。该标志仅在三次握手建立TCP连接时有效。它提示TCP连接的服务端检查序列编号，该序列编号为TCP连接初始端(一般是客户端)的初始序列编号。在这里，可以把TCP序列编号看作是一个范围从0到4，294，967，295的32位计数器。通过TCP连接交换的数据中每一个字节都经过序列编号。在TCP报头中的序列编号栏包括了TCP分段中第一个字节的序列编号。类似的后续文章介绍中当这个SYN标志位有效的时候我们称呼这个包为SYN包。\n\n**FIN(Finish)**：带有该标志置位的数据包用来结束一个TCP会话，但对应端口仍处于开放状态，准备接收后续数据。当FIN标志有效的时候我们称呼这个包为FIN包。\n\n  另外我们一般称呼链路层的发出去的数据包为**帧(frame)**，称呼网络层发给链路层的数据包为**包(packet)**，称呼传输层发给网络层的数据包为**段(segment)**。但是正如我们描述所用，段、包、帧也经常统称为数据包或者数据报文。\n\n  对应用层来说TCP是一个双向对称的全双工(full-duplex)协议，也就是说应用层可以同时发送数据和接收数据。这就意味着数据流在一个方向上的传输是独立于另一个方向的传输的，每个方向上都有独立的SN。\n\n## 三、TCP中的数据包窗口和滑窗\n\n  在TCP的发送端和接收端都会维持一个窗口，因为一个TCP连接是双向的，因此实际上一个TCP连接一共有四个窗口。此处我们先简单介绍一个发送端的窗口如下。图中的数字表示byte也就是和上面介绍的TCP协议头中的SN是对应的，3号byte以及3号之前的数据表示已经发送并且收到了接收端的ACK确认包的数据；4、5、6三个byte表示当前可以发送的数据包，也有可能已经已经发送了但是还没有收到ACK确认包；7号byte及之后的数据表示为了控制发送速率暂时不能发送的数据。其中4-6这三个byte就称呼为**窗口大小(window size)**。当TCP连接建立的时候，双方会通过TCP头中的窗口大小字段向对方通告自己接收端的窗口大小，发送端依据接收端通告的窗口大小来设置发送端的发送窗口大小，另外在拥塞控制的时候也是通过调整发送端的发送窗口来调整发送速率的。窗口这个词的来源就是当我们从这一个数据序列中单独看4、5、6这几个byte的时候，我们仿佛是从一个\"窗口\"中观察的一样。此处先简单有个滑窗的概念后续我们讲到TCP的窗口管理的时候会继续进一步介绍TCP的滑窗。\n\n \n\n![img](TCP-series-01-Overview-and-protocol-header-format/740952-20161107132809967-988574516.png)\n\n \n\n相关补充：\n1、TCPIP最初传输层和IP层是同一个层的，关于网络分层的小故事可以参考http://news.cnblogs.com/n/187131/ ， IETF上还专门有一个愚人节系列的RFC，参考[https://en.wikipedia.org/wiki/April_Fools%27_Day_Request_for_Comments](https://en.wikipedia.org/wiki/April_Fools'_Day_Request_for_Comments)\n\n2、TCP头中CheckSum的计算可以参考资料\n\nhttp://www.roman10.net/2011/11/27/how-to-calculate-iptcpudp-checksumpart-1-theory/这个连接里面一共三个系列分别是理论、实现、用例和验证。\n\nhttp://www.tcpipguide.com/free/t_TCPChecksumCalculationandtheTCPPseudoHeader-2.htm \n\n或者参考TCPIP详解卷一第二版(暂时只有英文版，名字TCP/IP Illustrated Volume 1 Second Edition The Protocols) P475页\n\n3、后面涉及的相关RFC文档可以去IETF官网 http://www.ietf.org/查询 直接搜索RFC号码就行了。整个TCP相关的协议体系，IETF梳理后在2015年以RFC7414发布，想了解或者查询TCP相关RFC协议的可以先看看RFC7414协议，以对整个TCP协议有个概括了解\n\n4、目前linux4.4实现上还不支持Nonce标志，可以参考内核代码中*struct tcphdr*结构对TCP头的定义。关于Llinux不同版本内核TCP实现相关的更新可以查看linux的changelog，网址https://kernelnewbies.org/LinuxVersions 其中有每个版本的changelog 还有对应的修改代码\n\n5、TCP传输中的包重复，不见得是TCP重传导致的，也可能是因为IP层提供的不可靠传输导致的 http://stackoverflow.com/questions/12871760/packet-loss-and-packet-duplication\n\n6、在网络传输过程中NAT可能会修改checksum甚至系列号seq，后面我们讨论窗口管理等内容的时候为了简化不考虑nat修改seq的场景，即认为发送端发包的seq与接收端接收这个包的时候seq相同。\n","tags":["TCP","计算机网络"],"categories":["计算机网络","TCP"]},{"title":"使用go-callvis查看函数调用流程","url":"/2023/08/06/how-to-use-go-callvis-to-see-how-funtion-are-made/","content":"\n使用go-callvis查看逻辑复杂的项目的函数调用流程，减少理解成本\n\n<!--more-->\n\n## go-callvis是什么\n\ngo-callvis是代码调用链路可视化工具，是代码方法级别的调用关系，主要用于代码设计。可视化工具可以将代码间的调用关系通过图表的方式展示出来，如下图。\n\n![image-20230807113823511](how-to-use-go-callvis-to-see-how-funtion-are-made/image-20230807113823511.png)\n\n## 如何生成调用关系图\n\ngo-callvis除了可以生成图片文件，还可以生成svg图，它默认会启动一个Web Server，我们可以在浏览器访问它的地址，在页面上实现交互式的浏览调用关系。\n\n### **SVG：**\n\n```text\nSVG是一种用XML定义的语言，用来描述二维矢量及矢量/栅格图形。\nSVG图形是可交互的和动态的，可以在SVG文件中嵌入动画元素或通过脚本来定义动画。\n```\n\n下面是一段SVG代码：\n\n```text\n<g id=\"a_clust3\"><a xlink:href=\"/?f=github.com/goccy/go-graphviz/cgraph\" xlink:title=\"package: github.com/goccy/go&#45;graphviz/cgraph\">\n<polygon fill=\"#ffffe0\" stroke=\"#000000\" stroke-width=\".8\" points=\"861.8909,-442.8 861.8909,-521.8 972.5803,-521.8 972.5803,-442.8 861.8909,-442.8\"/>\n<text text-anchor=\"middle\" x=\"917.2356\" y=\"-503.4\" font-family=\"Tahoma bold\" font-size=\"16.00\" fill=\"#000000\">cgraph</text> \n```\n\n可以看到和HTML类似，同样是一种标记语言。\n\n### **go-callvis使用介绍**\n\n首先使用`go get -u github.com/ofabry/go-callvis` 命令进行安装，安装完成后go-callvis将出现在你得GOPATH/bin目录下。\n\n### **命令行参数解释：**\n\n```text\ngo-callvis: visualize call graph of a Go program.\n\nUsage:\n  go-callvis [flags] package //package即想要进行分析的包名，注意：package必须是main包或者包含单元测试的包，原因稍候介绍\n\n\nFlags:\n\n  -cacheDir string\n        如果指定了缓存目录，生成过的图片将被保存下来，后续使用时不需要再渲染\n  -debug\n        开启调试日志.\n  -file string\n        指定输出文件名，使用后将不在启动Web Server\n  -focus string\n        定位到指定的package，package可以是包名也可以是包的import路径，默认main包\n  -format string\n        指定输出文件格式[svg | png | jpg | ...] (default \"svg\")\n  -graphviz\n        使用本地安装的graphviz的dot命令，否则使用graphviz的go库\n  -group string\n        分组方式： packages and/or types [pkg, type] (separated by comma) (default \"pkg\")\n  -http string\n        Web Server地址. (default \":7878\")\n  -ignore string\n        忽略的packages，多个使用逗号分隔。（使用前缀匹配）\n  -include string\n        必须包含的packages，多个使用逗号分隔。优先级比ignore和limit高（使用前缀匹配）\n  -limit string\n        限制的packages，多个使用逗号分隔（使用前缀匹配）\n  -minlen uint\n        两个节点直接最小连线长度（用于更宽的输出）. (default 2)\n  -nodesep float\n        同一列中两个相邻节点之间的最小空间（用于更高的输出）. (default 0.35)\n  -nodeshape string\n        节点形状 (查看graphvis文档，获取更多可用值) (default \"box\")\n  -nodestyle string\n        节点style(查看graphvis文档，获取更多可用值) (default \"filled,rounded\")\n  -nointer\n        忽略未导出的方法\n  -nostd\n        忽略标准库的方法\n  -rankdir string\n        对齐方式 [LR 调用关系从左到右| RL 从右到左| TB 从上到下| BT 从下到上] (default \"LR\")\n  -skipbrowser\n        不打开浏览器\n  -tags build tags\n        支持传入build tags\n  -tests\n        包含测试代码\n  -version\n        Show version and exit. \n```\n\n### **使用示例**\n\n### **1. 最简单的命令如下：**\n\n```text\ngo-callvis .\n```\n\n此命令会在当前目录进行分析，如果没有错误，会自动打开浏览器，在浏览器中展示图\n\n### **2. 指定package**\n\n```text\ngo-callvis github.com/ofabry/go-callvis\n```\n\n指定的package是main，工具将以main方法作为起始点进行链路生成\n\n### **3. 指定包含单元测试方法的package**\n\n```text\ngo-callvis -tests yourpackage\n```\n\n如果不想从main方法开始，可以使用-tests参数，在想要进行链路生成的package下面创建一个单元测试方法，测试方法中调用你想要作为起始点的方法。\n\n### **4. 输出结果到文件**\n\n以上都是打开浏览器进行交互式浏览和操作，如果只要输出文件，可以使用-file参数\n\n```text\ngo-callvis -file yourfilename -format png  yourpackage\n```\n\n### **5. include、limit、ignore参数**\n\n这三个参数用来控制过滤哪些调用关系（pkg1.FuncA -> pkg2.FuncB，形成一条调用关系，pkg1.FuncA为caller，pkg2.FuncB为callee）。例如代码中频繁出现的log包方法调用，没必要输出到链路中。可以使用ignore参数进行过滤\n\n```text\n go-callvis -ignore yourlogpkg yourpackage\n```\n\n1. 当调用关系中caller的pkg或者callee的pkg有任意一个在include中，则这条关系被保留。\n2. 不满足1时，当调用关系中caller的pkg或者callee的pkg有任意一个不在limit中，则这条关系被过滤。\n3. 不满足1时，当调用关系中caller的pkg或者callee的pkg有任意一个在ignore中，则这条关系被过滤。\n\n### **6. 过滤标准库**\n\n过滤掉代码中频繁使用的标准库方法调用，例如：fmt、math、strings等\n\n```text\n go-callvis -nostd yourpackage\n```\n\n### **7. build tags**\n\ngo build命令可以允许我们传入-tags参数，来控制编译的版本\n\n```text\ngo build -tags release \n```\n\n例如有两个配置文件dev_config.go和release_config.go，内容分别为\n\ndev_config.go\n\n```text\n // +build dev\n\npackage main\n\nvar version = \"DEV\"\n```\n\nrelease_config.go\n\n```text\n// +build release\n\npackage main\n\nconst version = \"RELEASE\"\n```\n\n每个文件都有一个编译选项（+build），编译器会根据-tags传入的参数识别应该编译哪一个文件。从而达到区分环境的效果。\ngo-callvis的tags参数同理。\n\n## 本地代码使用实战\n\n以kcp-go为例\n\n```\ngo-callvis -nostd examples/echo.go\n```\n\n<img src=\"how-to-use-go-callvis-to-see-how-funtion-are-made/image-20230807115955151.png\" alt=\"image-20230807115955151\" style=\"zoom: 67%;\" />\n\nmain包调用情况，点击黄色区域可以查看kcp包的调用情况（会耗时几分钟）\n\n![image-20230807120123267](how-to-use-go-callvis-to-see-how-funtion-are-made/image-20230807120123267.png)\n\n查看函数调用最密集的地方，也是最核心的地方，如下图便是Input，这也是kcp-go中最核心的代码\n\n![image-20230807120312873](how-to-use-go-callvis-to-see-how-funtion-are-made/image-20230807120312873.png)\n\n### 效果图说明\n\n![UntitledImage](how-to-use-go-callvis-to-see-how-funtion-are-made/1926214-20201014100459031-1029465438.png)\n","tags":["go"],"categories":["go"]},{"title":"快速判断一个数是否是2的幂次方","url":"/2023/07/31/quickly-determine-whether-a-number-is-a-power-of-2/","content":"\n如何利用位运算判断一个数是否是2的幂次方，如果是，是2的多少次方\n\n<!--more-->\n\n 将2的幂次方写成二进制形式后，很容易就会发现有一个特点：二进制中只有一个1，并且1后面跟了n个0； 因此问题可以转化为判断1后面是否跟了n个0就可以了。\n\n如果将这个数减去1后会发现，仅有的那个1会变为0，而原来的那n个0会变为1；因此将原来的数与去减去1后的数字进行与运算后会发现为零。\n\n最快速的方法： (number & number - 1) == 0\n\n原因：因为2的N次方换算是二进制为10……0这样的形式(0除外)。与上自己-1的位数，这们得到结果为0。例如。8的二进制为1000；8-1=7，7的二进制为111。两者相与的结果为0。计算如下：\n\n```\n     1000\n   & 0111\n    -------\n     0000\n```\n\n递归实现的代码与非递归实现的代码\n\n```java\npublic class IsTwoPower {\n    public static void main(String[] args) {\n        int n = 1024;\n        if((n & (n - 1) )== 0){\n            System.out.println(\"是2的\" + log2(n) + \"次方\");\n        }else {\n            System.out.println(\"不是2的n次方\");\n        }\n    }\n\n    // 递归实现\n    // 注意跳出递归条件，n == 1返回0效果一样但是多加了一层栈\n    public static int log2_recursion(int n) {\n        if(n == 2) {\n            return 1;\n        }else{\n            return log2_recursion(n >> 1) + 1;\n        }\n    }\n\n    // 非递归实现\n    // 注意跳出循环条件，不要多加\n    public static int log2(int n) {\n        int count = 0;\n        while (n != 1) {\n            n = n >> 1;\n            count ++;\n        }\n        return count;\n    }\n}\n```\n\n扩展1：求一个数n的二进制中的1的个数\n\n了解了(number & number - 1) == 0这个特性以后，我们可以发现利用它可以移除一个数最右边的1，循环移除就可以得到1的个数\n\n```java\n    public static int fun3(int n) {\n        int count = 0;\n        while (n != 0) {\n            n = n & (n - 1);\n            count++;\n        }\n        return count;\n    }\n```\n\n扩展2：数A与数B的二进制位中有多少个数不相同\n\n由于异或的特性，可知只有不同的数异或才为1，那么1的个数就是不相同的个数\n\n```java\n    public static int fun3(int n) {\n        int count = 0;\n        while (n != 0) {\n            n = n & (n - 1);\n            count++;\n        }\n        return count;\n    }\n\n    public static int difference(int i, int j) {\n        int c = i ^ j;\n        return fun3(c);\n    }\n```\n\n","tags":["位运算","Algorithm"],"categories":["位运算"]},{"title":"Cannot Resolve Symbol XXX问题的解决方法汇总","url":"/2023/07/31/Summary-of-solutions-to-the-Cannot-Resolve-Symbol-XXX-Problem/","content":"\n IDEA在使用过程中，会出现各式各样的`Cannot Resolve Symbol xxx`问题，这篇文章总结了所有的情况\n\n<!--more-->\n\n## 第一类:依赖问题\n\n　1、检查项目的pom文件，是否必要的依赖都写清楚了；\n\n　2、是否使用自己的私有库：<repositories>\n\n```\n　<repository>\n　　<id>release</id>\n　　<name>Private  Repository</name>\n　　<url>http://xxxxxx</url>\n　　</repository>\n　　</repositories>\n　　<pluginRepositories>\n　　<pluginRepository>\n　　<id>release</id>\n　　<name>PrivateRepository</name>\n　　<url>http://xxxxxxx</url>\n　　</pluginRepository>\n　　</pluginRepositories>\n```\n\n`pom`文件中有这样的就是使用自身的私有库，库的用户名密码有没有写清楚，一般在maven程序目录的`settings.xml`文件中设置，在<`servers`>标签下设置，类似这样：\n\n```\n<servers>\n　　<server>\n　　<id>nexus</id>\n　　<username>admin</username>\n　　<password>aaaaaaaaaa</password>\n　　</server>\n<servers>　\n```\n\n3、依赖添加正确后，检查本地的类有没有下载下来，一般是找**C:\\Users\\用户名.m2\\repository**或者自己定义的maven仓库目录这个路径下有没有相应的jar包，如果没有的话，就在编译器中打开`Maven Projects` 标签，先进行`clean`一下，再执行`install`，这里与在命令行下执行是一样的效果。\n\n## 第二类:SDK问题\n\n1、 File - Project Structure - Project SDK，看看SDK有没有选，重选一个本地的自己安装的jdk。\n\n2、编译器中的maven有没有设置成功，File - Settings - 搜索maven，Maven home directory，设置为自己安装的maven路径\n\n3、如果还是报错找不到，试试右侧Maven Projects - Report ，刷新样式的按钮，清除下编译器的缓存就好了\n\n## 第三类:POM文件未被正确加载\n\n当pom未被正确加载，module是灰色的，这是新增加的模块没有被正式识别\n\n解决方法：\n\n在idea中点击File–>settings，搜索maven，点击ignored Files，可以看到灰色的模块处于选中状态，去掉选中状态点击保存即可正常使用\n\n![img](Summary-of-solutions-to-the-Cannot-Resolve-Symbol-XXX-Problem/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2JlbmJlbmppbGU=,size_16,color_FFFFFF,t_70.png)\n\n","tags":["debug","Spring Boot"],"categories":["debug"]},{"title":"快排及其优化","url":"/2023/07/23/quicksort-optimize/","content":"\n  快排的split实现和partition实现及其优化\n\n<!--more-->\n\n## 快排的思想\n\n快排的核心思想在于数组的划分，，通常我们将数组的第一个元素定义为比较元素，然后将数组中小于比较元素的数放到左边，将大于比较元素的放到右边，\n\n这样我们就将数组拆分成了左右两部分：小于比较元素的数组；大于比较元素的数组。我们再对这两个数组进行同样的拆分，直到拆分到不能再拆分，数组就自然而然地以升序排列了。\n\n![img](quicksort-optimize/1514171-20181123212307575-952364244.png)\n\n## split算法\n\nsplit算法使用一个单向的指针来对数组进行遍历，首先将数组首元素设置为比较元素，然后将第二个开始的元素依次与比较元素比较，如果大于比较元素则跳过，如果小于比较元素，则将其与前面较大的元素进行交换，将数组中所有元素交换完毕后，再将比较元素放到中间位置。简单来说就是让j在前面扫描所有的数，让i记录小于比较元素的值，j扫描到大于比较元素，就往前移动，然后等扫描到小于比较元素的位置就将其交换。\n\n![img](quicksort-optimize/1514171-20181123212456916-1889158192.png)\n\n```java\n//划分数组\n    public static int split(int a[], int low, int high)\n    {\n        int i = low;    //i指向比较元素的期望位置\n        int x = a[low];    //将该组的第一个元素作为比较元素\n        //从第二个元素开始，若当前元素大于比较元素，将其跳过\n        for(int j = low+1; j <= high; j++)\n            //若找到了小于比较元素的元素，将其与前面较大的元素进行交换\n            if(a[j] <= x)\n            {\n                i++;\n                if(i != j)\n                    swap(a, i, j);\n\n            }\n        swap(a, i, low);     //将比较元素交换到正确的位置上\n        return i;    //返回比较元素的位置\n    }\n```\n\n## partition算法\n\npartition算法使用头尾两个方向相反的指针进行遍历，先将数组第一个元素设置为比较元素，头指针从左至右找到第一个大于比较元素的数，尾指针从右至左找到第一个小于比较元素的数，全部交换完毕后将比较元素放到中间位置。\n\n![img](quicksort-optimize/1514171-20181123213830176-1199589796.png)\n\n```\n//划分数组\n    public static int partition(int a[], int low, int high)\n    {\n        int x = a[low];    //将该数组第一个元素设置为比较元素\n        int i=low;\n        int j=high;\n        while(i < j)\n        {\n            while(i<j && a[i] <= x)\n                i++;\n            while(i<j && a[j] >= x)\n                j--;\n\n\n            if(i!=j)\n                swap(a, i, j);\n        }\n        swap(a, j, low);\n        return j;\n    }\n```\n\n## 快排优化方法\n\n当元素排列趋近有序或者有大量的相同元素，那么快排会退化成O(n2)的算法，可以从以下几个方面优化：\n\n- 三数取中法（Median-of-Three Partitioning）：选择子数组中的三个元素（通常是左端、中间和右端），取它们的中值作为枢纽元素。这样可以减少最坏情况发生的概率，提高排序的效率\n- 插入排序优化：在子数组较小（一般小于10个元素）时，采用插入排序而不是继续使用快速排序。插入排序在小数组上的效率较高，可以减少递归的层数，从而提高整体性能\n- 随机化：随机选择枢纽元素，以减少最坏情况发生的概率\n\n### 三点中值法\n\n```\n//三点中值法\n        public static int partition(int[] arr, int p, int r) {\n            //优化，在p, r, mid之间，选一个中间值作为主元\n            int midIndex = p + ((r - p) >> 1);//中间下标\n            int midValueIndex = -1;//中值的下标\n            if(arr[p] <= arr[midIndex] && arr[p] >= arr[r]) {\n                midValueIndex = p;\n            }else if(arr[r] <= arr[midIndex] && arr[r] >= arr[p]) {\n                midValueIndex = r;\n            }else {\n                midValueIndex = midIndex;\n            }\n            swap(arr, p, midValueIndex);\n            int pivot = arr[p];\n            int left = p + 1; //左侧指针\n            int right = r; //右侧指针\n            while(left <= right) {\n                while(left <= right && arr[left] <= pivot) {\n                    left++;\n                }\n                while(left <= right && arr[right] > pivot) {\n                    right--;\n                }\n                if(left < right) {\n                    swap(arr, left, right);\n                }\n            }\n            swap(arr, p, right);\n            return right;\n        }\n```\n\n三值中值和插入排序的实例\n\n```java\nimport java.util.Arrays;\nimport java.util.Random;\n\npublic class OptimizedQuickSort {\n\n    private static final int INSERTION_THRESHOLD = 10;\n\n    public static void quickSort(int[] arr) {\n        quickSort(arr, 0, arr.length - 1);\n    }\n\n    public static void quickSort(int[] arr, int left, int right) {\n        if (right - left <= INSERTION_THRESHOLD) {\n            insertionSort(arr, left, right);\n        } else {\n            int pivotIndex = medianOfThree(arr, left, right);\n            int pivot = arr[pivotIndex];\n            arr[pivotIndex] = arr[right];\n            arr[right] = pivot;\n\n            int i = left - 1;\n            for (int j = left; j < right; j++) {\n                if (arr[j] <= pivot) {\n                    i++;\n                    int temp = arr[i];\n                    arr[i] = arr[j];\n                    arr[j] = temp;\n                }\n            }\n            int temp = arr[i + 1];\n            arr[i + 1] = arr[right];\n            arr[right] = temp;\n\n            quickSort(arr, left, i);\n            quickSort(arr, i + 2, right);\n        }\n    }\n\n    private static int medianOfThree(int[] arr, int left, int right) {\n        int mid = left + (right - left) / 2;\n        if (arr[left] > arr[mid]) {\n            swap(arr, left, mid);\n        }\n        if (arr[left] > arr[right]) {\n            swap(arr, left, right);\n        }\n        if (arr[mid] > arr[right]) {\n            swap(arr, mid, right);\n        }\n        return mid;\n    }\n\n    private static void insertionSort(int[] arr, int left, int right) {\n        for (int i = left + 1; i <= right; i++) {\n            int key = arr[i];\n            int j = i - 1;\n            while (j >= left && arr[j] > key) {\n                arr[j + 1] = arr[j];\n                j--;\n            }\n            arr[j + 1] = key;\n        }\n    }\n\n    private static void swap(int[] arr, int i, int j) {\n        int temp = arr[i];\n        arr[i] = arr[j];\n        arr[j] = temp;\n    }\n\n    public static void main(String[] args) {\n        int[] arr = {38, 27, 43, 3, 9, 82, 10};\n        quickSort(arr);\n        System.out.println(Arrays.toString(arr)); // Output: [3, 9, 10, 27, 38, 43, 82]\n    }\n}\n\n```\n\n","tags":["Algorithm","数据结构"],"categories":["Algorithm"]},{"title":"事务隔离级别实例","url":"/2023/07/15/transaction-isolation-level-demo/","content":"\n以转账实例演示四种隔离级别\n\n<!--more-->\n\n事务隔离级别有四种，读未提交，读已提交，可重复读，串行化\n\n![image-20230715172836733](transaction-isolation-level-demo/image-20230715172836733.png)\n\n![image-20230715173210891](transaction-isolation-level-demo/image-20230715173210891.png)\n\n演示时先打开两个mysql窗口模拟并发场景![image-20230715173021672](transaction-isolation-level-demo/image-20230715173021672.png)\n\n### 未提交读\n\n脏读就是读取到了另一个事务未提交的数据\n\n先将事务隔离级别切换到未提交读\n\n左右窗口都开启了事务，左窗口先查询，结果正常，右窗口事务只进行更新未提交，左窗口又查询，结果变化了，这就是未提交读\n\n![image-20230715173642328](transaction-isolation-level-demo/image-20230715173642328.png)\n\n### 读已提交\n\n将事务隔离级别改为读已提交\n\n![image-20230715193942820](transaction-isolation-level-demo/image-20230715193942820.png)\n\n在进行一次同样的操作\n\n![image-20230715194220234](transaction-isolation-level-demo/image-20230715194220234.png)\n\n左窗口事务再查询就没有发生变化，右窗口事务提交以后在进行查询才发生变化![image-20230715194336414](transaction-isolation-level-demo/image-20230715194336414.png)\n\n读已提交解决了脏读问题，但是又会出现不可重复读问题\n\n比方说还是在刚刚的场景下：左右窗口同时开事务，左窗口事务查询数据，右窗口添加数据，左窗口查询无法查到，右窗口提交以后左窗口再查询就查到了，但是左窗口的事务还未结束，但是查询到的数据却不一样，这就是不可重复读问题\n\n![image-20230715195144084](transaction-isolation-level-demo/image-20230715195144084.png)\n\n### 可重复读\n\n将事务隔离级别切换为可重复读\n\n![image-20230715195315141](transaction-isolation-level-demo/image-20230715195315141.png)\n\n场景还是一样，在同一事务下查询，观察数据是否变化，提交以后数据是否变化![image-20230715195603759](transaction-isolation-level-demo/image-20230715195603759.png)\n\n可以看到左窗口事务提交以后才能看到更新\n\n但是可重复读无法解决幻读\n\n![image-20230715200019711](transaction-isolation-level-demo/image-20230715200019711.png)\n\n### 串行化\n\n开启串行化\n\n![image-20230715200251299](transaction-isolation-level-demo/image-20230715200251299.png)\n\n![image-20230715200422405](transaction-isolation-level-demo/image-20230715200422405.png)\n\n串行化就是并发事务只允许一个事务操作，等一个事务操作完以后再执行另一个事务\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"如何生成火焰图","url":"/2023/06/28/how-to-generate-a-flame-graph/","content":"\n如何使用perf工具和火焰图工具生成火焰图\n\n<!--more-->\n\n火焰图仅用一张小图，就可以定量展示所有的性能瓶颈的全景图，而不论目标软件有多么复杂。\n传统的性能分析工具通常会给用户展示大量的细节信息和数据， 而用户很难看到全貌，反而容易去优化那些并不重要的地方，经常浪费大量时间和精力却看不到明显效果。传统分析器的另一个缺点是，它们通常会孤立地显示每个函数调用的延时，但很难看出各个函数调用的上下文，而且用户还须刻意区分当前函数本身运行的时间（exclusive time）和包括了其调用其他函数的时间在内的总时间（inclusive time）。\n\n而相比之下，火焰图可以把大量信息压缩到一个大小相对固定的图片当中（通常一屏就可以显示全）。 不怎么重要的代码路径会在图上自然地淡化乃至消失，而真正重要的代码路径则会自然地凸显出来。越重要的，则会显示得越明显。火焰图总是为用户提供最适当的信息量，不多，也不少。\n\n## 1 火焰图简介\n\n官方博客：[https://www.brendangregg.com/flamegraphs.html](https://www.brendangregg.com/flamegraphs.html)，火焰图的源资料皆出自该博客。\n\n火焰图能做什么：\n\n- 可以分析函数执行的频繁程度\n- 可以分析哪些函数经常阻塞\n- 可以分析哪些函数频繁分配内存\n\n以分析程序的性能瓶颈。\n\n![flame](how-to-generate-a-flame-graph/flame.png)\n\n火焰图整个图形看起来就像一个跳动的火焰，这就是它名字的由来。\n火焰图有以下特征（这里以 on-cpu 火焰图为例）：\n\n- 每一列代表一个调用栈，每一个格子代表一个函数\n- 纵轴展示了栈的深度，按照调用关系从下到上排列。最顶上格子代表采样时，正在占用 cpu 的函数。\n- 横轴的意义是指：火焰图将采集的多个调用栈信息，通过按字母横向排序的方式将众多信息聚合在一起。需要注意的是它并不代表时间。\n- 横轴格子的宽度代表其在采样中出现频率，所以一个格子的宽度越大，说明它是瓶颈原因的可能性就越大。\n- 火焰图格子的颜色是随机的暖色调，方便区分各个调用信息。\n- 其他的采样方式也可以使用火焰图， on-cpu 火焰图横轴是指 cpu 占用时间，off-cpu 火焰图横轴则代表阻塞时间。\n- 采样可以是单线程、多线程、多进程甚至是多 host，进阶用法可以参考附录进阶阅读。\n\n### 1.1 火焰图类型\n\n常见的火焰图类型有 On-CPU，Off-CPU，还有 Memory，Hot/Cold，Differential 等等。它们有各自适合处理的场景。\n\n\n\n| 火焰图类型     | 横轴含义                  | 纵轴含义 | 解决问题                                                     | 采样方式                                                   |\n| -------------- | ------------------------- | -------- | ------------------------------------------------------------ | ---------------------------------------------------------- |\n| on-cpu火焰图   | cpu占用时间               | 调用栈   | 找出cpu占用搞的问题函数；分析代码热路径                      | 固定频率采样cpu调用栈                                      |\n| off-cpu火焰图  | 阻塞时间                  | 调用栈   | i/o、网络等阻塞场景导致的性能下降；锁竞争、死锁导致的性能下降问题 | 固定频率采样阻塞事件调用栈                                 |\n| 内存火焰图     | 内存申请/释放函数调用次数 | 调用栈   | 内存泄漏问题；内存占用高的对象/申请内存多的函数；虚拟内存或物理内存泄漏问题 | 有四种方式：跟踪malloc/free；跟踪brk；跟踪mmap；跟踪页错误 |\n| Hot/Cold火焰图 | on-cpu和off-cpu综合展示   | 调用栈   | 需要结合cpu占用以及阻塞分析的场景；off-cpu火焰图无法直观判断的场景 | on-cpu火焰图和off-cpu火焰图结合                            |\n|                |                           |          |                                                              |                                                            |\n\n### 1.2 什么时候使用 On-CPU 火焰图? 什么时候使用 Off-CPU 火焰图呢?\n\n取决于当前的瓶颈到底是什么：\n\n- 如果是 CPU 则使用 On-CPU 火焰图,\n- 如果是 IO 或锁则使用 Off-CPU 火焰图.\n- 如果无法确定, 那么可以通过压测工具来确认：\n- 通过压测工具看看能否让 **CPU 使用率趋于饱和**, 如果能那么使用 On-CPU 火焰图\n- 如果不管怎么压, **CPU 使用率始终上不来**, 那么多半说明程序被 IO 或锁卡住了, 此时适合使用 Off-CPU 火焰图.\n- 如果还是确认不了, 那么不妨 On-CPU 火焰图和 Off-CPU 火焰图都搞搞, 正常情况下它们的差异会比较大, 如果两张火焰图长得差不多, 那么通常认为 CPU 被其它进程抢占了\n\n### 1.3 火焰图分析技巧\n\n1. 纵轴代表调用栈的深度（栈桢数），用于表示函数间调用关系：下面的函数是上面函数的父函数。\n2. 横轴代表调用频次，一个格子的宽度越大，越说明其可能是瓶颈原因。\n3. 不同类型火焰图适合优化的场景不同，比如 on-cpu 火焰图适合分析 cpu 占用高的问题函数，off-cpu 火焰图适合解决阻塞和锁抢占问题。\n4. 无意义的事情：横向先后顺序是为了聚合，跟函数间依赖或调用关系无关；火焰图各种颜色是为方便区分，本身不具有特殊含义\n5. 多练习：进行性能优化有意识的使用火焰图的方式进行性能调优（如果时间充裕）\n\n## 2 如何绘制火焰图？\n\n### 2.1 生成火焰图的流程\n\nBrendan D. Gregg 的 Flame Graph 工程实现了一套生成火焰图的脚本。Flame Graph 项目位于 GitHub上\n[https://github.com/brendangregg/FlameGraph](https://github.com/brendangregg/FlameGraph)\n\n当GitHub网络不通畅的时候可以使用码云的链接：\ngit clone [https://gitee.com/mirrors/FlameGraph.git](https://gitee.com/mirrors/FlameGraph.git)\n\n用 git 将其 clone下来\n\n\n生成和创建火焰图需要如下几个步骤\n\n| 流程       | 描述                                                         | 脚本                               |\n| ---------- | ------------------------------------------------------------ | ---------------------------------- |\n| 捕获堆栈   | 使用 perf/systemtap/dtrace 等工具抓取程序的运行堆栈          | perf/systemtap/dtrace              |\n| 折叠堆栈   | trace 工具抓取的系统和程序运行每一时刻的堆栈信息, 需要对他们进行分析组合, 将重复的堆栈累计在一起, 从而体现出负载和关键路径 | FlameGraph 中的 stackcollapse 程序 |\n| 生成火焰图 | 分析 stackcollapse 输出的堆栈信息生成火焰图                  | flamegraph.pl                      |\n|            |                                                              |                                    |\n\n\n\n不同的 trace 工具抓取到的信息不同, 因此 Flame Graph 提供了一系列的 stackcollapse 工具.\n\n| stackcollapse                | 描述                                       |\n| ---------------------------- | ------------------------------------------ |\n| stackcollapse.pl             | for DTrace stacks                          |\n| stackcollapse-perf.pl        | for Linux perf_events “perf script” output |\n| stackcollapse-pmc.pl         | for FreeBSD pmcstat -G stacks              |\n| stackcollapse-stap.pl        | for SystemTap stacks                       |\n| stackcollapse-instruments.pl | for XCode Instruments                      |\n| stackcollapse-vtune.pl       | for Intel VTune profiles                   |\n| stackcollapse-ljp.awk        | for Lightweight Java Profiler              |\n| stackcollapse-jstack.pl      | for Java jstack(1) output                  |\n| stackcollapse-gdb.pl         | for gdb(1) stacks                          |\n| stackcollapse-go.pl          | for Golang pprof stacks                    |\n| stackcollapse-vsprof.pl      | for Microsoft Visual Studio profiles       |\n\n\n**查看帮助**\n`./FlameGraph/flamegraph.pl -h`\n\n### 2.2 安装 perf工具\n\nperf 命令(performance 的缩写)讲起, 它是 Linux 系统原生提供的性能分析工具, 会返回 CPU 正在执行的函数名以及调用栈(stack)\n\n具体用法：\n\n- **perf Examples** [https://www.brendangregg.com/perf.html](https:///www.brendangregg.com/perf.html)\n- **Linux kernel profiling with perf** [https://perf.wiki.kernel.org/index.php/Tutorial](https://perf.wiki.kernel.org/index.php/Tutorial)\n\n#### 2.2.1 安装perf\n\nubuntu下\n\n```console\n# apt install linux-tools-common\n```\n\ncentos下\n\n```\nyum install perf\n```\n\n#### 2.2.2 测试perf是否可用\n\n```bash\n# perf record -F 99 -a -g -- sleep 10    \n```\n\n如果报错\n\n> WARNING: perf not found for kernel **4.15.0-48**\n>\n> You may need to install the following packages for this specific kernel:\n> linux-tools-4.15.0-48-generic\n> linux-cloud-tools-4.15.0-48-generic\n>\n> You may also want to install one of the following packages to keep up to date:\n> linux-tools-generic\n> linux-cloud-tools-generic\n>\n> apt install linux-tools-generic\n> apt install linux-cloud-tools-generic\n\n\n则需要安装linux-tools-generic和linux-cloud-tools-generic，但需选择对应的版本，比如提示的是**4.15.0-48，则我们安装4.15.0-48版本**。\n\n> \\# apt-get install linux-tools-4.15.0-48-generic linux-cloud-tools-4.15.0-48-generic linux-tools-generic linux-cloud-tools-generic\n\n再次测试\n\n```bash\n# perf record -F 99 -a -g -- sleep 10    \n```\n\n如果没有报错则在执行的目录产生perf.data\n\n![image-20230806204937168](how-to-generate-a-flame-graph/image-20230806204937168.png)\n\n#### 2.2.3 perf常用命令\n\n查看帮助文档，perf功能非常强大，我们这里只关注record和report功能，record和report也可以继续通过二级命令查询帮助文档。\n\n**perf -h**\n\n常用的五个命令：\n\n- perf list：查看当前软硬件环境支持的性能事件\n- perf stat：分析指定程序的性能概况\n- perf top：实时显示系统/进程的性能统计信息\n- **perf record**：记录一段时间内系统/进程的性能事件perf report：读取perf record生成的perf.data文件，并显示分析数据（生成火焰图用的采集命令）\n- perf report：交互式命令查看资源使用情况\n\n### 2.3 perf 采集数据\n\n```\nperf record -F 99 -p 3887 -g -- sleep 30\n```\n\nperf record 表示采集系统事件, 没有使用 -e 指定采集事件, 则默认采集 cycles(即 CPU clock 周期), -F 99 表示每秒 99 次, -p 13204 是进程号, 即对哪个进程进行分析, -g 表示记录调用栈, sleep 30 则是持续 30 秒.\n\n一定要加上 - g，否则无法记录数据！\n\n> -F 指定采样频率为 99Hz(每秒99次), 如果 99次 都返回同一个函数名, 那就说明 CPU 这一秒钟都在执行同一个函数, 可能存在性能问题.\n\n运行后会产生一个庞大的文本文件. 如果一台服务器有 16 个 CPU, 每秒抽样 99 次, 持续 30 秒, 就得到 47,520 个调用栈, 长达几十万甚至上百万行.\n\n为了便于阅读, perf record 命令可以统计每个调用栈出现的百分比, 然后从高到低排列.\n\n```\nperf report -n --stdio\n```\n\n### 2.4 生成火焰图\n\n1. 首先用 **perf script** 工具对 perf.data 进行解析\n\n> \\# 生成折叠后的调用栈\n> perf script -i perf.data &> perf.unfold\n\n这里在任意文件夹都可使用\n\n2. 然后将解析出来的信息存下来, 供生成火焰图\n\n用 **stackcollapse-perf.pl** 将 perf 解析出的内容 **perf.unfold** 中的符号进行折叠 :\n\n> \\# 在FlameGraph同路径下的文件夹生成火焰图\n> \\# ./FlameGraph/stackcollapse-perf.pl perf.unfold &> perf.folded\n>\n> 或者使用全路径\n>\n> /opt/rh/FlameGraph/stackcollapse-perf.pl perf.unfold &> perf.folded\n\n3. 最后生成 svg 图\n\n> \\# ./FlameGraph/flamegraph.pl perf.folded > perf.svg\n>\n> /opt/rh/FlameGraph/flamegraph.pl perf.folded > perf.svg\n\n## 3.1 火焰图的含义\n\n火焰图是基于 stack 信息生成的 SVG 图片, 用来展示 CPU 的调用栈。\n\n- y 轴表示调用栈, 每一层都是一个函数. 调用栈越深, 火焰就越高, 顶部就是正在执行的函数, 下方都是它的父函数.\n- x 轴表示抽样数, 如果一个函数在 x 轴占据的宽度越宽, 就表示它被抽到的次数多, 即执行的时间长. 注意, x 轴不代表时间, 而是所有的调用栈合并后, 按字母顺序排列的.\n- 火焰图就是看顶层的哪个函数占据的宽度最大. 只要有 “平顶”(plateaus), 就表示该函数可能存在性能问题。\n- 颜色没有特殊含义, 因为火焰图表示的是 CPU 的繁忙程度, 所以一般选择暖色调.\n\n## 4 互动\n\n火焰图是 SVG 图片，可以与用户互动\n\n火焰的每一层都会标注函数名，鼠标悬浮时会显示完整的函数名、抽样抽中的次数、占据总抽样次数的百分比。下面是一个例子\n\n在某一层点击，火焰图会水平放大，该层会占据所有宽度，显示详细信息。\n\n![image-20230806210451419](how-to-generate-a-flame-graph/image-20230806210451419.png)\n","tags":["perf"],"categories":["perf"]},{"title":"go中slice扩容机制","url":"/2023/06/12/slice-expansion-mechanism-in-go/","content":"\nGo1.18前后扩容机制的区别\n\n<!--more-->\n\n## Go1.17及以前\n\n### 扩容机制\n\n过去的扩容机制主要分为两个过程：第一步是分配新的内存空间，第二步是将原有切片内容进行复制。分配新空间时候需要估计大致容量，然后再确定容量。\n\n根据该切片当前容量选择不同的策略：\n\n- 如果期望容量大于当前容量的两倍，就会使用期望容量\n- 如果当前切片的长度小于 1024，容量就会翻倍\n- 如果当前切片的长达大于 1024，每次扩容 25% 的容量，直到新容量大于期望容量\n- 在进行循环1.25倍计算时，最终容量计算值发生溢出，即超过了int的最大范围，则最终容量就是新申请的容量\n\n对于切片的扩容\n\n- 当切片比较小的，采用较大的扩容倍速进行扩容，避免频繁扩容，从而减少内存分配的次数和数据拷贝的代价\n- 当切片较大的时，采用较小的扩容倍速，主要避免空间浪费\n\n![image-20230812151240785](slice-expansion-mechanism-in-go/image-20230812151240785.png)\n\n### 旧规则存在的问题\n\n我们知道，slice扩容时会调用`runtime.growslice`函数(不熟悉slice底层原理的同学可以先看看这篇[《Go语言切片剖析》](https://mp.weixin.qq.com/s/vIX5NHtDTaqAu2WVUwn6WA))。这里我们只关注该函数slice计算容量部分的逻辑，计算方法如下:\n\n```go\n// runtime/slice.go\n// et：表示slice的一个元素；old：表示旧的slice； cap：表示新切片需要的容量；\nfunc growslice(et *_type, old slice, cap int) slice {\n\tif cap < old.cap {\n\t\tpanic(errorString(\"growslice: cap out of range\"))\n\t}\n\n\tif et.size == 0 {\n\t\t// append should not create a slice with nil pointer but non-zero len.\n\t\t// We assume that append doesn't need to preserve old.array in this case.\n\t\treturn slice{unsafe.Pointer(&zerobase), old.len, cap}\n\t}\n\n\tnewcap := old.cap\n        // 两倍扩容\n\tdoublecap := newcap + newcap\n        // 新切片需要的容量大于当前容量的两倍，则直接按照新切片需要的容量扩容\n\tif cap > doublecap {\n\t\tnewcap = cap\n\t} else {\n        // 原 slice 容量小于 1024 的时候，新 slice 容量按2倍扩容\n\t\tif old.cap < 1024 {\n\t\t\tnewcap = doublecap\n\t\t} else { // 原 slice 容量超过 1024，新 slice 容量变成原来的1.25倍。\n\t\t\t// Check 0 < newcap to detect overflow\n\t\t\t// and prevent an infinite loop.\n\t\t\tfor 0 < newcap && newcap < cap {\n\t\t\t\tnewcap += newcap / 4\n\t\t\t}\n\t\t\t// Set newcap to the requested cap when\n\t\t\t// the newcap calculation overflowed.\n\t\t\tif newcap <= 0 {\n\t\t\t\tnewcap = cap\n\t\t\t}\n\t\t}\n\t}\n\n        // 后半部分还对 newcap 作了一个内存对齐，这个和内存分配策略相关。进行内存对齐之后，新 slice 的容量是要 大于等于 老 slice 容量的 2倍或者1.25倍。\n\tvar overflow bool\n\tvar lenmem, newlenmem, capmem uintptr\n\t// Specialize for common values of et.size.\n\t// For 1 we don't need any division/multiplication.\n\t// For sys.PtrSize, compiler will optimize division/multiplication into a shift by a constant.\n\t// For powers of 2, use a variable shift.\n\tswitch {\n\tcase et.size == 1:\n\t\tlenmem = uintptr(old.len)\n\t\tnewlenmem = uintptr(cap)\n\t\tcapmem = roundupsize(uintptr(newcap))\n\t\toverflow = uintptr(newcap) > maxAlloc\n\t\tnewcap = int(capmem)\n\tcase et.size == sys.PtrSize:\n\t\tlenmem = uintptr(old.len) * sys.PtrSize\n\t\tnewlenmem = uintptr(cap) * sys.PtrSize\n\t\tcapmem = roundupsize(uintptr(newcap) * sys.PtrSize)\n\t\toverflow = uintptr(newcap) > maxAlloc/sys.PtrSize\n\t\tnewcap = int(capmem / sys.PtrSize)\n\tcase isPowerOfTwo(et.size):\n\t\tvar shift uintptr\n\t\tif sys.PtrSize == 8 {\n\t\t\t// Mask shift for better code generation.\n\t\t\tshift = uintptr(sys.Ctz64(uint64(et.size))) & 63\n\t\t} else {\n\t\t\tshift = uintptr(sys.Ctz32(uint32(et.size))) & 31\n\t\t}\n\t\tlenmem = uintptr(old.len) << shift\n\t\tnewlenmem = uintptr(cap) << shift\n\t\tcapmem = roundupsize(uintptr(newcap) << shift)\n\t\toverflow = uintptr(newcap) > (maxAlloc >> shift)\n\t\tnewcap = int(capmem >> shift)\n\tdefault:\n\t\tlenmem = uintptr(old.len) * et.size\n\t\tnewlenmem = uintptr(cap) * et.size\n\t\tcapmem, overflow = math.MulUintptr(et.size, uintptr(newcap))\n\t\tcapmem = roundupsize(capmem)\n\t\tnewcap = int(capmem / et.size)\n\t}\n}\n\n```\n\n打印扩容的容量\n\n```go\npackage main\n\nimport (\n    \"fmt\"\n)\n\nfunc main() {\n    for i := 0; i < 2000; i += 100 {\n        fmt.Println(i, cap(append(make([]bool, i), true)))\n    }\n}\n```\n\n该程序的输出如下(旧版本的扩容规则):\n\n```\n// 第一列是切片的旧容量\n// 第二列是扩容后的容量\n0 8\n100 208\n200 416\n300 640\n400 896\n500 1024\n600 1280\n700 1408\n800 1792\n900 2048\n1000 2048\n1100 1408 <-- 在这个点，扩容后的新容量比上面的容量要小\n1200 1536\n1300 1792\n1400 1792\n1500 2048\n1600 2048\n1700 2304\n1800 2304\n1900 2688\n```\n\n![image-20230812152116742](slice-expansion-mechanism-in-go/image-20230812152116742.png)\n\n## Go1.18后：更加平滑的扩容算法\n\n从`go1.18`开始，slice容量的计算方法被改为了这样:\n\n```go\n// 只关心扩容规则的简化版growslice\nfunc growslice(old, cap int) int {\n    newcap := old\n    doublecap := newcap + newcap\n    if cap > doublecap {\n        newcap = cap\n    } else {\n        const threshold = 256 // 不同点1\n        if old.cap < threshold {\n            newcap = doublecap\n        } else {\n            for 0 < newcap && newcap < cap {\n                newcap += (newcap + 3*threshold) / 4 // 不同点2\n            }\n            if newcap <= 0 {\n                newcap = cap\n            }\n        }\n    }\n    return newcap\n}\n```\n\n首先是双倍容量扩容的最大阈值**从1024降为了256**，只要超过了256，就开始进行缓慢的增长。其次是增长比例的调整，之前超过了阈值之后，基本为恒定的1.25倍增长，而现在超过了阈值之后，增长比例是会动态调整的。\n\n![image-20230812152404106](slice-expansion-mechanism-in-go/image-20230812152404106.png)\n\n## 内存对齐\n\n分析完两个版本的扩容策略之后，再看前面的那段测试代码，就会发现扩容之后的容量并不是严格按照这个策略的。\n\n那是为什么呢？\n\n实际上，growslice 的后半部分还有更进一步的优化（内存对齐等），靠的是 roundupsize 函数，在计算完 newcap 值之后，还会有一个步骤计算最终的容量：\n\n```\ncapmem = roundupsize(uintptr(newcap) * ptrSize)\nnewcap = int(capmem / ptrSize)\n```\n\n","tags":["go"],"categories":["go"]},{"title":"DDD架构中数据传递的过程","url":"/2023/05/11/the-process-of-data-transfer-in-DDD-architecture/","content":"\nDDD架构中如何domain层和infrastructure如何传递数据，以及作用\n\n<!--more-->\n\n### 传统的三层架构\n\n传统的三层架构包括表示层、业务逻辑层和数据访问层，它的设计目标是将系统划分为独立的、高内聚、低耦合的模块，使得每个模块的职责清晰、易于维护和升级。在这种架构中，业务逻辑层是系统的核心，它处理所有的业务逻辑，而表示层和数据访问层则分别负责与用户交互和访问数据。\n\n![1895018-20230314115040094-875486601](the-process-of-data-transfer-in-DDD-architecture/1895018-20230314115040094-875486601-16843216712372.png)\n\nMVC模式中业务逻辑层直接与数据访问层交互，导致与数据层面有较强的依赖关系，以致于不便后续数据层面的更新，并且也会导致自身的庞大和臃肿，不便后续的维护。\n\n### 领域驱动设计的四层架构\n\n![2-02-16826858766012](the-process-of-data-transfer-in-DDD-architecture/2-02-16826858766012.png)\n\n领域驱动设计的四层架构则更加强调领域模型的设计和实现，它包括表示层、应用层、领域层和基础设施层。在这种架构中，领域层是系统的核心，它包含了系统的领域模型和业务逻辑，而应用层负责协调各个领域层的操作，提供应用程序的服务接口，表示层负责与用户交互，基础设施层负责提供与外部系统的交互和数据存储等服务。\n\n领域层只关注业务逻辑的实现，提供领域数据的接口，而不关注具体数据如何操作，基础层实现领域层提供的接口，配合DAO和po完成具体的方法。\n\n#### 领域层包结构\n\n![image-20230517192910187](the-process-of-data-transfer-in-DDD-architecture/image-20230517192910187.png)\n\nactivity, award,strategy是三个领域，领域下在repository包中定义具体的数据接口。\n\n#### 基础层包结构\n\ndao包含数据访问逻辑，po是持久化对象，repository是对领域层提供的接口的实现\n\n![image-20230517193502810](the-process-of-data-transfer-in-DDD-architecture/image-20230517193502810.png)\n\n在infrastructure层下实现这些接口，DAO做数据层面的交互，处理数据访问逻辑，可以实现解耦合。\n\n并且，仓储层可以在领域模型的操作之上实施领域规则。这意味着在执行数据访问操作之前或之后，可以在仓储中添加额外的逻辑来保持领域模型的一致性和完整性。\n\n![image-20230517200449992](the-process-of-data-transfer-in-DDD-architecture/image-20230517200449992.png)\n\n仓储层可以负责将基础设施层的数据映射为领域模型所需的数据结构，以及将领域模型的数据转换为基础设施层所需的格式。这种转换和映射逻辑可以在仓储中集中处理，减少领域模型与基础设施层之间的耦合。如转换成聚合根。\n\n![image-20230517200645985](the-process-of-data-transfer-in-DDD-architecture/image-20230517200645985.png)\n\n过在仓储层中定义接口，可以实现技术的灵活性，使得可以更换底层数据访问技术或使用不同的数据存储策略，而无需修改领域模型。同时，仓储接口也有助于编写针对领域模型的单元测试，因为可以使用模拟或存根实现来模拟数据访问。\n","tags":["设计模式"],"categories":["设计模式"]},{"title":"理清@Autowired和@Resource的区别和联系","url":"/2023/04/17/difference-between-resource-and-autowired/","content":"\n使用方法以及区别联系\n\n<!--more-->\n\n### 联系\n\n@Autowired和@Resource注解都是作为bean对象注入的时候使用的\n两者都可以声明在字段和setter方法上\n注意：如果声明在字段上，那么就不需要再写setter方法。但是本质上，该对象还是作为set方法的实参，通过执行set方法注入，只是省略了setter方法罢了\n\n### 区别\n\n@Autowired注解是Spring提供的，而@Resource注解是J2EE本身提供的，JDK1.6之后才能使用\n@Autowird注解默认通过byType方式注入，而@Resource注解默认通过byName方式注入\n@Autowired注解注入的对象需要在IOC容器中存在，否则需要加上属性required=false，表示忽略当前要注入的bean，如果有直接注入，没有跳过，不会报错\n\n#### 什么是byType，什么是byName\n\n```\n<bean id=\"userService\" class=\"com.test.UserServiceImpl\">\n</bean> \n```\n\n```\n@Autowired\nprivate UserService userService;\n```\n\n此处byName就是拿变量名userService去匹配IOC容器的iduserService，匹配成功；而byType就是拿变量类型UserService去匹配IOC容器的idcom.test.UserService.UserServiceImpl，因为UserServiceImpl是UserService实现，所以也匹配成功\n\n### @Autowird注解的使用\n\n@Autowird默认的注入方式为byType，也就是根据类型匹配，当有多个实现时，则通过byName注入，也可以通过配合@Qualifier注解来显式指定name值，指明要使用哪个具体的实现类\n\n举例：\n\n首先有一个接口UserService和两个实现类UserServiceImpl1和UserServiceImpl2，并且这两个实现类已经加入到Spring的IOC容器中了\n\n```\n@Service\npublic class UserServiceImpl1 implements UserService\n\n@Service\npublic class UserServiceImpl2 implements UserService\n```\n\n通过@Autowired注入使用\n\n```\n@Autowired\nprivate UserService userService;\n```\n\n根据上面的步骤，可以很容易判断出，直接这么使用是会报错的\n原因：首先通过byType注入，判断UserService类型有两个实现，无法确定具体是哪一个，于是通过byName方式，这里的变量名userService也无法匹配IOC容器中id（此处指的userServiceImpl1和userServiceImpl2），于是报错。\n\n注意：通过注解注入到IOC容器的id值默认是其类名首字母小写\n\n解决方案\n\n方式一：\n\n// 方式一：改变变量名\n\n```\n@Autowired\nprivate UserService userServiceImpl1;\n```\n\n方式二：\n\n// 方式二：配合@Qualifier注解来显式指定name值\n\n```\n@Autowired\n@Qualifier(value = \"userServiceImpl1\")\nprivate UserService userService;\n```\n\n### @Resource注解的使用\n\n步骤：@Resource默认通过byName注入，如果没有匹配则通过byType注入\n\n举例：\n\n```\n@Service\npublic class UserServiceImpl1 implements UserService\n\n@Service\npublic class UserServiceImpl2 implements UserService\n\n@Resource\nprivate UserService userService;\n```\n\n首先通过byName匹配，变量名userService无法匹配IOC容器中任何一个id（这里指的userServiceImpl1和userServiceImpl2），于是通过byType匹配，发现类型UserService的实现类有两个，仍然无法确定，于是BeanCreationException异常。\n\n同时@Resource还有两个重要的属性：name和type，用来显式指定byName和byType方式注入\n\n#### @Resource装配顺序\n\n```\n/ 1. 默认方式：byName\n@Resource  \nprivate UserService userDao; \n\n// 2. 指定byName\n@Resource(name=\"userService\")  \nprivate UserService userService; \n\n// 3. 指定byType\n@Resource(type=UserService.class)  \nprivate UserService userService; \n\n// 4. 指定byName和byType\n@Resource(name=\"userService\",type=UserService.class)  \nprivate UserService userService; \n```\n\n既没指定name属性，也没指定type属性：默认通过byName方式注入，如果byName匹配失败，则使用byType方式注入（也就是上面的那个例子）\n指定name属性：通过byName方式注入，把变量名和IOC容器中的id去匹配，匹配失败则报错\n指定type属性：通过byType方式注入，在IOC容器中匹配对应的类型，如果匹配不到或者匹配到多个则报错\n同时指定name属性和type属性：在IOC容器中匹配，名字和类型同时匹配则成功，否则失败\n","tags":["Spring Boot","Java"],"categories":["Java","Spring Boot"]},{"title":"git使用过程中遇到的问题以及解决方法","url":"/2023/04/09/the-usage-of-git/","content":"\n记录了git使用过程中遇到的问题以及解决方法\n\n<!--more-->\n\n### git stash暂存文件\n\n当前分支还未完成所有的工作，然而又需要切换分支或者不能继续工作，可以采用`git stash`命令，切换回来以后再采用`git stash pop`命令切回\n\n在idea 2020版中使用`git stash`命令有几率丢失文件\n\n所以也可以commit 之后再切换分支然后再reset\n\n### git pull拉取分支\n\n在团队开发时，可能出现增加了其他文件和修改统一文件的情况，此时需要`git pull`先合并再push，若不想合并则先fetch\n\n### git pull和git fetch的区别\n\n#### 目的不同\n\n**git fetch**：从远程获取最新版本到本地，但不会自动 merge，用于从远程跟踪分支下载和查看其他人完成的最新提交，但不将这些提交合并到本地存储库中。它从远程存储库中获取更改并将其存储在本地存储库中。\n\n**git pull**：从远程获取最新版本并 merge 到本地，它会自动将提交合并到您的本地存储库中，而无需查看提交。\n\n#### 用途不同\n\n**git fetch**：Fetch 只是通过将提交从远程存储库传输到本地存储库来使远程存储库的本地副本保持最新。将提交导入到本地分支将允许您跟上其他人所做的更改。\n\n**git pull**：Pull 将更改引入本地代码存储库，以使用远程存储库更新本地存储库。\n\n#### 用法不同\n\n**git fetch**：当您想要查看其他人正在处理的内容时，Fetch 命令非常有用，这使您可以在将更改与本地存储库集成之前轻松查看其他开发人员推送的提交。您可以通过使用命令“git fetch ”来做到这一点，该命令从远程存储库中获取所有分支。\n\n**git pull**：您可以使用命令“git pull ”来执行拉取，该命令检索分支的远程副本并将其与本地副本合并。这与使用命令“git fetch ”后跟“git merge ”完全相同。\n\n#### 远端跟踪分支不同\n\n**git fetch**：Git fetch能够直接更改远端跟踪分支。\n\n**git pull**：git pull无法直接对远程跟踪分支操作，我们必须先切回本地分支然后创建一个新的commit提交。\n\n### 使用 git revert 回滚某次的提交\n\n想象这么一个场景，你的项目最近有2个版本要上线，这两个版本还伴随着之前遗留的 bug 的修复，一开始的时候，你将 bug 修复在了第一个版本的 release 分支上，突然在发版前一天，测试那边反馈，需要把第一个版本修复 bug 的内容改在第二个版本上，这个时候，第一个版本的集成分支的提交应该包括了第一个版本的功能内容，遗留 bug 修复的提交和其他同事提交的内容，想要通过 reset 的方式粗暴摘除之前的关于 bug 修复的 commit 肯定是不行的，同时，这种做法比较危险，此时，我们既不想破坏之前的提交记录，又想撤回我们遗留 bug 的 commit 记录应该怎么做呢？git revert 就派上了用场。\n\n `git revert <commit-id>` 针对普通 commit\n\n`git revert <commit-id> -m` 针对 merge 的 commit\n\n下面就用一个案例来理解一下这个命令，如下图所示，假设被红框框起来的地方是会引起 bug 的一次提交，在他的提交之后，又进行了2次提交，其中包含了其它同事的提交。\n\n![image-20210519142702752.png](the-usage-of-git/f36331158e084072a033802bf4fa0478tplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp)\n\n此时想把引起提交的 bug 的干掉，执行 `git revert 1121932`，执行操作后，再打开查看日志，如下图所示，可以看到是新增了一条 commit 记录，这个 commit 的产生的 msg 是自动生成的，Revert 开头，后面跟撤回的 commit-msg 信息 之前的 commit 记录并没有消失，此时也达到了代码回退的效果\n\n![image-20210519142824836.png](the-usage-of-git/9729e537218e4609b54df3e899fd332ftplv-k3u1fbpfcp-zoom-in-crop-mark4536000.awebp)\n\n此外 git revert 也可以回滚多次的提交\n\n语法：`git revert [commit-id1] [commit-id2] ...`  注意这是一个前开后闭区间，即不包括 commit1 ，但包括 commit2 。\n\n回滚我们的提交有二种方式，一种是上文提到的`git revert`命令外，还可以使用 `git reset` 命令，那么它们两者有什么区别呢？\n\n`git revert` 会新建一条 commit 信息，来撤回之前的修改。\n\n`git reset` 会直接将提交记录退回到指定的 commit 上。\n\n对于个人的 feature 分支而言，可以使用 `git reset` 来回退历史记录，之后使用 `git push --force` 进行推送到远程，但是如果是在多人协作的集成分支上，不推荐直接使用 `git reset` 命令，而是使用更加安全的 `git revert` 命令进行撤回提交。这样，提交的历史记录不会被抹去，可以安全的进行撤回。\n","tags":["git"],"categories":["git"]},{"title":"使用go实现一个简单的高性能RPC","url":"/2023/04/02/implment-a-high-performance-rpc-with-go/","content":"\nRPC是远程过程调用（**Remote Procedure Call**）的缩写形式。RPC调用的原理其实很简单，它类似于三层构架的C/S系统，第三方的客户程序通过接口调用RPC内部的标准或自定义函数，获得函数返回的数据进行处理后显示或打印。\n\n<!--more-->\n\n[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc) 是基于Go语言标准库 **net/rpc** 扩展的远程过程调用框架，它具有以下特性：\n\n- 基于TCP传输层协议\n- 支持多种**压缩格式**：gzip、snappy、zlib；\n- 基于二进制的 **Protocol Buffer** 序列化协议：具有协议编码小及高扩展性和跨平台性；\n- 支持生成工具：TinyRPC提供的 **protoc-gen-tinyrpc** 插件可以帮助开发者快速定义自己的服务；\n- 支持自定义序列化器\n\n[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc) 的源代码仅有一千行左右，通过学习 **TinyRPC** ，开发者可以得到以下收获：\n\n- 代码简洁规范\n- 涵盖大多数 Go 语言基础用法和高级特性\n- 单元测试编写技巧\n- TCP流中处理数据包的技巧\n- RPC框架的设计理念\n\n## 基于TCP的TinyRPC协议\n\n在TinyRPC中，请求消息由TinyRPC客户端的应用程序发出，在TCP的字节流中，请求消息分为三部分：\n\n- 由可变长量编码的 **uint 类型**用来标识请求头的长度；\n- 基于自定义协议编码的请求头部信息\n- 基于 **Protocol Buffer** 协议编码的请求体，见图所示：\n\n![img](implment-a-high-performance-rpc-with-go/v2-62b7995089963eb1477a66476c18f3f3_b.jpg)\n\n在TinyRPC中，响应消息由TinyRPC服务端的应用程序响应，在TCP的字节流中，响应消息分为三部分：\n\n- 由可变长量编码的 **uint 类型**用来标识响应头的长度；\n- 基于自定义协议编码的响应头部信息\n- 基于 **Protocol Buffer** 协议编码的响应体，见图所示：\n\n![img](implment-a-high-performance-rpc-with-go/v2-512d68763da8ca61ebbaa6735485a768_b.jpg)\n\n其中ID为RPC调用的序号，以便在并发调用时，客户端根据响应的ID序号来判断RPC的调用结果；\n\nError message为调用时发生错误的消息，若该内容为空则表示未出现RPC调用错误；\n\n在请求I/O流中，请求体（Request Body）表示RPC的参数内容；而在响应I/O流中，响应体（Response Body）则表示RPC调用的结果，这些Body在TinyRPC中均采用 **Protocol Buffer** 协议编码。\n\n## 请求头部消息编码\n\n由于[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc)的请求头部是自定义协议编码的，我们可以查看文件[header/header.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/header/header.go)了解它的细节：\n\n```go\n// CompressType type of compressions supported by rpc\ntype CompressType uint16\n\n// RequestHeader request header structure looks like:\n// +--------------+----------------+----------+------------+----------+\n// | CompressType |      Method    |    ID    | RequestLen | Checksum |\n// +--------------+----------------+----------+------------+----------+\n// |    uint16    | uvarint+string |  uvarint |   uvarint  |  uint32  |\n// +--------------+----------------+----------+------------+----------+\ntype RequestHeader struct {\n        sync.RWMutex\n\tCompressType CompressType  // 它表示RPC的协议内容的压缩类型，TinyRPC支持四种压缩类型，Raw、Gzip、Snappy、Zlib\n\tMethod       string  // 方法名\n\tID           uint64  // 请求ID\n\tRequestLen   uint32  // 请求体长度\n\tChecksum     uint32  // 请求体校验 使用CRC32摘要算法\n}\n```\n\n其中 RequestHeader 的编解码过程如下所示：\n\n```go\n\n// Marshal will encode request header into a byte slice\nfunc (r *RequestHeader) Marshal() []byte {\n        r.RLock()\n\tdefer r.RUnlock()\n\tidx := 0\n\theader := make([]byte, MaxHeaderSize+len(r.Method))\n        // 写入uint16类型的压缩类型\n\tbinary.LittleEndian.PutUint16(header[idx:], uint16(r.CompressType))\n\tidx += Uint16Size\n        \n\tidx += writeString(header[idx:], r.Method)\n\tidx += binary.PutUvarint(header[idx:], r.ID)  // 写入uvarint类型的请求ID号\n\tidx += binary.PutUvarint(header[idx:], uint64(r.RequestLen)) // 写入uvarint类型的请求体长度\n\n\tbinary.LittleEndian.PutUint32(header[idx:], r.Checksum)  // 写入uvarint类型的校验码\n\tidx += Uint32Size\n\treturn header[:idx]\n}\n\n// Unmarshal will decode request header into a byte slice\nfunc (r *RequestHeader) Unmarshal(data []byte) (err error) {\n\tr.Lock()\n\tdefer r.Unlock()\n        if len(data) == 0 {\n\t\treturn UnmarshalError\n\t}\n\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = UnmarshalError\n\t\t}\n\t}()\n\tidx, size := 0, 0\n\tr.CompressType = CompressType(binary.LittleEndian.Uint16(data[idx:]))\n\tidx += Uint16Size // 读取uint16类型的压缩类型\n\n\tr.Method, size = readString(data[idx:])\n\tidx += size\n\n\tr.ID, size = binary.Uvarint(data[idx:]) // 读取uvarint类型的请求ID号\n\tidx += size\n\n\tlength, size := binary.Uvarint(data[idx:])   // 读取uvarint类型的请求体长度\n\tr.RequestLen = uint32(length)\n\tidx += size\n\n\tr.Checksum = binary.LittleEndian.Uint32(data[idx:]) // 读取uvarint类型的校验码\n\treturn\n}\n\nfunc readString(data []byte) (string, int) {\n\tidx := 0\n\tlength, size := binary.Uvarint(data)  // 读取一个uvarint类型表示字符的长度\n\tidx += size\n\tstr := string(data[idx : idx+int(length)])\n\tidx += len(str)\n\treturn str, idx\n}\n\nfunc writeString(data []byte, str string) int {\n\tidx := 0\n\tidx += binary.PutUvarint(data, uint64(len(str)))  // 写入一个uvarint类型表示字符长度\n\tcopy(data[idx:], str)\n\tidx += len(str)\n\treturn idx\n}\n```\n\n## 响应头部消息编码\n\n由于[TinyRPC](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc)的响应头部是自定义协议编码的，我们可以查看文件[header/header.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/header/header.go)了解它的细节：\n\n```go\n// ResponseHeader request header structure looks like:\n// +--------------+---------+----------------+-------------+----------+\n// | CompressType |    ID   |      Error     | ResponseLen | Checksum |\n// +--------------+---------+----------------+-------------+----------+\n// |    uint16    | uvarint | uvarint+string |    uvarint  |  uint32  |\n// +--------------+---------+----------------+-------------+----------+\ntype ResponseHeader struct {\n        sync.RWMutex\n\tCompressType CompressType  // 压缩类型\n\tID           uint64  // 响应ID号\n\tError        string  // 错误信息\n\tResponseLen  uint32  // 响应体长度\n\tChecksum     uint32  // 响应体校验码\n}\n```\n\n其中 ResponseHeader 的编解码过程如下所示，与RequestHeader 的编解码过程类似：\n\n```go\n\n// Marshal will encode response header into a byte slice\nfunc (r *ResponseHeader) Marshal() []byte {\n        r.RLock()\n\tdefer r.RUnlock()\n\tidx := 0\n\theader := make([]byte, MaxHeaderSize+len(r.Error))\n\n\tbinary.LittleEndian.PutUint16(header[idx:], uint16(r.CompressType))\n\tidx += Uint16Size\n\n\tidx += binary.PutUvarint(header[idx:], r.ID)\n\tidx += writeString(header[idx:], r.Error)\n\tidx += binary.PutUvarint(header[idx:], uint64(r.ResponseLen))\n\n\tbinary.LittleEndian.PutUint32(header[idx:], r.Checksum)\n\tidx += Uint32Size\n\treturn header[:idx]\n}\n\n// Unmarshal will decode response header into a byte slice\nfunc (r *ResponseHeader) Unmarshal(data []byte) (err error) {\n        r.Lock()\n\tdefer r.Unlock()\n\tif len(data) == 0 {\n\t\treturn UnmarshalError\n\t}\n\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\terr = UnmarshalError\n\t\t}\n\t}()\n\tidx, size := 0, 0\n\tr.CompressType = CompressType(binary.LittleEndian.Uint16(data[idx:]))\n\tidx += Uint16Size\n\n\tr.ID, size = binary.Uvarint(data[idx:])\n\tidx += size\n\n\tr.Error, size = readString(data[idx:])\n\tidx += size\n\n\tlength, size := binary.Uvarint(data[idx:])\n\tr.ResponseLen = uint32(length)\n\tidx += size\n\n\tr.Checksum = binary.LittleEndian.Uint32(data[idx:])\n\treturn\n}\n```\n\n## 头部消息对象池\n\n为了减少创建请求头部对象 **RequestHeader** 和响应头部对象 **ResponseHeader** 的次数**，**我们通过为这两个结构体建立对象池，以便可以进行复用。\n\n同时我们为 *RequestHeader* 和 *ResponseHeader* 都实现了ResetHeader方法，当每次使用完这些对象时，我们调用ResetHeader让结构体内容初始化，随后再把它们丢回对象池里。\n\n代码 [header/pool.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/header/pool.go) 如下：\n\n```go\n\npackage header\n\nimport \"sync\"\n\nvar (\n\tRequestPool  sync.Pool\n\tResponsePool sync.Pool\n)\n\nfunc init() {\n\tRequestPool = sync.Pool{New: func() any {\n\t\treturn &RequestHeader{}\n\t}}\n\tResponsePool = sync.Pool{New: func() any {\n\t\treturn &ResponseHeader{}\n\t}}\n}\n\n// ResetHeader reset request header\nfunc (h *RequestHeader) ResetHeader() {\n\th.Id = 0\n\th.Checksum = 0\n\th.Method = \"\"\n\th.CompressType = 0\n\th.RequestLen = 0\n}\n\n// ResetHeader reset response header\nfunc (h *ResponseHeader) ResetHeader() {\n\th.Error = \"\"\n\th.Id = 0\n\th.CompressType = 0\n\th.Checksum = 0\n\th.ResponseLen = 0\n}\n```\n\n## IO操作\n\nTinyRPC的IO操作函数在[codec/io.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/codec/io.go)中，其中 *sendFrame* 函数会向IO中写入**uvarint**类型的 *size* ，表示要发送数据的长度，随后将该字节slice类型的数据 *data* 写入IO流中。\n\n- 若写入数据的长度为 0 ，此时*sendFrame* 函数会向IO流写入uvarint类型的 0 值；\n- 若写入数据的长度大于 0 ，此时*sendFrame* 函数会向IO流写入uvarint类型的 *len(data)* 值，随后将该字节串的数据 data 写入IO流中。\n\n代码如下所示：\n\n```go\nfunc sendFrame(w io.Writer, data []byte) (err error) {\n\tvar size [binary.MaxVarintLen64]byte\n\n\tif data == nil || len(data) == 0 {\n\t\tn := binary.PutUvarint(size[:], uint64(0))\n\t\tif err = write(w, size[:n]); err != nil {\n\t\t\treturn\n\t\t}\n\t\treturn\n\t}\n\n\tn := binary.PutUvarint(size[:], uint64(len(data)))\n\tif err = write(w, size[:n]); err != nil {\n\t\treturn\n\t}\n\tif err = write(w, data); err != nil {\n\t\treturn\n\t}\n\treturn\n}\n\nfunc write(w io.Writer, data []byte) error {\n\tfor index := 0; index < len(data); {\n\t\tn, err := w.Write(data[index:])\n\t\tif _, ok := err.(net.Error); !ok {\n\t\t\treturn err\n\t\t}\n\t\tindex += n\n\t}\n\treturn nil\n}\n```\n\n*recvFrame* 函数与*sendFrame* 函数类似，首先会向IO中读入**uvarint**类型的 *size* ，表示要接收数据的长度，随后将该从IO流中读取该 *size* 长度字节串。\n\n> 注意，由于 codec 层会传入一个**bufio**类型的结构体，**bufio**类型实现了有缓冲的IO操作，以便减少IO在用户态与内核态拷贝的次数。\n\n- 若 *recvFrame* 函数从IO流读取**uvarint**类型的 *size* 值大于0，随后 *recvFrame* 将该从IO流中读取该 *size* 长度字节串。\n\n```go\nfunc recvFrame(r io.Reader) (data []byte, err error) {\n\tsize, err := binary.ReadUvarint(r.(io.ByteReader))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif size != 0 {\n\t\tdata = make([]byte, size)\n\t\tif err = read(r, data); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn data, nil\n}\n\nfunc read(r io.Reader, data []byte) error {\n\tfor index := 0; index < len(data); {\n\t\tn, err := r.Read(data[index:])\n\t\tif err != nil {\n\t\t\tif _, ok := err.(net.Error); !ok {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tindex += n\n\t}\n\treturn nil\n}\n```\n\n## TinyRPC的压缩器\n\nTinyRPC的压缩器代码部分很短，RawCompressor、GzipCompressor、SnappyCompressor、ZlibCompressor压缩器均实现了Compressor 接口，代码[compressor/compressor.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/compressor/compressor.go)：\n\n```go\ntype CompressType int32\n\nconst (\n\tRaw CompressType = iota\n\tGzip\n\tSnappy\n\tZlib\n)\n// Compressors 四种压缩器的实现\nvar Compressors = map[CompressType]Compressor{\n\tRaw:    RawCompressor{},\n\tGzip:   GzipCompressor{},\n\tSnappy: SnappyCompressor{},\n\tZlib:   ZlibCompressor{},\n}\n// Compressor 压缩器接口\ntype Compressor interface {\n\tZip([]byte) ([]byte, error)\n\tUnzip([]byte) ([]byte, error)\n}\n\n```\n\n## TinyRPC的序列化器\n\nTinyRPC的序列化器的代码部分也很短，ProtoSerializer实现了Serializer接口，它是基于Protocol Buffer的序列化协议，代码[serializer/serializer.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/serializer/serializer.go)：\n\n```go\ntype SerializeType int32\n\ntype Serializer interface {\n\tMarshal(message any) ([]byte, error)\n\tUnmarshal(data []byte, message any) error\n}\n```\n\n## 实现ClientCodec接口\n\n由于TinyRPC是**基于标准库net/rpc**扩展的，所以TinyRPC在codec层需要实现**net/rpc**的**ClientCodec**接口，我们先看看**ClientCodec**的代码：\n\n```go\n// 文件 src/net/rpc/server.go\n\ntype ClientCodec interface {\n\tWriteRequest(*Request, any) error\n\tReadResponseHeader(*Response) error\n\tReadResponseBody(any) error\n\n\tClose() error\n}\n// Request 标准库里的请求体结构\ntype Request struct {\n\tServiceMethod string \n\tSeq           uint64 \n\tnext          *Request \n}\n// Response 标准库里的响应结构\ntype Response struct {\n\tServiceMethod string \n\tSeq           uint64 \n\tError         string \n\tnext          *Response \n}\n```\n\n其中ClientCodec接口包括**写请求**、**读响应头部**和**读响应体**，我们建立一个clientCode的结构体用来实现ClientCodec接口：\n\n代码 [codec/client.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/codec/client.go) 如下：\n\n```go\ntype clientCodec struct {\n\tr io.Reader\n\tw io.Writer\n\tc io.Closer\n\n\tcompressor compressor.CompressType // rpc compress type(raw,gzip,snappy,zlib)\n\tserializer serializer.Serializer\n\tresponse   header.ResponseHeader // rpc response header\n\tmutex      sync.Mutex            // protect pending map\n\tpending    map[uint64]string\n}\n```\n\n其中 *compressor* 表示压缩类型，*serializer* 表示使用的序列化器，*response* 是响应的头部，*mutex* 是用于保护 *pending* 的互斥锁；\n\n```go\n// NewClientCodec Create a new client codec\nfunc NewClientCodec(conn io.ReadWriteCloser,\n\tcompressType compressor.CompressType, serializer serializer.Serializer) rpc.ClientCodec {\n\n\treturn &clientCodec{\n\t\tr:          bufio.NewReader(conn),\n\t\tw:          bufio.NewWriter(conn),\n\t\tc:          conn,\n\t\tcompressor: compressType,\n\t\tserializer: serializer,\n\t\tpending:    make(map[uint64]string),\n\t}\n}\n```\n\n这里的读写IO分别使用 *bufio.NewReader* 和 *bufio.NewWriter* 构造，通过缓冲IO来提高RPC的读写性能；\n\n首先 *clientCode* 结构体实现了 ***ClientCodec*** 接口的***WriteRequest*** 方法：\n\n```go\nfunc (c *clientCodec) WriteRequest(r *rpc.Request, param any) error {\nc.mutex.Lock()\n\tc.pending[r.Seq] = r.ServiceMethod\n\tc.mutex.Unlock()\n          // 判断压缩器是否存在\n\tif _, ok := compressor.Compressors[c.compressor]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n\treqBody, err := c.serializer.Marshal(param) // 用序列化器进行编码\n\tif err != nil {\n\t\treturn err\n\t}\n        // 压缩\n\tcompressedReqBody, err := compressor.Compressors[c.compressor].Zip(reqBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 从请求头部对象池取出请求头\n\th := header.RequestPool.Get().(*header.RequestHeader)\n\tdefer func() {\n\t\th.ResetHeader()\n\t\theader.RequestPool.Put(h)\n\t}()\n\th.ID = r.Seq\n\th.Method = r.ServiceMethod\n\th.RequestLen = uint32(len(compressedReqBody))\n\th.CompressType = header.CompressType(c.compressor)\n\th.Checksum = crc32.ChecksumIEEE(compressedReqBody)\n        // 发送请求头\n\tif err := sendFrame(c.w, h.Marshal()); err != nil {\n\t\treturn err\n\t}\n        // 发送请求体\n\tif err := write(c.w, compressedReqBody); err != nil {\n\t\treturn err\n\t}\n\n\tc.w.(*bufio.Writer).Flush()\n\treturn nil\t\n}\n```\n\n实现 ***ClientCodec\\*** 接口的 ***ReadResponseHeader\\*** 方法：\n\n```go\nfunc (c *clientCodec) ReadResponseHeader(r *rpc.Response) error {\n        c.response.ResetHeader() // 重置clientCodec的响应头部\n\tdata, err := recvFrame(c.r) // 读取请求头字节串  \n\tif err != nil {\n\t\treturn err\n\t}\n\terr = c.response.Unmarshal(data) // 用序列化器继续解码\n\tif err != nil {\n\t\treturn err\n\t}\n\tc.mutex.Lock()\n\tr.Seq = c.response.ID // 填充 r.Seq  \n\tr.Error = c.response.Error // 填充 r.Error\n\tr.ServiceMethod = c.pending[r.Seq]  // 根据序号填充 r.ServiceMethod\n\tdelete(c.pending, r.Seq) // 删除pending里的序号  \n\tc.mutex.Unlock()\n\treturn nil\t\n}\n```\n\n实现 ***ClientCodec\\*** 接口的 ***ReadResponseBody\\*** 方法：\n\n```go\n\nfunc (c *clientCodec) ReadResponseBody(param any) error {\n        if param == nil {\n\t\tif c.response.ResponseLen != 0 {   // 废弃多余部分\n\t\t\tif err := read(c.r, make([]byte, c.response.ResponseLen)); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n        // 根据响应体长度，读取该长度的字节串\n\trespBody := make([]byte, c.response.ResponseLen)\n\terr := read(c.r, respBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 校验\n\tif c.response.Checksum != 0 {\n\t\tif crc32.ChecksumIEEE(respBody) != c.response.Checksum {\n\t\t\treturn UnexpectedChecksumError\n\t\t}\n\t}\n        // 判断压缩器是否存在\n\tif _, ok := compressor.Compressors[c.response.GetCompressType()]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n        // 解压\n\tresp, err := compressor.Compressors[c.response.GetCompressType()].Unzip(respBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 反序列化\n\treturn c.serializer.Unmarshal(resp, param)\n}\n```\n\n## 实现ServerCodec接口\n\nTinyRPC在codec层还需要实现**net/rpc**的**ServerCodec**接口\n\n*ServerCodec* 的接口和 *ClientCodec* 接口十分类似：\n\n```go\ntype ServerCodec interface {\n\tReadRequestHeader(*Request) error\n\tReadRequestBody(any) error\n\tWriteResponse(*Response, any) error\n\tClose() error\n}\n```\n\n其中 *ServerCodec* 接口包括**写响应**、**读请求头部**和**读请求体**，我们建立一个 *serverCodec* 的结构体用来实现 *ServerCodec* 接口，代码[codec/server.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/codec/server.go)：\n\n```go\ntype serverCodec struct {\n\tr io.Reader\n\tw io.Writer\n\tc io.Closer\n\n\trequest    header.RequestHeader\n\tserializer serializer.Serializer\n\tmutex      sync.Mutex // protects seq, pending\n\tseq        uint64\n\tpending    map[uint64]uint64\n}\n\n// NewServerCodec Create a new server codec\nfunc NewServerCodec(conn io.ReadWriteCloser, serializer serializer.Serializer) rpc.ServerCodec {\n\treturn &serverCodec{\n\t\tr:          bufio.NewReader(conn),\n\t\tw:          bufio.NewWriter(conn),\n\t\tc:          conn,\n\t\tserializer: serializer,\n\t\tpending:    make(map[uint64]uint64),\n\t}\n}\n```\n\n是不是和刚才的 *clientCode* 结构体**神似**？\n\n首先， *serverCodec* 结构体实现了 *ServerCodec* 接口的 *ReadRequestHeader*方法：\n\n```go\nfunc (s *serverCodec) ReadRequestHeader(r *rpc.Request) error {\n\ts.request.ResetHeader()  // 重置serverCodec结构体的请求头部\n\tdata, err := recvFrame(s.r) // 读取请求头部字节串\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = s.request.Unmarshal(data)   //将字节串反序列化\n\tif err != nil {\n\t\treturn err\n\t}\n\ts.mutex.Lock()\n\ts.seq++  // 序号自增\n\ts.pending[s.seq] = s.request.ID // 自增序号与请求头部的ID进行绑定\n\tr.ServiceMethod = s.request.Method  // 填充 r.ServiceMethod \n\tr.Seq = s.seq// 填充 r.Seq  \n\ts.mutex.Unlock()\n\treturn nil\t\n}\n```\n\n实现 *ServerCodec* 接口的 *ReadRequestBody* 方法：\n\n```go\nfunc (s *serverCodec) ReadRequestBody(x any) error {\n       if param == nil { \n\t\tif s.request.RequestLen != 0 {  // 废弃多余部分\n\t\t\tif err := read(s.r, make([]byte, s.request.RequestLen)); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\n\treqBody := make([]byte, s.request.RequestLen)\n        // 根据请求体的大小，读取该大小的字节串\n\terr := read(s.r, reqBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 校验\n\tif s.request.Checksum != 0 {\n\t\tif crc32.ChecksumIEEE(reqBody) != s.request.Checksum {\n\t\t\treturn UnexpectedChecksumError\n\t\t}\n\t}\n         // 判断压缩器是否存在\n\tif _, ok := compressor.\n\t\tCompressors[s.request.GetCompressType()]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n        // 解压\n\treq, err := compressor.\n\t\tCompressors[s.request.GetCompressType()].Unzip(reqBody)\n\tif err != nil {\n\t\treturn err\n\t}\n        // 把字节串反序列化\n\treturn s.serializer.Unmarshal(req, param)\n}\n```\n\n实现 *ServerCodec* 接口的 *WriteResponse* 方法：\n\n```go\nfunc (s *serverCodec) WriteResponse(r *rpc.Response, param any) error {\n\ts.mutex.Lock()\n\tid, ok := s.pending[r.Seq]\n\tif !ok {\n\t\ts.mutex.Unlock()\n\t\treturn InvalidSequenceError\n\t}\n\tdelete(s.pending, r.Seq)\n\ts.mutex.Unlock()\n\n\tif r.Error != \"\" {   // 如果RPC调用结果有误，把param置为nil\n\t\tparam = nil\n\t}\n         // 判断压缩器是否存在\n\tif _, ok := compressor.\n\t\tCompressors[s.request.GetCompressType()]; !ok {\n\t\treturn NotFoundCompressorError\n\t}\n        \n\tvar respBody []byte\n\tvar err error\n\tif param != nil {\n\t\trespBody, err = s.serializer.Marshal(param) // 反序列化\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n        // 压缩\n\tcompressedRespBody, err := compressor.\n\t\tCompressors[s.request.GetCompressType()].Zip(respBody)\n\tif err != nil {\n\t\treturn err\n\t}\n\th := header.ResponsePool.Get().(*header.ResponseHeader)\n\tdefer func() {\n\t\th.ResetHeader()\n\t\theader.ResponsePool.Put(h)\n\t}()\n\th.ID = id\n\th.Error = r.Error\n\th.ResponseLen = uint32(len(compressedRespBody))\n\th.Checksum = crc32.ChecksumIEEE(compressedRespBody)\n\th.CompressType = s.request.CompressType\n        // 发送响应头\n\tif err = sendFrame(s.w, h.Marshal()); err != nil {\n\t\treturn err\n\t}\n        // 发送响应体\n\tif err = write(s.w, compressedRespBody); err != nil {\n\t\treturn err\n\t}\n\ts.w.(*bufio.Writer).Flush()\n\treturn nil\n}\n```\n\n## TinyRPC的Server\n\nTinyRPC的服务端非常简单，把标准库 **net/rpc** 的 **Server** 结构包装了一层，其中 *ServeCodec* 使用的是TinyRPC的编解码器，代码[server.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/server.go)：\n\n```go\ntype Server struct {\n\t*rpc.Server\n\tserializer.Serializer\n}\n\n...\n\nfunc (s *Server) Serve(lis net.Listener) {\n\tfor {\n\t\tconn, err := lis.Accept()\n\t\tif err != nil {\n\t\t\tlog.Print(\"tinyrpc.Serve: accept:\", err.Error())\n\t\t\treturn\n\t\t}\n\t\tgo s.Server.ServeCodec(codec.NewServerCodec(conn, s.Serializer)))  // 使用TinyRPC的解码器\n\t}\n}\n```\n\n## TinyRPC的Client\n\nTinyRPC的客户端也很简单，把标准库 **net/rpc** 的 **Client** 结构包装了一层，其中 *ClientCodec* 使用的是TinyRPC的编解码器，代码[client.go](https://link.zhihu.com/?target=https%3A//github.com/zehuamama/tinyrpc/blob/main/client.go)：\n\n> 注意：TinyRPC Client使用一种Go语言常用的设计模式：功能选项模式\n\n```go\n// Client rpc client based on net/rpc implementation\ntype Client struct {\n\t*rpc.Client\n}\n\n//Option provides options for rpc\ntype Option func(o *options)\n\ntype options struct {\n\tcompressType compressor.CompressType\n\tserializer   serializer.Serializer\n}\n\n// WithCompress set client compression format\nfunc WithCompress(c compressor.CompressType) Option {\n\treturn func(o *options) {\n\t\to.compressType = c\n\t}\n}\n\n// WithSerializer set client serializer\nfunc WithSerializer(serializer serializer.Serializer) Option {\n\treturn func(o *options) {\n\t\to.serializer = serializer\n\t}\n}\n\n// NewClient Create a new rpc client\nfunc NewClient(conn io.ReadWriteCloser, opts ...Option) *Client {\n\toptions := options{\n\t\tcompressType: compressor.Raw,\n\t\tserializer:   serializer.Proto,\n\t}\n\tfor _, option := range opts {\n\t\toption(&options)\n\t}\n\treturn &Client{rpc.NewClientWithCodec(\n\t\tcodec.NewClientCodec(conn, options.compressType, options.serializer))}\n}\n\n// Call synchronously calls the rpc function\nfunc (c *Client) Call(serviceMethod string, args interface{}, reply interface{}) error {\n\treturn c.Client.Call(serviceMethod, args, reply)\n}\n\n// AsyncCall asynchronously calls the rpc function and returns a channel of *rpc.Call\nfunc (c *Client) AsyncCall(serviceMethod string, args interface{}, reply interface{}) chan *rpc.Call {\n\treturn c.Go(serviceMethod, args, reply, nil).Done\n}\n```\n\n作者：马丸子\n链接：https://zhuanlan.zhihu.com/p/499098284\n来源：知乎\n","tags":["go"],"categories":["go"]},{"title":"how to fix Incorrect credentials. Request response. 401 Unauthorized","url":"/2023/03/23/how-to-fix-Incorrect-credentials-Request-response-401-Unauthorized/","content":"\n使用GitHub生成的token登录idea时，无法登录，报了如标题错误\n\n<!--more-->\n\n这是因为生成token时未勾选相应的权限\n\n请务必勾选以下权限\n\n```\nrepo - select everything\ngist - select everything\norg - select only read:org\n```\n\n勾选以后即可使用GitHub登录idea了\n","tags":["debug","git"],"categories":["debug"]},{"title":"redis实战:短信登录","url":"/2023/03/21/redis-in-action-SMS-login/","content":"\n本文介绍了如何使用session进行登录及其缺点，以及如何用redis对缺点进行改进\n\n<!--more-->\n\n## 基于session实现登录流程\n\n### **发送验证码：**\n\n用户在提交手机号后，会校验手机号是否合法，如果不合法，则要求用户重新输入手机号\n\n如果手机号合法，后台此时生成对应的验证码，同时将验证码进行保存，然后再通过短信的方式将验证码发送给用户\n\n### **短信验证码登录、注册：**\n\n用户将验证码和手机号进行输入，后台从 session 中拿到当前验证码，然后和用户输入的验证码进行校验，如果不一致，则无法通过校验，如果一致，则后台根据手机号查询用户，如果用户不存在，则为用户创建账号信息，保存到数据库，无论是否存在，都会将用户信息保存到 session 中，方便后续获得当前登录信息\n\n### **校验登录状态:**\n\n用户在请求时候，会从 cookie 中携带sessionId 到后台，后台通过 sessionId 从 session 中拿到用户信息，如果没有 session 信息，则进行拦截，如果有 session 信息，则将用户信息保存到 threadLocal 中，并且放行\n\n![登录流程](redis-in-action-SMS-login/登录流程.png)\n\n## 实现发送短信验证码功能\n\n![短信验证码](redis-in-action-SMS-login/短信验证码.png)\n\n代码如下：\n\n```\n    @Override\n    public Result sendCode(String phone, HttpSession session) {\n        // 1.校验手机号\n        if (RegexUtils.isPhoneInvalid(phone)) {\n            // 2.如果不符合，返回错误信息\n            return Result.fail(\"手机号格式错误！\");\n        }\n        // 3.符合，生成验证码\n        String code = RandomUtil.randomNumbers(6);\n \n        // 4.保存验证码到 session\n        session.setAttribute(\"code\",code);\n        // 5.发送验证码\n        log.debug(\"发送短信验证码成功，验证码：{}\", code);\n        // 返回ok\n        return Result.ok();\n    }\n```\n\n登录：\n\n```\n    @Override\n    public Result login(LoginFormDTO loginForm, HttpSession session) {\n        // 1.校验手机号\n        String phone = loginForm.getPhone();\n        if (RegexUtils.isPhoneInvalid(phone)) {\n            // 2.如果不符合，返回错误信息\n            return Result.fail(\"手机号格式错误！\");\n        }\n        // 3.校验验证码\n        Object cacheCode = session.getAttribute(\"code\");\n        String code = loginForm.getCode();\n        if(cacheCode == null || !cacheCode.toString().equals(code)){\n             //3.不一致，报错\n            return Result.fail(\"验证码错误\");\n        }\n        //一致，根据手机号查询用户\n        User user = query().eq(\"phone\", phone).one();\n \n        //5.判断用户是否存在\n        if(user == null){\n            //不存在，则创建\n            user =  createUserWithPhone(phone);\n        }\n        //7.保存用户信息到session中\n        session.setAttribute(\"user\",user);\n \n        return Result.ok();\n    }\n```\n\n## 实现登录拦截功能\n\n![登录拦截](redis-in-action-SMS-login/登录拦截.png)\n\n当用户发起请求时，会访问我们像 tomcat 注册的端口，任何程序想要运行，都需要有一个线程对当前端口号进行监听，tomcat 也不例外，当监听线程知道用户想要和 tomcat 连接连接时，那会由监听线程创建 socket 连接，socket 都是成对出现的，用户通过 socket 像互相传递数据，当 tomcat 端的 socket 接受到数据后，此时监听线程会从 tomcat 的线程池中取出一个线程执行用户请求，在我们的服务部署到 tomcat 后，线程会找到用户想要访问的工程，然后用这个线程转发到工程中的 controller，service，dao 中，并且访问对应的 DB，在用户执行完请求后，再统一返回，再找到 tomcat 端的 socket，再将数据写回到用户端的 socket，完成请求和响应\n\n通过以上讲解，我们可以得知 每个用户其实对应都是去找 tomcat 线程池中的一个线程来完成工作的， 使用完成后再进行回收，既然每个请求都是独立的，所以在每个用户去访问我们的工程时，我们可以使用 threadlocal 来做到线程隔离，每个线程操作自己的一份数据\n\n**温馨小贴士：关于 threadlocal**\n\n如果小伙伴们看过 threadLocal 的源码，你会发现在 threadLocal 中，无论是他的 put 方法和他的 get 方法， 都是先从获得当前用户的线程，然后从线程中取出线程的成员变量 map，只要线程不一样，map 就不一样，所以可以通过这种方式来做到线程隔离\n\n![拦截器处理](redis-in-action-SMS-login/拦截器处理.png)\n\n拦截器代码：\n\n```\npublic class LoginInterceptor implements HandlerInterceptor {\n \n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n       //1.获取session\n        HttpSession session = request.getSession();\n        //2.获取session中的用户\n        Object user = session.getAttribute(\"user\");\n        //3.判断用户是否存在\n        if(user == null){\n              //4.不存在，拦截，返回401状态码\n              response.setStatus(401);\n              return false;\n        }\n        //5.存在，保存用户信息到Threadlocal\n        UserHolder.saveUser((User)user);\n        //6.放行\n        return true;\n    }\n}\n```\n\n使拦截器生效：\n\n```\n@Configuration\npublic class MvcConfig implements WebMvcConfigurer {\n \n    @Resource\n    private StringRedisTemplate stringRedisTemplate;\n \n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        // 登录拦截器\n        registry.addInterceptor(new LoginInterceptor())\n                .excludePathPatterns(\n                        \"/shop/**\",\n                        \"/voucher/**\",\n                        \"/shop-type/**\",\n                        \"/upload/**\",\n                        \"/blog/hot\",\n                        \"/user/code\",\n                        \"/user/login\"\n                ).order(1);\n        // token刷新的拦截器\n        registry.addInterceptor(new RefreshTokenInterceptor(stringRedisTemplate)).order(0);\n    }\n}\n```\n\n## 隐藏用户敏感信息\n\n我们通过浏览器观察到此时用户的全部信息都在，这样极为不靠谱，所以我们应当在返回用户信息之前，将用户的敏感信息进行隐藏，采用的核心思路就是书写一个 UserDto 对象，这个 UserDto 对象就没有敏感信息了，我们在返回前，将有用户敏感信息的 User 对象转化成没有敏感信息的 UserDto 对象，那么就能够避免这个尴尬的问题了\n\n```\n//7.保存用户信息到session中\nsession.setAttribute(\"user\", BeanUtils.copyProperties(user,UserDTO.class));\n```\n\n**在拦截器处：**\n\n```\n//5.存在，保存用户信息到Threadlocal\nUserHolder.saveUser((UserDTO) user);\n```\n\n**在 UserHolder 处：将 user 对象换成 UserDTO**\n\n```\n\tpublic class UserHolder {\n    private static final ThreadLocal<UserDTO> tl = new ThreadLocal<>();\n \n    public static void saveUser(UserDTO user){\n        tl.set(user);\n    }\n \n    public static UserDTO getUser(){\n        return tl.get();\n    }\n \n    public static void removeUser(){\n        tl.remove();\n    }\n}\n```\n\n## session 共享问题\n\n**核心思路分析：**\n\n每个 tomcat 中都有一份属于自己的 session, 假设用户第一次访问第一台 tomcat，并且把自己的信息存放到第一台服务器的 session 中，但是第二次这个用户访问到了第二台 tomcat，那么在第二台服务器上，肯定没有第一台服务器存放的 session，所以此时 整个登录拦截功能就会出现问题，我们能如何解决这个问题呢？早期的方案是 session 拷贝，就是说虽然每个 tomcat 上都有不同的 session，但是每当任意一台服务器的 session 修改时，都会同步给其他的 Tomcat 服务器的 session，这样的话，就可以实现 session 的共享了\n\n但是这种方案具有两个大问题\n\n1、每台服务器中都有完整的一份 session 数据，服务器压力过大。\n\n2、session 拷贝数据时，可能会出现延迟\n\n所以咱们后来采用的方案都是基于 redis 来完成，我们把 session 换成 redis，redis 数据本身就是共享的，就可以避免 session 共享的问题了\n\n![session共享](redis-in-action-SMS-login/session共享.png)\n\n## Redis 代替 session 的业务流程\n\n### 设计 key 的结构\n\n首先我们要思考一下利用 redis 来存储数据，那么到底使用哪种结构呢？由于存入的数据比较简单，我们可以考虑使用 String，或者是使用哈希，如下图，如果使用 String，同学们注意他的 value，用多占用一点空间，如果使用哈希，则他的 value 中只会存储他数据本身，如果不是特别在意内存，其实使用 String 就可以啦。\n\n![redis设计key](redis-in-action-SMS-login/redis设计key.png)\n\n### 设计 key 的具体细节\n\n所以我们可以使用 String 结构，就是一个简单的 key，value 键值对的方式，但是关于 key 的处理，session 他是每个用户都有自己的 session，但是 redis 的 key 是共享的，咱们就不能使用 code 了\n\n在设计这个 key 的时候，我们之前讲过需要满足两点\n\n1、key 要具有唯一性\n\n2、key 要方便携带\n\n如果我们采用 phone：手机号这个的数据来存储当然是可以的，但是如果把这样的敏感数据存储到 redis 中并且从页面中带过来毕竟不太合适，所以我们在后台生成一个随机串 token，然后让前端带来这个 token 就能完成我们的整体逻辑了\n\n### 整体访问流程\n\n当注册完成后，用户去登录会去校验用户提交的手机号和验证码，是否一致，如果一致，则根据手机号查询用户信息，不存在则新建，最后将用户数据保存到 redis，并且生成 token 作为 redis 的 key，当我们校验用户是否登录时，会去携带着 token 进行访问，从 redis 中取出 token 对应的 value，判断是否存在这个数据，如果没有则拦截，如果存在则将其保存到 threadLocal 中，并且放行。\n\n![共享session登录](redis-in-action-SMS-login/共享session登录.png)\n\n## 基于 Redis 实现短信登录\n\n### 设计 key 的结构\n\n首先我们要思考一下利用 redis 来存储数据，那么到底使用哪种结构呢？由于存入的数据比较简单，我们可以考虑使用 String，或者是使用哈希，如下图，如果使用 String，同学们注意他的 value，用多占用一点空间，如果使用哈希，则他的 value 中只会存储他数据本身，如果不是特别在意内存，其实使用 String 就可以啦。\n\n![使用string结构保存json字符串](redis-in-action-SMS-login/使用string结构保存json字符串.png)\n\n### 设计 key 的具体细节\n\n所以我们可以使用 String 结构，就是一个简单的 key，value 键值对的方式，但是关于 key 的处理，session 他是每个用户都有自己的 session，但是 redis 的 key 是共享的，咱们就不能使用 code 了\n\n在设计这个 key 的时候，我们之前讲过需要满足两点\n\n1、key 要具有唯一性\n\n2、key 要方便携带\n\n如果我们采用 phone：手机号这个的数据来存储当然是可以的，但是如果把这样的敏感数据存储到 redis 中并且从页面中带过来毕竟不太合适，所以我们在后台生成一个随机串 token，然后让前端带来这个 token 就能完成我们的整体逻辑了\n\n### 整体访问流程\n\n当注册完成后，用户去登录会去校验用户提交的手机号和验证码，是否一致，如果一致，则根据手机号查询用户信息，不存在则新建，最后将用户数据保存到 redis，并且生成 token 作为 redis 的 key，当我们校验用户是否登录时，会去携带着 token 进行访问，从 redis 中取出 token 对应的 value，判断是否存在这个数据，如果没有则拦截，如果存在则将其保存到 threadLocal 中，并且放行。\n\n![1653319474181](redis-in-action-SMS-login/1653319474181.png)\n\n## 基于 Redis 实现短信登录\n\n这里具体逻辑就不分析了，之前咱们已经重点分析过这个逻辑啦。\n\n```java\n@Override\npublic Result login(LoginFormDTO loginForm, HttpSession session) {\n    // 1.校验手机号\n    String phone = loginForm.getPhone();\n    if (RegexUtils.isPhoneInvalid(phone)) {\n        // 2.如果不符合，返回错误信息\n        return Result.fail(\"手机号格式错误！\");\n    }\n    // 3.从redis获取验证码并校验\n    String cacheCode = stringRedisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone);\n    String code = loginForm.getCode();\n    if (cacheCode == null || !cacheCode.equals(code)) {\n        // 不一致，报错\n        return Result.fail(\"验证码错误\");\n    }\n \n    // 4.一致，根据手机号查询用户 select * from tb_user where phone = ?\n    User user = query().eq(\"phone\", phone).one();\n \n    // 5.判断用户是否存在\n    if (user == null) {\n        // 6.不存在，创建新用户并保存\n        user = createUserWithPhone(phone);\n    }\n \n    // 7.保存用户信息到 redis中\n    // 7.1.随机生成token，作为登录令牌\n    String token = UUID.randomUUID().toString(true);\n    // 7.2.将User对象转为HashMap存储\n    UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class);\n    Map<String, Object> userMap = BeanUtil.beanToMap(userDTO, new HashMap<>(),\n            CopyOptions.create()\n                    .setIgnoreNullValue(true)\n                    .setFieldValueEditor((fieldName, fieldValue) -> fieldValue.toString()));\n    // 7.3.存储\n    String tokenKey = LOGIN_USER_KEY + token;\n    stringRedisTemplate.opsForHash().putAll(tokenKey, userMap);\n    // 7.4.设置token有效期\n    stringRedisTemplate.expire(tokenKey, LOGIN_USER_TTL, TimeUnit.MINUTES);\n \n    // 8.返回token\n    return Result.ok(token);\n}\n```\n\n","tags":["redis"],"categories":["redis"]},{"title":"爬虫初级使用记录","url":"/2023/03/20/introduction-to-spider/","content":"\n本文记录了爬虫最基础的使用方法，如果只想最快获得网页源码从2.2浏览即可\n\n<!--more-->\n\n## 1、爬虫核心库1：requests库\n\n学习爬虫其实并不太需要了解太多的网页结构知识，作为初学者只需要知道1点：所有想要获取的内容（例如新闻标题/网址/日期/来源等）都在网页源代码里，所谓网页源代码，就是网页背后的编程代码，这一小节我们首先来讲解下如何查看网页源代码，以及通过两个案例快速体验下如何通过requests库获取网页源代码。\n\n### 1.1 如何查看网页源代码\n\n在进入正式爬虫实战前，我们首先来了解下如何查看网页源代码。\n\n网络爬虫首先得有一个浏览器，这里强烈推荐谷歌浏览器（百度搜索谷歌浏览器，然后在官网[https://www.google.cn/chrome/](https://www.google.cn/chrome/)下载，谷歌浏览器默认是谷歌搜索，直接在网址输入框里输入内容可能搜索不到内容，可以在网址栏上输入baidu.com进行访问，或者可以点击浏览器右侧的设置按钮->选择界面左侧的搜索引擎->选择百度搜索引擎）。当然用别的浏览器，比如火狐浏览器等都是可以的，只要它按F12(有的电脑要同时按住左下角的Fn键)能弹出网页源代码即可。\n\n以谷歌浏览器为例来演示下F12的强大作用，百度搜索“阿里巴巴”，然后**按一下F12（有的电脑还得同时按住Fn）**，弹出如下页面，其中点击右侧设置按钮可以切换布局样式。\n\n![image-20230320154143682](introduction-to-spider/image-20230320154143682.png)\n\n这个按住F12弹出来的东西叫做开发者工具，是进行数据挖掘的利器，对于爬虫来说，大多数情况下只需要会用下图的这两个按钮即可。\n\n![img](introduction-to-spider/v2-e64893143d82ba0f5e79621345dea1cf_r.jpg)\n\n第一个按钮箭头形状按钮为**选择**按钮，第二个Elements按钮为**元素**按钮。\n\n**(1)** **选择按钮**\n\n点击一下它，发现它会变成蓝色，然后把鼠标在页面上移动移动，会发现页面上的颜色机会发生改变。如下图所示，当**移动鼠标**的时候，会发现界面上的颜色会发生变化，并且Elements里的内容就会随之发生变化。\n\n![image-20230320154833691](introduction-to-spider/image-20230320154833691.png)\n\n下面当选择按钮处于蓝色状态的时，点击一下第一个链接的标题，这时候选择按钮再次变成灰色，而Elements里的内容也将不再变动，此时便可以观察具体的网页源代码内容了，如下图所示，我们一般只关心里面的所需要的中文内容，如果没有看到中文文本，店家下图所示的三角箭头，即可展开内容，看到中文文本。\n\n![image-20230320155030944](introduction-to-spider/image-20230320155030944.png)\n\n**(2) Elements元素按钮**：\n\nElements元素按钮里面的内容可以理解为**就是网站的源码**，最后爬虫爬到的内容大致就是长这个样子的。下面就要接着完成一些“神奇”的操作。\n\n在下图“**1688”**那个地方鼠标双击俩下，这两个字变成可编辑的格式。\n\n![image-20230320155132398](introduction-to-spider/image-20230320155132398.png)\n\n将其改成“测试”，可以看到第一个的标题发生了改变，如下图所示：\n\n![image-20230320155245952](introduction-to-spider/image-20230320155245952.png)\n\n还可以用同样的操作，修改页面上的其他信息，如股价等。\n\n通过F12启动开发者工具，我们可以对网页结构有一个初步的认识，并可以利用选择按钮和“Elements”元素按钮观察我们想获取的内容在源码中的文本格式以及所在位置。\n\n**补充知识点1：查看网页源码的另一个方式**\n\n除了F12，另一个获取网页源码的方式是在网页上右击选择“**查看网页源代码**”，就可以获取这个网址的源代码，这个基本就是Python爬取到的最终信息。用鼠标上下滚动，就能看到很多内容，同样初学者不需要关心那些英文或者网页框架，只需要知道想获取的中文在哪里即可。\n\n这个方法比F12观察源码的方式更加真实，因为F12观察到的源码可能是被网页修饰过的，通过Python获取到内容可能和F12看到的不一致。通过该方法查看到的源码就是通过Python程序能够获取到的网页源代码。实战中常将两种方法联合使用：通过F12进行初步了解，然后右击查看网页源代码，看看所需内容到底在网页源代码的什么位置，其中可以通过Ctrl + F快捷键搜索所需要的内容。\n\n此外，如果F12看到的内容和通过右击查看网页源代码看到的内容很不一样，这是因为网站做了动态渲染的处理（这是一种反爬处理），这时候就需要用到2.2节selenium库的相关知识点来获取真正的网页源代码。\n\n**补充知识点2：http与https协议**\n\n有的时候我们理解的网址是：[http://www.baidu.com]([http://www.baidu.com)，但其实在编程里或者它真实的名字其实是：[https://www.baidu.com](https://www.baidu.com)，它前面有个“https://”这个叫做https协议，是网址的固定构成形式，某种程度表明这个网址是安全的，有的网址前面则为http://。如果在Python里输入[www.baidu.com](https://link.zhihu.com/?target=http%3A//www.baidu.com/)它是不认识的，得把“https://”加上才行，如下面所示。\n\n```text\nurl = 'https://www.baidu.com/'\n```\n\n其实最简单的办法，**就是直接浏览器访问该网址，然后把链接复制下来就行**。\n\n### 1.2 爬虫初尝试 - requests库获取网页源代码\n\n了解了如何查看网页源代码后，这一小节我们讲解下如何通过requests库爬取网页源代码。这里以一个学校的招聘网站为例。\n\n**（1） 获取网页源代码**\n\n通过第一章最后介绍的requests库来尝试获取下新闻的网页源代码，代码如下：\n\n```python\nimport requests\nurl = 'https://www.163.com/dy/article/I09JUB0P051984TV.html'\nres = requests.get(url).text\nprint(res)\n```\n\n运行后报错：\n\n`requests.exceptions.SSLError: HTTPSConnectionPool`\n\n![image-20230320160811293](introduction-to-spider/image-20230320160811293.png)\n\n这是由于ssl认证失败造成的，我们并不需要知道原因，只要像以下一样禁用ssl认证就可以了。\n\n```python\nimport requests\n\ns = requests.session()\ns.trust_env = False\ns.keep_alive = False\nrequests.DEFAULT_RETRIES = 50\n\nurl = 'https://www.gdpt.edu.cn/al_8/189'\nres = s.get(url).text\nprint(res)\n```\n\n这段代码使requests的连接禁用了ssl认证，不使用keep-alive，并将重连次数增加到了50，如果出现了类似的错误只需要将以上代码复制粘贴即可。运行后得到以下结果。\n\n![image-20230320161701948](introduction-to-spider/image-20230320161701948.png)\n\n这里虽然得到了结果，但是有的网站只认可浏览器发送过去的访问，而不认可直接通过Python发送过去的访问请求，那么该如何解决该问题呢？这时就需要设置下requests.get()中的headers参数，用来模拟浏览器进行访问。\n\n```python\nimport requests\n\ns = requests.session()\ns.trust_env = False\ns.keep_alive = False\nrequests.DEFAULT_RETRIES = 50\n\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 \\\n                    (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1'}\nurl = 'https://www.gdpt.edu.cn/al_8/189'\nres = s.get(url, headers=headers).text\nprint(res)\n```\n\n## 2 爬虫核心库2：selenium库\n\n对比了我想要查询的内容，发现requests爬取的信息不是完整的，这是因为Requests只能获取到HTML文本，而无法获取到JavaScript动态生成的内容。如果div盒子里的内容是通过JavaScript生成的，那么requests就无法获取到。此时就需要使用selenium库了。\n\nSelenium库这一知识点相对比较重要，如果说requests库能够爬取50%的网站的话，那么通过selenium库的话可以爬取95%的网站，大部分较为困难的网址都可以通过其来获取网页源代码。下面我们首先来分析下requests库在一些复杂爬虫中遇到的难点，然后讲解下如何安装selenium库以及如何通过selenium库获取到网页源代码。\n\n### 2.1 requests库遇到的难点\n\n在使用requests库进行爬虫实战时，有时会遇到一大难题：获取不了网页真正的源代码。例如，上海证券交易所的公开信息、新浪财经的股票行情实时数据等，用常规爬虫手段会发现获取到的网页源代码内容很少且没有用。因为这些网页上展示的信息是动态渲染出来的，而通过常规爬虫手段获取的则是未经渲染的信息，所以其中没有我们想要的信息。\n\n以新浪财经的上证综合指数（上证综合指数反映在上海证券交易所全部上市股票价格综合情况）网页（[http://finance.sina.com.cn/realstock/]([http://finance.sina.com.cn/realstock)）为例，在浏览器中按F12 键，可以在网页源代码中看到指数数值。然后用常规爬虫手段，以requests.get(url).text 的方式获取这个网页的源代码，然后按快捷键Ctrl+F，在源代码中搜索刚才看到的指数数值，会发现搜索不到，如下图所示。而且就算加上headers 参数也没有改观。\n\n面对这种动态渲染的网页，在数据挖掘时就需要使用Selenium 库，通过模拟打开一个浏览器访问网址，然后获取渲染后的网页源代码，从而完成requests库难以完成的任务。\n\n| 优点       | 缺点                |                  |\n| ---------- | ------------------- | ---------------- |\n| requests库 | 爬取速度快          | 有些网站爬取不到 |\n| selenium库 | 能爬取95%以上的网站 | 爬取速度较慢     |\n\n### 2.2  Selenium库介绍与安装\n\n正式介绍selenium库之前，得首先先安装一个网页模拟器：ChromeDriver，它的作用是给Pyhton提供一个模拟浏览器，让Python能够运行一个模拟的浏览器进行网页访问，并用selenium进行鼠标及键盘等操作获取到网页真正的源代码。\n\n**(1) 安装Chrome谷歌浏览器**\n\n安装ChromeDriver之前，得先装一下Chrome谷歌浏览器，直接百度搜索谷歌浏览器，然后在官网[https://www.google.cn/chrome/](https://www.google.cn/chrome)下载即可。\n\n**(2) 查看Chrome浏览器版本**\n\n地址栏输入`chrome://version`回车即可\n\n![image-20230320163352932](introduction-to-spider/image-20230320163352932.png)\n\n![image-20230320163501421](introduction-to-spider/image-20230320163501421.png)\n\n**(3) ChromeDriver下载**\n\nChromeDriver官方下载地址：[http://chromedriver.storage.googleapis.com/index.html](http://chromedriver.storage.googleapis.com/index.html)。进入官网后，选择对应自己谷歌浏览器版本的ChromeDriver下载即可。不过由于官网再国内经常访问不了，因此可以在百度上搜索“ChromeDriver下载”，可以找到如下一个镜像下载网站：[http://npm.taobao.org/mirrors/chromedriver/](https://registry.npmmirror.com/binary.html?path=chromedriver/)。\n\n**(4) ChromeDriver环境变量配置**\n\n解压压缩包，找到chromedriver.exe复制到chrome的安装目录（其实也可以随便放一个文件夹,关键是要加入环境变量）。复制chromedriver.exe文件的路径并加入到电脑的环境变量中去。具体的：\n\n![img](introduction-to-spider/1365470-20190316154653549-1071713064.png)进入环境变量编辑界面，添加到用户变量即可，双击PATH，将你的文件位置（C:\\Program Files (x86)\\Google\\Chrome\\Application\\)添加到后面。\n\n![img](introduction-to-spider/1365470-20190316155217109-176711956.png)\n\n完成后在按住win+R键进入cmd，输入chromedriver验证是否安装成功：\n\n![image-20230320165251568](introduction-to-spider/image-20230320165251568.png)\n\n未配置环境也可以，例如：\n\n```python\nfrom selenium import webdriver\nimport time\n\ndef main():\n    chrome_driver = 'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe'  #chromedriver的文件位置\n    b = webdriver.Chrome(executable_path = chrome_driver)\n    b.get('https://www.google.com')\n    time.sleep(5)\n    b.quit()\n\nif __name__ == '__main__':\n    main()\n```\n\n已配置环境变量时，就不需要指定位置了\n\n```python\nfrom selenium import webdriver\nimport time\n\ndef main():\n    b = webdriver.Chrome()\n    b.get('https://www.baidu.com')\n    time.sleep(5)\n    b.quit()\n\nif __name__ == '__main__':\n    main()\n```\n\n如果运行时提示\n\n![img](introduction-to-spider/1365470-20190316162023053-275348276.png)\n\n很可能是chromedriver的版本不对（不要问我怎么知道的）。\n\n### **2.3 Selenium库获取网页源代码** \n\nSelenium库的功能很强大，使用技巧却并不复杂，只要掌握了下面的几个知识点，就能较游刃有余的使用selenium库了。\n\n**(1) 访问及关闭页面 + 网页最大化**\n\n通过以下这三行代码，就可以访问网站了，它相当于模拟人打开了一个浏览器，然后输入了一串网址：\n\n```text\nfrom selenium import webdriver\nbrowser = webdriver.Chrome()\nbrowser.get(\"https://www.baidu.com/\")\n```\n\n第一行引入selenium库里的webdriver功能，第二行browser = webdriver.Chrome()声明我们用的模拟器是谷歌浏览器，第三行通过brower.get()的这个方法访问网址。\n\n关闭模拟浏览器的代码如下，在代码最后加上这么一行，能关闭模拟浏览器。\n\n```text\nbrowser.quit()\n```\n\n**(2) 获取网页真正的源代码**\n\n利用selenium的一个主要目的就是为了获取原来难以获得的网页源码，代码如下：\n\n```text\ndata = browser.page_source\n```\n\n拿这个方法来试试之前提到过的比较难以获取的动态加载的内容：\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver import ChromeOptions\n\nurl = \"https://www.gdpt.edu.cn/al_8/189\"\n\noptions = ChromeOptions()\nbrowser = webdriver.Chrome(options=options)\nbrowser.get(url)\n\nsource = browser.page_source\n\nwith open('example.html', 'w', encoding=\"utf8\") as f:\n    f.write(source)\nbrowser.quit()\n```\n\n这样就得到了所有的内容并以一个html文件的形式写出\n\n### 2.4 selenium库加载登录信息\n\n如果一个网站要求登录才能看到信息，如何使用selenium登录呢。很简单，加载浏览器登陆过的信息即可。浏览器会将用户登录过的所有数据保存在`C:\\Users\\电脑用户名\\AppData\\Local\\Google\\Chrome\\User Data`，selenium只需要加载这个文件夹就可以了，代码如下：\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver import ChromeOptions\n\nurl = \"https://www.gdpt.edu.cn/al_8/189\"\n\n# 加载cookies中已经保存的账号和密码\noptions = ChromeOptions()\noptions.add_argument(r'user-data-dir=C:\\Users\\电脑用户名\\AppData\\Local\\Google\\Chrome\\User Data')\nbrowser = webdriver.Chrome(options=options)\nbrowser.get(url)\n\nsource = browser.page_source\n\nwith open('example.html', 'w', encoding=\"utf8\") as f:\n    f.write(source)\nbrowser.quit()\n```\n\n","tags":["Python","spider"],"categories":["Python","spider"]},{"title":"how-to-fix-This-application-has-no-explicit-mapping-error","url":"/2023/03/17/how-to-fix-This-application-has-no-explicit-mapping-error/","content":"\n报错完整信息:This application has no explicit mapping for /error, so you are seeing this as a fallback\n\n<!--more-->\n\n翻阅了网上众多资料，主要有一下几种解决的方向：\n\n## 方向1:包的位置可能错误\n\nApplication启动类的位置不对.要将Application类放在最外侧,即包含所有子包\n\n原因:spring-boot会自动加载启动类所在包下及其子包下的所有组件.\n\n## 方向2: springboot配置文件有误\n\n在springboot的配置文件:application.yml或application.properties中关于视图解析器的配置问题:\n\n当pom文件下的spring-boot-starter-paren版本高时使用:\n\nspring.mvc.view.prefix/spring.mvc.view.suffix\n\n当pom文件下的spring-boot-starter-paren版本低时使用:\n\nspring.view.prefix/spring.view.suffix\n\n## 方向3: 映射路径有误\n\n控制器的URL路径书写问题\n\n@RequestMapping(“xxxxxxxxxxxxxx”)\n\n实际访问的路径与”xxx”不符合.\n\n然而作为刚接触SpringBoot的我一开始犯错的时候是在第四层\n\n## 方向4: 扫包出现错误\n\n你把你Controller类的@Controller给补上\n\n## 方向5: nginx是否打开并检查端口\n\n当使用nginx代理静态资源时，需要检查是否运行nginx，并注意端口不能冲突\n\n","tags":["debug","Spring Boot"],"categories":["debug","Spring Boot"]},{"title":"LeetCode题解：括号匹配算法","url":"/2023/01/21/LeetCode题解：括号匹配算法/","content":"\n## 括号匹配算法\n\n左*括号*必须用相同类型的右*括号*闭合。 左*括号*必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。\n\n<!--more-->\n\n### 1.实现目标\n\n在开发中，会出现需要判断字符串是否匹配的问题，如文本编辑器中括号不匹配会出现格式错误（如以下字符串），这就需要括号匹配算法\n\n```\ndsa(dsadsa{dhk)s})}\n```\n\n### 2.实现思路\n\n![$R5G0SIK](LeetCode题解：括号匹配算法/$R5G0SIK.jpg)\n\n由于括号是与最近的同类型括号匹配，可以利用栈的后进先出特性将右括号与最近的左括号匹配，如果不匹配，直接返回false\n\n### 3.具体实现\n\n当括号数量为奇数时直接返回false，为0直接返回true。\n\n核心逻辑：循环遍历字符串每一个字符，判断是左括号则入栈，num++，若是右括号则num--，让该括号与栈顶括号匹配，若相同则弹出栈，不同则什么都不做，这样就可以跳过普通字符而判断括号是否匹配\n\n为什么要设置num：设置变量num统计左括号的数目，当有右括号时num--，这是为了判断左右括号的数目要相同，但是还要判断是否为同类括号\n\n改进方法：判断isMatch（）时在后面加else，就不用判断num了，但是使用原方法leetcode速度更快，内存也更小\n\n代码\n\n```javascript\n<script>\t\n    let isValid = funtion(str){\n        const len = str.length\n        if(len%2===1)\n            return false\n        if(len===0)\n            return true\n        \n        str = str.split('')\n        let stack = []\n        const leftBracket = '{[('\n        cosnt rightBracket = '}])'\n        let a = str[0]\n        if(rightBracket.includes(a))\n            return false\n        \n        for(let i = 0;i<len;i++)\n            if(leftBracket.includes(str[i]))\n                stack.push(str[i])\n        \t\tnum++\n        \telse if(rightBracket.includes(str[i]))//\n                num--\n                let top = stack[stack.length-1]\n                if(isMatch(top,str[i]))\n                    stack.pop()\n        \t\t/*\n        \t\telse\n        \t\t\treturn false\t\t此时就不用num了\n        \t\t*/\n        if(num===0&&stack.length===0)\n            return true\n        else \n            return false\n        \n        \n    }\n\n\n\tfuntion isMatch(left,right){\n        if(left==='{'&&right==='}'){\n            return true\n        }else if(left==='['&&right===']'){\n            return true\n        }else if(left==='('&&right===')'){\n            return true\n        }else\n            return false\n    \n</script>\n```\n\n","tags":["Leetcode"],"categories":["Leetcode"]},{"title":"每天一个Linux命令：top","url":"/2022/07/20/one-linux-command-per-day/","content":"\n每天坚持学习Linux\n\n<!--more-->\n\ntop命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。下面详细介绍它的使用方法。top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定\n\n**1．**命令格式：\n\ntop [参数]\n\n**2．** 命令功能\n\n显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等\n\n3．命令参数：\n\n-b 批处理\n\n-c 显示完整的治命令\n\n-I 忽略失效过程\n\n-s 保密模式\n\n-S 累积模式\n\n-i<时间> 设置间隔时间\n\n-u<用户名> 指定用户名\n\n-p<进程号> 指定进程\n\n-n<次数> 循环显示的次数\n\n**统计信息区**：\n\n前五行是当前系统情况整体的统计信息区。下面我们看每一行信息的具体意义。\n\n**第一行**，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下：\n\n14:06:23 — 当前系统时间\n\nup 70 days, 16:44 — 系统已经运行了70天16小时44分钟（\n\n2 users — 当前有2个用户登录系统\n\nload average: 1.15, 1.42, 1.44 — load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。\n\nload average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。\n\n**第二行**，Tasks — 任务（进程），具体信息说明如下：\n\n系统现在共有206个进程，其中处于运行中的有1个，205个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。\n\n**第三行**，cpu状态 信息，具体属性说明如下：\n\n5.9%us — 用户空间占用CPU的百分比。\n\n3.4% sy — 内核空间占用CPU的百分比。\n\n0.0% ni — 改变过优先级的进程占用CPU的百分比\n\n90.4% id — 空闲CPU百分比\n\n0.0% wa — IO等待占用CPU的百分比\n\n0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比\n\n0.2% si — 软中断（Software Interrupts）占用CPU的百分比\n\n**备注：**在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！\n\n**第四行**,内存状态，具体信息如下：\n\n32949016k total — 物理内存总量（32GB）\n\n14411180k used — 使用中的内存总量（14GB）\n\n18537836k free — 空闲内存总量（18GB）\n\n169884k buffers — 缓存的内存量 （169M）\n\n**第五行，**swap交换分区信息，具体信息说明如下：\n\n32764556k total — 交换区总量（32GB）\n\n0k used — 使用的交换区总量（0K）\n\n32764556k free — 空闲交换区总量（32GB）\n\n3612636k cached — 缓冲的交换区总量（3.6GB）\n\n备注：第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。\n\n如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached\n\n对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了\n\n**其他使用技巧：**\n\n**1.** **多U多核CPU监控**\n\n在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况：\n\n​\t![img](one-linux-command-per-day/top1.jpg) \n\n观察上图，服务器有16个逻辑CPU，实际上是4个物理CPU。再按数字键1，就会返回到top基本视图界面。\n\n**2.****高亮显示当前运行进程**\n\n​\t敲击键盘“b”（打开/关闭加亮效果），top的视图变化如下：\n\n​\t  ![img](one-linux-command-per-day/top2.png) \n\n我们发现进程id为2570的“top”进程被加亮了，top进程就是视图第二行显示的唯一的运行态（runing）的那个进程，可以通过敲击“y”键关闭或打开运行态进程的加亮效果。\n\n**3.****进程字段排序**\n\n默认进入top时，各进程是按照CPU的占用量来排序的,敲击键盘“x”（打开/关闭排序列的加亮效果），top默认的排序列是“%CPU”。\n\n4.通过”shift + >”或”shift + <”可以向右或左改变排序列\n\n**实例2：****显示 完整命令**\n\ntop -c\n\n**实例3：以批处理模式显示程序信息**\n\ntop -b\n\n**实例4：****以累积模式显示程序信息**\n\ntop -S\n\n**实例5：****设置信息更新次数**\n\n top -n 2\n\n表示更新两次后终止更新显示\n\n**实例6：设置信息更新时间**\n\ntop -d 3\n\n表示更新周期为3秒\n\n**实例7：显示指定的进程信息**\n\ntop -p 574\n\n **5.top交互命令**\n\n在top 命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了s 选项， 其中一些命令可能会被屏蔽。\n\nh 显示帮助画面，给出一些简短的命令总结说明\n\nk 终止一个进程。\n\ni 忽略闲置和僵死进程。这是一个开关式命令。\n\nq 退出程序\n\nr 重新安排一个进程的优先级别\n\nS 切换到累计模式\n\ns 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s\n\nf或者F 从当前显示中添加或者删除项目\n\no或者O 改变显示项目的顺序\n\nl 切换显示平均负载和启动时间信息\n\nm 切换显示内存信息\n\nt 切换显示进程和CPU状态信息\n\nc 切换显示命令名称和完整命令行\n\nM 根据驻留内存大小进行排序\n\nP 根据CPU使用百分比大小进行排序\n\nT 根据时间/累计时间进行排序\n","tags":["Linux"],"categories":["Linux"]}]