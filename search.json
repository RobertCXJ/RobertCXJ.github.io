[{"title":"how to fix Incorrect credentials. Request response. 401 Unauthorized","url":"/2023/03/23/how-to-fix-Incorrect-credentials-Request-response-401-Unauthorized/","content":"\n使用GitHub生成的token登录idea时，无法登录，报了如标题错误\n\n<!--more-->\n\n这是因为生成token时未勾选相应的权限\n\n请务必勾选以下权限\n\n```\nrepo - select everything\ngist - select everything\norg - select only read:org\n```\n\n勾选以后即可使用GitHub登录idea了\n","tags":["debug","git"],"categories":["debug"]},{"title":"redis实战:短信登录","url":"/2023/03/21/redis-in-action-SMS-login/","content":"\n本文介绍了如何使用session进行登录及其缺点，以及如何用redis对缺点进行改进\n\n<!--more-->\n\n## 基于session实现登录流程\n\n### **发送验证码：**\n\n用户在提交手机号后，会校验手机号是否合法，如果不合法，则要求用户重新输入手机号\n\n如果手机号合法，后台此时生成对应的验证码，同时将验证码进行保存，然后再通过短信的方式将验证码发送给用户\n\n### **短信验证码登录、注册：**\n\n用户将验证码和手机号进行输入，后台从 session 中拿到当前验证码，然后和用户输入的验证码进行校验，如果不一致，则无法通过校验，如果一致，则后台根据手机号查询用户，如果用户不存在，则为用户创建账号信息，保存到数据库，无论是否存在，都会将用户信息保存到 session 中，方便后续获得当前登录信息\n\n### **校验登录状态:**\n\n用户在请求时候，会从 cookie 中携带sessionId 到后台，后台通过 sessionId 从 session 中拿到用户信息，如果没有 session 信息，则进行拦截，如果有 session 信息，则将用户信息保存到 threadLocal 中，并且放行\n\n![登录流程](redis-in-action-SMS-login/登录流程.png)\n\n## 实现发送短信验证码功能\n\n![短信验证码](redis-in-action-SMS-login/短信验证码.png)\n\n代码如下：\n\n```\n    @Override\n    public Result sendCode(String phone, HttpSession session) {\n        // 1.校验手机号\n        if (RegexUtils.isPhoneInvalid(phone)) {\n            // 2.如果不符合，返回错误信息\n            return Result.fail(\"手机号格式错误！\");\n        }\n        // 3.符合，生成验证码\n        String code = RandomUtil.randomNumbers(6);\n \n        // 4.保存验证码到 session\n        session.setAttribute(\"code\",code);\n        // 5.发送验证码\n        log.debug(\"发送短信验证码成功，验证码：{}\", code);\n        // 返回ok\n        return Result.ok();\n    }\n```\n\n登录：\n\n```\n    @Override\n    public Result login(LoginFormDTO loginForm, HttpSession session) {\n        // 1.校验手机号\n        String phone = loginForm.getPhone();\n        if (RegexUtils.isPhoneInvalid(phone)) {\n            // 2.如果不符合，返回错误信息\n            return Result.fail(\"手机号格式错误！\");\n        }\n        // 3.校验验证码\n        Object cacheCode = session.getAttribute(\"code\");\n        String code = loginForm.getCode();\n        if(cacheCode == null || !cacheCode.toString().equals(code)){\n             //3.不一致，报错\n            return Result.fail(\"验证码错误\");\n        }\n        //一致，根据手机号查询用户\n        User user = query().eq(\"phone\", phone).one();\n \n        //5.判断用户是否存在\n        if(user == null){\n            //不存在，则创建\n            user =  createUserWithPhone(phone);\n        }\n        //7.保存用户信息到session中\n        session.setAttribute(\"user\",user);\n \n        return Result.ok();\n    }\n```\n\n## 实现登录拦截功能\n\n![登录拦截](redis-in-action-SMS-login/登录拦截.png)\n\n当用户发起请求时，会访问我们像 tomcat 注册的端口，任何程序想要运行，都需要有一个线程对当前端口号进行监听，tomcat 也不例外，当监听线程知道用户想要和 tomcat 连接连接时，那会由监听线程创建 socket 连接，socket 都是成对出现的，用户通过 socket 像互相传递数据，当 tomcat 端的 socket 接受到数据后，此时监听线程会从 tomcat 的线程池中取出一个线程执行用户请求，在我们的服务部署到 tomcat 后，线程会找到用户想要访问的工程，然后用这个线程转发到工程中的 controller，service，dao 中，并且访问对应的 DB，在用户执行完请求后，再统一返回，再找到 tomcat 端的 socket，再将数据写回到用户端的 socket，完成请求和响应\n\n通过以上讲解，我们可以得知 每个用户其实对应都是去找 tomcat 线程池中的一个线程来完成工作的， 使用完成后再进行回收，既然每个请求都是独立的，所以在每个用户去访问我们的工程时，我们可以使用 threadlocal 来做到线程隔离，每个线程操作自己的一份数据\n\n**温馨小贴士：关于 threadlocal**\n\n如果小伙伴们看过 threadLocal 的源码，你会发现在 threadLocal 中，无论是他的 put 方法和他的 get 方法， 都是先从获得当前用户的线程，然后从线程中取出线程的成员变量 map，只要线程不一样，map 就不一样，所以可以通过这种方式来做到线程隔离\n\n![拦截器处理](redis-in-action-SMS-login/拦截器处理.png)\n\n拦截器代码：\n\n```\npublic class LoginInterceptor implements HandlerInterceptor {\n \n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n       //1.获取session\n        HttpSession session = request.getSession();\n        //2.获取session中的用户\n        Object user = session.getAttribute(\"user\");\n        //3.判断用户是否存在\n        if(user == null){\n              //4.不存在，拦截，返回401状态码\n              response.setStatus(401);\n              return false;\n        }\n        //5.存在，保存用户信息到Threadlocal\n        UserHolder.saveUser((User)user);\n        //6.放行\n        return true;\n    }\n}\n```\n\n使拦截器生效：\n\n```\n@Configuration\npublic class MvcConfig implements WebMvcConfigurer {\n \n    @Resource\n    private StringRedisTemplate stringRedisTemplate;\n \n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        // 登录拦截器\n        registry.addInterceptor(new LoginInterceptor())\n                .excludePathPatterns(\n                        \"/shop/**\",\n                        \"/voucher/**\",\n                        \"/shop-type/**\",\n                        \"/upload/**\",\n                        \"/blog/hot\",\n                        \"/user/code\",\n                        \"/user/login\"\n                ).order(1);\n        // token刷新的拦截器\n        registry.addInterceptor(new RefreshTokenInterceptor(stringRedisTemplate)).order(0);\n    }\n}\n```\n\n## 隐藏用户敏感信息\n\n我们通过浏览器观察到此时用户的全部信息都在，这样极为不靠谱，所以我们应当在返回用户信息之前，将用户的敏感信息进行隐藏，采用的核心思路就是书写一个 UserDto 对象，这个 UserDto 对象就没有敏感信息了，我们在返回前，将有用户敏感信息的 User 对象转化成没有敏感信息的 UserDto 对象，那么就能够避免这个尴尬的问题了\n\n```\n//7.保存用户信息到session中\nsession.setAttribute(\"user\", BeanUtils.copyProperties(user,UserDTO.class));\n```\n\n**在拦截器处：**\n\n```\n//5.存在，保存用户信息到Threadlocal\nUserHolder.saveUser((UserDTO) user);\n```\n\n**在 UserHolder 处：将 user 对象换成 UserDTO**\n\n```\n\tpublic class UserHolder {\n    private static final ThreadLocal<UserDTO> tl = new ThreadLocal<>();\n \n    public static void saveUser(UserDTO user){\n        tl.set(user);\n    }\n \n    public static UserDTO getUser(){\n        return tl.get();\n    }\n \n    public static void removeUser(){\n        tl.remove();\n    }\n}\n```\n\n## session 共享问题\n\n**核心思路分析：**\n\n每个 tomcat 中都有一份属于自己的 session, 假设用户第一次访问第一台 tomcat，并且把自己的信息存放到第一台服务器的 session 中，但是第二次这个用户访问到了第二台 tomcat，那么在第二台服务器上，肯定没有第一台服务器存放的 session，所以此时 整个登录拦截功能就会出现问题，我们能如何解决这个问题呢？早期的方案是 session 拷贝，就是说虽然每个 tomcat 上都有不同的 session，但是每当任意一台服务器的 session 修改时，都会同步给其他的 Tomcat 服务器的 session，这样的话，就可以实现 session 的共享了\n\n但是这种方案具有两个大问题\n\n1、每台服务器中都有完整的一份 session 数据，服务器压力过大。\n\n2、session 拷贝数据时，可能会出现延迟\n\n所以咱们后来采用的方案都是基于 redis 来完成，我们把 session 换成 redis，redis 数据本身就是共享的，就可以避免 session 共享的问题了\n\n![session共享](redis-in-action-SMS-login/session共享.png)\n\n## Redis 代替 session 的业务流程\n\n### 设计 key 的结构\n\n首先我们要思考一下利用 redis 来存储数据，那么到底使用哪种结构呢？由于存入的数据比较简单，我们可以考虑使用 String，或者是使用哈希，如下图，如果使用 String，同学们注意他的 value，用多占用一点空间，如果使用哈希，则他的 value 中只会存储他数据本身，如果不是特别在意内存，其实使用 String 就可以啦。\n\n![redis设计key](redis-in-action-SMS-login/redis设计key.png)\n\n### 设计 key 的具体细节\n\n所以我们可以使用 String 结构，就是一个简单的 key，value 键值对的方式，但是关于 key 的处理，session 他是每个用户都有自己的 session，但是 redis 的 key 是共享的，咱们就不能使用 code 了\n\n在设计这个 key 的时候，我们之前讲过需要满足两点\n\n1、key 要具有唯一性\n\n2、key 要方便携带\n\n如果我们采用 phone：手机号这个的数据来存储当然是可以的，但是如果把这样的敏感数据存储到 redis 中并且从页面中带过来毕竟不太合适，所以我们在后台生成一个随机串 token，然后让前端带来这个 token 就能完成我们的整体逻辑了\n\n### 整体访问流程\n\n当注册完成后，用户去登录会去校验用户提交的手机号和验证码，是否一致，如果一致，则根据手机号查询用户信息，不存在则新建，最后将用户数据保存到 redis，并且生成 token 作为 redis 的 key，当我们校验用户是否登录时，会去携带着 token 进行访问，从 redis 中取出 token 对应的 value，判断是否存在这个数据，如果没有则拦截，如果存在则将其保存到 threadLocal 中，并且放行。\n\n![共享session登录](redis-in-action-SMS-login/共享session登录.png)\n\n## 基于 Redis 实现短信登录\n\n### 设计 key 的结构\n\n首先我们要思考一下利用 redis 来存储数据，那么到底使用哪种结构呢？由于存入的数据比较简单，我们可以考虑使用 String，或者是使用哈希，如下图，如果使用 String，同学们注意他的 value，用多占用一点空间，如果使用哈希，则他的 value 中只会存储他数据本身，如果不是特别在意内存，其实使用 String 就可以啦。\n\n![使用string结构保存json字符串](redis-in-action-SMS-login/使用string结构保存json字符串.png)\n\n### 设计 key 的具体细节\n\n所以我们可以使用 String 结构，就是一个简单的 key，value 键值对的方式，但是关于 key 的处理，session 他是每个用户都有自己的 session，但是 redis 的 key 是共享的，咱们就不能使用 code 了\n\n在设计这个 key 的时候，我们之前讲过需要满足两点\n\n1、key 要具有唯一性\n\n2、key 要方便携带\n\n如果我们采用 phone：手机号这个的数据来存储当然是可以的，但是如果把这样的敏感数据存储到 redis 中并且从页面中带过来毕竟不太合适，所以我们在后台生成一个随机串 token，然后让前端带来这个 token 就能完成我们的整体逻辑了\n\n### 整体访问流程\n\n当注册完成后，用户去登录会去校验用户提交的手机号和验证码，是否一致，如果一致，则根据手机号查询用户信息，不存在则新建，最后将用户数据保存到 redis，并且生成 token 作为 redis 的 key，当我们校验用户是否登录时，会去携带着 token 进行访问，从 redis 中取出 token 对应的 value，判断是否存在这个数据，如果没有则拦截，如果存在则将其保存到 threadLocal 中，并且放行。\n\n![1653319474181](redis-in-action-SMS-login/1653319474181.png)\n\n## 基于 Redis 实现短信登录\n\n这里具体逻辑就不分析了，之前咱们已经重点分析过这个逻辑啦。\n\n```java\n@Override\npublic Result login(LoginFormDTO loginForm, HttpSession session) {\n    // 1.校验手机号\n    String phone = loginForm.getPhone();\n    if (RegexUtils.isPhoneInvalid(phone)) {\n        // 2.如果不符合，返回错误信息\n        return Result.fail(\"手机号格式错误！\");\n    }\n    // 3.从redis获取验证码并校验\n    String cacheCode = stringRedisTemplate.opsForValue().get(LOGIN_CODE_KEY + phone);\n    String code = loginForm.getCode();\n    if (cacheCode == null || !cacheCode.equals(code)) {\n        // 不一致，报错\n        return Result.fail(\"验证码错误\");\n    }\n \n    // 4.一致，根据手机号查询用户 select * from tb_user where phone = ?\n    User user = query().eq(\"phone\", phone).one();\n \n    // 5.判断用户是否存在\n    if (user == null) {\n        // 6.不存在，创建新用户并保存\n        user = createUserWithPhone(phone);\n    }\n \n    // 7.保存用户信息到 redis中\n    // 7.1.随机生成token，作为登录令牌\n    String token = UUID.randomUUID().toString(true);\n    // 7.2.将User对象转为HashMap存储\n    UserDTO userDTO = BeanUtil.copyProperties(user, UserDTO.class);\n    Map<String, Object> userMap = BeanUtil.beanToMap(userDTO, new HashMap<>(),\n            CopyOptions.create()\n                    .setIgnoreNullValue(true)\n                    .setFieldValueEditor((fieldName, fieldValue) -> fieldValue.toString()));\n    // 7.3.存储\n    String tokenKey = LOGIN_USER_KEY + token;\n    stringRedisTemplate.opsForHash().putAll(tokenKey, userMap);\n    // 7.4.设置token有效期\n    stringRedisTemplate.expire(tokenKey, LOGIN_USER_TTL, TimeUnit.MINUTES);\n \n    // 8.返回token\n    return Result.ok(token);\n}\n```\n\n","tags":["redis"],"categories":["redis"]},{"title":"爬虫初级使用记录","url":"/2023/03/20/introduction-to-spider/","content":"\n本文记录了爬虫最基础的使用方法，如果只想最快获得网页源码从2.2浏览即可\n\n<!--more-->\n\n## 1、爬虫核心库1：requests库\n\n学习爬虫其实并不太需要了解太多的网页结构知识，作为初学者只需要知道1点：所有想要获取的内容（例如新闻标题/网址/日期/来源等）都在网页源代码里，所谓网页源代码，就是网页背后的编程代码，这一小节我们首先来讲解下如何查看网页源代码，以及通过两个案例快速体验下如何通过requests库获取网页源代码。\n\n### 1.1 如何查看网页源代码\n\n在进入正式爬虫实战前，我们首先来了解下如何查看网页源代码。\n\n网络爬虫首先得有一个浏览器，这里强烈推荐谷歌浏览器（百度搜索谷歌浏览器，然后在官网[https://www.google.cn/chrome/](https://www.google.cn/chrome/)下载，谷歌浏览器默认是谷歌搜索，直接在网址输入框里输入内容可能搜索不到内容，可以在网址栏上输入baidu.com进行访问，或者可以点击浏览器右侧的设置按钮->选择界面左侧的搜索引擎->选择百度搜索引擎）。当然用别的浏览器，比如火狐浏览器等都是可以的，只要它按F12(有的电脑要同时按住左下角的Fn键)能弹出网页源代码即可。\n\n以谷歌浏览器为例来演示下F12的强大作用，百度搜索“阿里巴巴”，然后**按一下F12（有的电脑还得同时按住Fn）**，弹出如下页面，其中点击右侧设置按钮可以切换布局样式。\n\n![image-20230320154143682](introduction-to-spider/image-20230320154143682.png)\n\n这个按住F12弹出来的东西叫做开发者工具，是进行数据挖掘的利器，对于爬虫来说，大多数情况下只需要会用下图的这两个按钮即可。\n\n![img](introduction-to-spider/v2-e64893143d82ba0f5e79621345dea1cf_r.jpg)\n\n第一个按钮箭头形状按钮为**选择**按钮，第二个Elements按钮为**元素**按钮。\n\n**(1)** **选择按钮**\n\n点击一下它，发现它会变成蓝色，然后把鼠标在页面上移动移动，会发现页面上的颜色机会发生改变。如下图所示，当**移动鼠标**的时候，会发现界面上的颜色会发生变化，并且Elements里的内容就会随之发生变化。\n\n![image-20230320154833691](introduction-to-spider/image-20230320154833691.png)\n\n下面当选择按钮处于蓝色状态的时，点击一下第一个链接的标题，这时候选择按钮再次变成灰色，而Elements里的内容也将不再变动，此时便可以观察具体的网页源代码内容了，如下图所示，我们一般只关心里面的所需要的中文内容，如果没有看到中文文本，店家下图所示的三角箭头，即可展开内容，看到中文文本。\n\n![image-20230320155030944](introduction-to-spider/image-20230320155030944.png)\n\n**(2) Elements元素按钮**：\n\nElements元素按钮里面的内容可以理解为**就是网站的源码**，最后爬虫爬到的内容大致就是长这个样子的。下面就要接着完成一些“神奇”的操作。\n\n在下图“**1688”**那个地方鼠标双击俩下，这两个字变成可编辑的格式。\n\n![image-20230320155132398](introduction-to-spider/image-20230320155132398.png)\n\n将其改成“测试”，可以看到第一个的标题发生了改变，如下图所示：\n\n![image-20230320155245952](introduction-to-spider/image-20230320155245952.png)\n\n还可以用同样的操作，修改页面上的其他信息，如股价等。\n\n通过F12启动开发者工具，我们可以对网页结构有一个初步的认识，并可以利用选择按钮和“Elements”元素按钮观察我们想获取的内容在源码中的文本格式以及所在位置。\n\n**补充知识点1：查看网页源码的另一个方式**\n\n除了F12，另一个获取网页源码的方式是在网页上右击选择“**查看网页源代码**”，就可以获取这个网址的源代码，这个基本就是Python爬取到的最终信息。用鼠标上下滚动，就能看到很多内容，同样初学者不需要关心那些英文或者网页框架，只需要知道想获取的中文在哪里即可。\n\n这个方法比F12观察源码的方式更加真实，因为F12观察到的源码可能是被网页修饰过的，通过Python获取到内容可能和F12看到的不一致。通过该方法查看到的源码就是通过Python程序能够获取到的网页源代码。实战中常将两种方法联合使用：通过F12进行初步了解，然后右击查看网页源代码，看看所需内容到底在网页源代码的什么位置，其中可以通过Ctrl + F快捷键搜索所需要的内容。\n\n此外，如果F12看到的内容和通过右击查看网页源代码看到的内容很不一样，这是因为网站做了动态渲染的处理（这是一种反爬处理），这时候就需要用到2.2节selenium库的相关知识点来获取真正的网页源代码。\n\n**补充知识点2：http与https协议**\n\n有的时候我们理解的网址是：[http://www.baidu.com]([http://www.baidu.com)，但其实在编程里或者它真实的名字其实是：[https://www.baidu.com](https://www.baidu.com)，它前面有个“https://”这个叫做https协议，是网址的固定构成形式，某种程度表明这个网址是安全的，有的网址前面则为http://。如果在Python里输入[www.baidu.com](https://link.zhihu.com/?target=http%3A//www.baidu.com/)它是不认识的，得把“https://”加上才行，如下面所示。\n\n```text\nurl = 'https://www.baidu.com/'\n```\n\n其实最简单的办法，**就是直接浏览器访问该网址，然后把链接复制下来就行**。\n\n### 1.2 爬虫初尝试 - requests库获取网页源代码\n\n了解了如何查看网页源代码后，这一小节我们讲解下如何通过requests库爬取网页源代码。这里以一个学校的招聘网站为例。\n\n**（1） 获取网页源代码**\n\n通过第一章最后介绍的requests库来尝试获取下新闻的网页源代码，代码如下：\n\n```python\nimport requests\nurl = 'https://www.163.com/dy/article/I09JUB0P051984TV.html'\nres = requests.get(url).text\nprint(res)\n```\n\n运行后报错：\n\n`requests.exceptions.SSLError: HTTPSConnectionPool`\n\n![image-20230320160811293](introduction-to-spider/image-20230320160811293.png)\n\n这是由于ssl认证失败造成的，我们并不需要知道原因，只要像以下一样禁用ssl认证就可以了。\n\n```python\nimport requests\n\ns = requests.session()\ns.trust_env = False\ns.keep_alive = False\nrequests.DEFAULT_RETRIES = 50\n\nurl = 'https://www.gdpt.edu.cn/al_8/189'\nres = s.get(url).text\nprint(res)\n```\n\n这段代码使requests的连接禁用了ssl认证，不使用keep-alive，并将重连次数增加到了50，如果出现了类似的错误只需要将以上代码复制粘贴即可。运行后得到以下结果。\n\n![image-20230320161701948](introduction-to-spider/image-20230320161701948.png)\n\n这里虽然得到了结果，但是有的网站只认可浏览器发送过去的访问，而不认可直接通过Python发送过去的访问请求，那么该如何解决该问题呢？这时就需要设置下requests.get()中的headers参数，用来模拟浏览器进行访问。\n\n```python\nimport requests\n\ns = requests.session()\ns.trust_env = False\ns.keep_alive = False\nrequests.DEFAULT_RETRIES = 50\n\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 \\\n                    (KHTML, like Gecko) Chrome/14.0.835.163 Safari/535.1'}\nurl = 'https://www.gdpt.edu.cn/al_8/189'\nres = s.get(url, headers=headers).text\nprint(res)\n```\n\n## 2 爬虫核心库2：selenium库\n\n对比了我想要查询的内容，发现requests爬取的信息不是完整的，这是因为Requests只能获取到HTML文本，而无法获取到JavaScript动态生成的内容。如果div盒子里的内容是通过JavaScript生成的，那么requests就无法获取到。此时就需要使用selenium库了。\n\nSelenium库这一知识点相对比较重要，如果说requests库能够爬取50%的网站的话，那么通过selenium库的话可以爬取95%的网站，大部分较为困难的网址都可以通过其来获取网页源代码。下面我们首先来分析下requests库在一些复杂爬虫中遇到的难点，然后讲解下如何安装selenium库以及如何通过selenium库获取到网页源代码。\n\n### 2.1 requests库遇到的难点\n\n在使用requests库进行爬虫实战时，有时会遇到一大难题：获取不了网页真正的源代码。例如，上海证券交易所的公开信息、新浪财经的股票行情实时数据等，用常规爬虫手段会发现获取到的网页源代码内容很少且没有用。因为这些网页上展示的信息是动态渲染出来的，而通过常规爬虫手段获取的则是未经渲染的信息，所以其中没有我们想要的信息。\n\n以新浪财经的上证综合指数（上证综合指数反映在上海证券交易所全部上市股票价格综合情况）网页（[http://finance.sina.com.cn/realstock/]([http://finance.sina.com.cn/realstock)）为例，在浏览器中按F12 键，可以在网页源代码中看到指数数值。然后用常规爬虫手段，以requests.get(url).text 的方式获取这个网页的源代码，然后按快捷键Ctrl+F，在源代码中搜索刚才看到的指数数值，会发现搜索不到，如下图所示。而且就算加上headers 参数也没有改观。\n\n面对这种动态渲染的网页，在数据挖掘时就需要使用Selenium 库，通过模拟打开一个浏览器访问网址，然后获取渲染后的网页源代码，从而完成requests库难以完成的任务。\n\n| 优点       | 缺点                |                  |\n| ---------- | ------------------- | ---------------- |\n| requests库 | 爬取速度快          | 有些网站爬取不到 |\n| selenium库 | 能爬取95%以上的网站 | 爬取速度较慢     |\n\n### 2.2  Selenium库介绍与安装\n\n正式介绍selenium库之前，得首先先安装一个网页模拟器：ChromeDriver，它的作用是给Pyhton提供一个模拟浏览器，让Python能够运行一个模拟的浏览器进行网页访问，并用selenium进行鼠标及键盘等操作获取到网页真正的源代码。\n\n**(1) 安装Chrome谷歌浏览器**\n\n安装ChromeDriver之前，得先装一下Chrome谷歌浏览器，直接百度搜索谷歌浏览器，然后在官网[https://www.google.cn/chrome/](https://www.google.cn/chrome)下载即可。\n\n**(2) 查看Chrome浏览器版本**\n\n地址栏输入`chrome://version`回车即可\n\n![image-20230320163352932](introduction-to-spider/image-20230320163352932.png)\n\n![image-20230320163501421](introduction-to-spider/image-20230320163501421.png)\n\n**(3) ChromeDriver下载**\n\nChromeDriver官方下载地址：[http://chromedriver.storage.googleapis.com/index.html](http://chromedriver.storage.googleapis.com/index.html)。进入官网后，选择对应自己谷歌浏览器版本的ChromeDriver下载即可。不过由于官网再国内经常访问不了，因此可以在百度上搜索“ChromeDriver下载”，可以找到如下一个镜像下载网站：[http://npm.taobao.org/mirrors/chromedriver/](https://registry.npmmirror.com/binary.html?path=chromedriver/)。\n\n**(4) ChromeDriver环境变量配置**\n\n解压压缩包，找到chromedriver.exe复制到chrome的安装目录（其实也可以随便放一个文件夹,关键是要加入环境变量）。复制chromedriver.exe文件的路径并加入到电脑的环境变量中去。具体的：\n\n![img](introduction-to-spider/1365470-20190316154653549-1071713064.png)进入环境变量编辑界面，添加到用户变量即可，双击PATH，将你的文件位置（C:\\Program Files (x86)\\Google\\Chrome\\Application\\)添加到后面。\n\n![img](introduction-to-spider/1365470-20190316155217109-176711956.png)\n\n完成后在按住win+R键进入cmd，输入chromedriver验证是否安装成功：\n\n![image-20230320165251568](introduction-to-spider/image-20230320165251568.png)\n\n未配置环境也可以，例如：\n\n```python\nfrom selenium import webdriver\nimport time\n\ndef main():\n    chrome_driver = 'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe'  #chromedriver的文件位置\n    b = webdriver.Chrome(executable_path = chrome_driver)\n    b.get('https://www.google.com')\n    time.sleep(5)\n    b.quit()\n\nif __name__ == '__main__':\n    main()\n```\n\n已配置环境变量时，就不需要指定位置了\n\n```python\nfrom selenium import webdriver\nimport time\n\ndef main():\n    b = webdriver.Chrome()\n    b.get('https://www.baidu.com')\n    time.sleep(5)\n    b.quit()\n\nif __name__ == '__main__':\n    main()\n```\n\n如果运行时提示\n\n![img](introduction-to-spider/1365470-20190316162023053-275348276.png)\n\n很可能是chromedriver的版本不对（不要问我怎么知道的）。\n\n### **2.3 Selenium库获取网页源代码** \n\nSelenium库的功能很强大，使用技巧却并不复杂，只要掌握了下面的几个知识点，就能较游刃有余的使用selenium库了。\n\n**(1) 访问及关闭页面 + 网页最大化**\n\n通过以下这三行代码，就可以访问网站了，它相当于模拟人打开了一个浏览器，然后输入了一串网址：\n\n```text\nfrom selenium import webdriver\nbrowser = webdriver.Chrome()\nbrowser.get(\"https://www.baidu.com/\")\n```\n\n第一行引入selenium库里的webdriver功能，第二行browser = webdriver.Chrome()声明我们用的模拟器是谷歌浏览器，第三行通过brower.get()的这个方法访问网址。\n\n关闭模拟浏览器的代码如下，在代码最后加上这么一行，能关闭模拟浏览器。\n\n```text\nbrowser.quit()\n```\n\n**(2) 获取网页真正的源代码**\n\n利用selenium的一个主要目的就是为了获取原来难以获得的网页源码，代码如下：\n\n```text\ndata = browser.page_source\n```\n\n拿这个方法来试试之前提到过的比较难以获取的动态加载的内容：\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver import ChromeOptions\n\nurl = \"https://www.gdpt.edu.cn/al_8/189\"\n\noptions = ChromeOptions()\nbrowser = webdriver.Chrome(options=options)\nbrowser.get(url)\n\nsource = browser.page_source\n\nwith open('example.html', 'w', encoding=\"utf8\") as f:\n    f.write(source)\nbrowser.quit()\n```\n\n这样就得到了所有的内容并以一个html文件的形式写出\n\n### 2.4 selenium库加载登录信息\n\n如果一个网站要求登录才能看到信息，如何使用selenium登录呢。很简单，加载浏览器登陆过的信息即可。浏览器会将用户登录过的所有数据保存在`C:\\Users\\电脑用户名\\AppData\\Local\\Google\\Chrome\\User Data`，selenium只需要加载这个文件夹就可以了，代码如下：\n\n```python\nfrom selenium import webdriver\nfrom selenium.webdriver import ChromeOptions\n\nurl = \"https://www.gdpt.edu.cn/al_8/189\"\n\n# 加载cookies中已经保存的账号和密码\noptions = ChromeOptions()\noptions.add_argument(r'user-data-dir=C:\\Users\\电脑用户名\\AppData\\Local\\Google\\Chrome\\User Data')\nbrowser = webdriver.Chrome(options=options)\nbrowser.get(url)\n\nsource = browser.page_source\n\nwith open('example.html', 'w', encoding=\"utf8\") as f:\n    f.write(source)\nbrowser.quit()\n```\n\n","tags":["python","spider"],"categories":["python","spider"]},{"title":"how-to-fix-This-application-has-no-explicit-mapping-error","url":"/2023/03/17/how-to-fix-This-application-has-no-explicit-mapping-error/","content":"\n报错完整信息:This application has no explicit mapping for /error, so you are seeing this as a fallback\n\n<!--more-->\n\n翻阅了网上众多资料，主要有一下几种解决的方向：\n\n## 方向1:包的位置可能错误\n\nApplication启动类的位置不对.要将Application类放在最外侧,即包含所有子包\n\n原因:spring-boot会自动加载启动类所在包下及其子包下的所有组件.\n\n## 方向2: springboot配置文件有误\n\n在springboot的配置文件:application.yml或application.properties中关于视图解析器的配置问题:\n\n当pom文件下的spring-boot-starter-paren版本高时使用:\n\nspring.mvc.view.prefix/spring.mvc.view.suffix\n\n当pom文件下的spring-boot-starter-paren版本低时使用:\n\nspring.view.prefix/spring.view.suffix\n\n## 方向3: 映射路径有误\n\n控制器的URL路径书写问题\n\n@RequestMapping(“xxxxxxxxxxxxxx”)\n\n实际访问的路径与”xxx”不符合.\n\n然而作为刚接触SpringBoot的我一开始犯错的时候是在第四层\n\n## 方向4: 扫包出现错误\n\n你把你Controller类的@Controller给补上\n\n## 方向5: nginx是否打开并检查端口\n\n当使用nginx代理静态资源时，需要检查是否运行nginx，并注意端口不能冲突\n\n","tags":["debug","springboot"],"categories":["debug","springboot"]},{"title":"LeetCode题解：括号匹配算法","url":"/2023/01/21/LeetCode题解：括号匹配算法/","content":"\n## 括号匹配算法\n\n左*括号*必须用相同类型的右*括号*闭合。 左*括号*必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。\n\n<!--more-->\n\n### 1.实现目标\n\n在开发中，会出现需要判断字符串是否匹配的问题，如文本编辑器中括号不匹配会出现格式错误（如以下字符串），这就需要括号匹配算法\n\n```\ndsa(dsadsa{dhk)s})}\n```\n\n### 2.实现思路\n\n![$R5G0SIK](LeetCode题解：括号匹配算法/$R5G0SIK.jpg)\n\n由于括号是与最近的同类型括号匹配，可以利用栈的后进先出特性将右括号与最近的左括号匹配，如果不匹配，直接返回false\n\n### 3.具体实现\n\n当括号数量为奇数时直接返回false，为0直接返回true。\n\n核心逻辑：循环遍历字符串每一个字符，判断是左括号则入栈，num++，若是右括号则num--，让该括号与栈顶括号匹配，若相同则弹出栈，不同则什么都不做，这样就可以跳过普通字符而判断括号是否匹配\n\n为什么要设置num：设置变量num统计左括号的数目，当有右括号时num--，这是为了判断左右括号的数目要相同，但是还要判断是否为同类括号\n\n改进方法：判断isMatch（）时在后面加else，就不用判断num了，但是使用原方法leetcode速度更快，内存也更小\n\n代码\n\n```javascript\n<script>\t\n    let isValid = funtion(str){\n        const len = str.length\n        if(len%2===1)\n            return false\n        if(len===0)\n            return true\n        \n        str = str.split('')\n        let stack = []\n        const leftBracket = '{[('\n        cosnt rightBracket = '}])'\n        let a = str[0]\n        if(rightBracket.includes(a))\n            return false\n        \n        for(let i = 0;i<len;i++)\n            if(leftBracket.includes(str[i]))\n                stack.push(str[i])\n        \t\tnum++\n        \telse if(rightBracket.includes(str[i]))//\n                num--\n                let top = stack[stack.length-1]\n                if(isMatch(top,str[i]))\n                    stack.pop()\n        \t\t/*\n        \t\telse\n        \t\t\treturn false\t\t此时就不用num了\n        \t\t*/\n        if(num===0&&stack.length===0)\n            return true\n        else \n            return false\n        \n        \n    }\n\n\n\tfuntion isMatch(left,right){\n        if(left==='{'&&right==='}'){\n            return true\n        }else if(left==='['&&right===']'){\n            return true\n        }else if(left==='('&&right===')'){\n            return true\n        }else\n            return false\n    \n</script>\n```\n\n","tags":["leetcode"],"categories":["leetcode"]}]